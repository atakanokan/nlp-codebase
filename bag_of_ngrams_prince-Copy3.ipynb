{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"tocheading\">Table of Contents</h1>\n",
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import random\n",
    "import pickle as pkl\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import spacy\n",
    "import string\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "The dataset was downloaded from: http://ai.stanford.edu/~amaas/data/sentiment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_loc = \"data/imdb_reviews/\"\n",
    "\n",
    "# def read_txt_files(folder_path):\n",
    "#     \"\"\"Reads all .txt files in a folder to a list\"\"\"\n",
    "    \n",
    "#     file_list = os.listdir(folder_path)\n",
    "#     # for debugging, printing out the folder path and some files in it\n",
    "#     print(folder_path)\n",
    "#     print(file_list[:10])\n",
    "    \n",
    "#     all_reviews = []\n",
    "#     for file_path in file_list:\n",
    "#         f = open(folder_path + file_path,\"r\")\n",
    "#         all_reviews.append(f.readline())\n",
    "        \n",
    "#     return all_reviews\n",
    "\n",
    "# train_pos = read_txt_files(folder_path=data_loc+\"train/pos/\")\n",
    "# print(len(train_pos))\n",
    "# train_neg = read_txt_files(folder_path=data_loc+\"train/neg/\")\n",
    "# print(len(train_neg))\n",
    "# test_pos = read_txt_files(folder_path=data_loc+\"test/pos/\")\n",
    "# print(len(test_pos))\n",
    "# test_neg = read_txt_files(folder_path=data_loc+\"test/neg/\")\n",
    "# print(len(test_neg))\n",
    "\n",
    "# print(\"Train Positive examples = \" + str(len(train_pos)))\n",
    "# print(\"Train Negative examples = \" + str(len(train_neg)))\n",
    "# print(\"Test Positive examples = \" + str(len(test_pos)))\n",
    "# print(\"Test Negative examples = \" + str(len(test_neg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pos_labels = np.ones((len(train_pos),), dtype=int)\n",
    "# train_pos_labels\n",
    "\n",
    "# train_neg_labels = np.zeros((len(train_neg),), dtype=int)\n",
    "# train_neg_labels\n",
    "\n",
    "# train_data_labels = np.concatenate((train_pos_labels,train_neg_labels))\n",
    "# print(len(train_data_labels))\n",
    "# print(train_data_labels)\n",
    "\n",
    "# test_pos_labels = np.ones((len(test_pos),), dtype=int)\n",
    "# test_neg_labels = np.zeros((len(test_neg),), dtype=int)\n",
    "# test_data_labels = np.concatenate((test_pos_labels,test_neg_labels))\n",
    "# print(len(test_data_labels))\n",
    "# print(test_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# def cleanhtml(raw_html):\n",
    "#     cleanr = re.compile('<.*?>')\n",
    "#     cleantext = re.sub(cleanr, '', raw_html)\n",
    "#     return cleantext\n",
    "\n",
    "# train_pos_clean = [cleanhtml(x) for x in train_pos]\n",
    "# train_neg_clean = [cleanhtml(x) for x in train_neg]\n",
    "\n",
    "# test_pos_clean = [cleanhtml(x) for x in test_pos]\n",
    "# test_neg_clean = [cleanhtml(x) for x in test_neg]\n",
    "\n",
    "# train_all_clean = train_pos_clean + train_neg_clean\n",
    "# len(train_all_clean)\n",
    "\n",
    "# test_all_clean = test_pos_clean + test_neg_clean\n",
    "# len(test_all_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_size = 20000\n",
    "\n",
    "# assert training_size < 25000\n",
    "\n",
    "# shuffled_index = np.random.permutation(len(train_all_clean))\n",
    "# print(len(shuffled_index))\n",
    "# print(shuffled_index)\n",
    "\n",
    "# training_all_clean = [train_all_clean[i] for i in shuffled_index[:training_size]]\n",
    "# training_labels = [train_data_labels[i] for i in shuffled_index[:training_size]]\n",
    "# print(len(training_all_clean))\n",
    "# print(len(training_labels))\n",
    "\n",
    "# validation_all_clean = [train_all_clean[i] for i in shuffled_index[training_size:]]\n",
    "# validation_labels = [train_data_labels[i] for i in shuffled_index[training_size:]]\n",
    "# print(len(validation_all_clean))\n",
    "# print(len(validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pkl.dump(shuffled_index, open(\"shuffled_index.p\", \"wb\"))\n",
    "# pkl.dump(training_all_clean, open(\"training_all_clean.p\", \"wb\"))\n",
    "# pkl.dump(training_labels,  open(\"training_labels.p\", \"wb\"))\n",
    "# pkl.dump(validation_all_clean, open(\"validation_all_clean.p\", \"wb\"))\n",
    "# pkl.dump(validation_labels,  open(\"validation_labels.p\", \"wb\"))\n",
    "\n",
    "shuffled_index = pkl.load(open(\"shuffled_index.p\", \"rb\"))\n",
    "training_all_clean = pkl.load(open(\"training_all_clean.p\", \"rb\"))\n",
    "training_labels = pkl.load(open(\"training_labels.p\", \"rb\"))\n",
    "validation_all_clean = pkl.load(open(\"validation_all_clean.p\", \"rb\"))\n",
    "validation_labels = pkl.load(open(\"validation_labels.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# import string\n",
    "\n",
    "# # Load English tokenizer, tagger, parser, NER and word vectors\n",
    "# tokenizer = spacy.load('en_core_web_sm')\n",
    "# punctuations = string.punctuation\n",
    "\n",
    "# # This is word tokenizer\n",
    "# # # lowercase and remove punctuation\n",
    "# # def tokenize(sent):\n",
    "# #     tokens = tokenizer(sent)\n",
    "# #     return [token.text.lower() for token in tokens if (token.text not in punctuations)]\n",
    "# #     #return [token.text.lower() for token in tokens]\n",
    "    \n",
    "# # Modified for n-grams\n",
    "# def tokenize(sent, n_gram = 0, lemmatize = False):\n",
    "    \n",
    "#     tokens = tokenizer(sent)\n",
    "    \n",
    "#     # unigrams\n",
    "#     if lemmatize == False:\n",
    "#         unigrams = [token.text.lower() for token in tokens if (token.text not in punctuations)]\n",
    "#     else:\n",
    "#         #LEMMATIZED\n",
    "#         unigrams = [token.lemma_.lower() for token in tokens if (token.text not in punctuations)]\n",
    "    \n",
    "    \n",
    "#     output = []\n",
    "#     output.extend(unigrams)\n",
    "    \n",
    "#     n = 2\n",
    "#     while n <= n_gram:\n",
    "#         ngram_tokens = [\" \".join(unigrams[x:x+n]) for x in range(len(unigrams)-n+1)]\n",
    "#         output.extend(ngram_tokens)\n",
    "#         n = n + 1\n",
    "        \n",
    "#     return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def lower_case_remove_punc(parsed):\n",
    "#     return [token.text.lower() for token in parsed if (token.text not in punctuations)]\n",
    "\n",
    "# def tokenize_dataset(dataset, n_gram, lemmatize = True):\n",
    "#     token_dataset = []\n",
    "#     # we are keeping track of all tokens in dataset\n",
    "#     # in order to create vocabulary later\n",
    "#     all_tokens = []\n",
    "\n",
    "# #     for sample in tqdm_notebook(tokenizer.pipe(dataset, \n",
    "# #                                                disable=['parser', 'tagger', 'ner'], \n",
    "# #                                                batch_size=512, \n",
    "# #                                                n_threads=4)):\n",
    "\n",
    "#     itr = 0\n",
    "#     for sample in dataset:\n",
    "        \n",
    "#         if itr % 50 == 0:\n",
    "#             print(str(itr) + \" / \" + str(len(dataset)))\n",
    "#         # unigram version\n",
    "#         #tokens = lower_case_remove_punc(sample)\n",
    "        \n",
    "#         # n-gram version\n",
    "#         tokens = tokenize(sample,n_gram, lemmatize = lemmatize)\n",
    "        \n",
    "#         token_dataset.append(tokens)\n",
    "#         all_tokens += tokens\n",
    "        \n",
    "#         itr = itr + 1\n",
    "\n",
    "#     return token_dataset, all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert token to id in the dataset\n",
    "def token2index_dataset(tokens_data, token2id):\n",
    "    indices_data = []\n",
    "    for tokens in tokens_data:\n",
    "        index_list = [token2id[token] if token in token2id else UNK_IDX for token in tokens]\n",
    "        indices_data.append(index_list)\n",
    "    return indices_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save index 0 for unk and 1 for pad\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "\n",
    "def build_vocab(all_tokens, max_vocab_size = 10000):\n",
    "    # Returns:\n",
    "    # id2token: list of tokens, where id2token[i] returns token that corresponds to token i\n",
    "    # token2id: dictionary where keys represent tokens and corresponding values represent indices\n",
    "    token_counter = Counter(all_tokens)\n",
    "    vocab, count = zip(*token_counter.most_common(max_vocab_size))\n",
    "    id2token = list(vocab)\n",
    "    token2id = dict(zip(vocab, range(2,2+len(vocab)))) \n",
    "    id2token = ['<pad>', '<unk>'] + id2token\n",
    "    token2id['<pad>'] = PAD_IDX \n",
    "    token2id['<unk>'] = UNK_IDX\n",
    "    return token2id, id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grams = [1,2,3]\n",
    "lemmatize_list = [True,False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for lemmatize_arg in lemmatize_list:\n",
    "#     for gram_no in grams:\n",
    "#         print(str(gram_no))\n",
    "\n",
    "#         train_data_tokens, all_train_tokens = tokenize_dataset(training_all_clean,\n",
    "#                                                                n_gram=gram_no, \n",
    "#                                                                lemmatize = lemmatize_arg)\n",
    "\n",
    "#         # Tokenize Validation\n",
    "#         val_data_tokens, _ = tokenize_dataset(validation_all_clean,\n",
    "#                                               n_gram=gram_no, \n",
    "#                                               lemmatize = lemmatize_arg)\n",
    "\n",
    "#         if lemmatize_arg == True:\n",
    "#             gram_no = str(gram_no) + \"_lemma\"\n",
    "#         else:\n",
    "#             gram_no = str(gram_no)\n",
    "#         print(gram_no)\n",
    "\n",
    "#         # val set tokens\n",
    "#         print (\"Tokenizing val data\")\n",
    "#         pkl.dump(val_data_tokens, open(\"val_data_tokens_\"+str(gram_no)+\".p\", \"wb\"))\n",
    "\n",
    "#         # train set tokens\n",
    "#         print (\"Tokenizing train data\")\n",
    "#         pkl.dump(train_data_tokens, open(\"train_data_tokens_\"+str(gram_no)+\".p\", \"wb\"))\n",
    "#         pkl.dump(all_train_tokens, open(\"all_train_tokens_\"+str(gram_no)+\".p\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_SENTENCE_LENGTH = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class IMDBDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's \n",
    "    readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_list, target_list):\n",
    "        \"\"\"\n",
    "        @param data_list: list of newsgroup tokens \n",
    "        @param target_list: list of newsgroup targets \n",
    "\n",
    "        \"\"\"\n",
    "        self.data_list = data_list\n",
    "        self.target_list = target_list\n",
    "        assert (len(self.data_list) == len(self.target_list))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        \n",
    "        token_idx = self.data_list[key][:MAX_SENTENCE_LENGTH]\n",
    "        label = self.target_list[key]\n",
    "        return [token_idx, len(token_idx), label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imdb_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    length_list = []\n",
    "    #print(\"collate batch: \", batch[0][0])\n",
    "    #batch[0][0] = batch[0][0][:MAX_SENTENCE_LENGTH]\n",
    "    for datum in batch:\n",
    "        label_list.append(datum[2])\n",
    "        length_list.append(datum[1])\n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        padded_vec = np.pad(np.array(datum[0]), \n",
    "                                pad_width=((0,MAX_SENTENCE_LENGTH-datum[1])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list.append(padded_vec)\n",
    "    return [torch.from_numpy(np.array(data_list)), \n",
    "            torch.LongTensor(length_list), \n",
    "            torch.LongTensor(label_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BagOfNgrams(nn.Module):\n",
    "    \"\"\"\n",
    "    BagOfNgrams classification model\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, emb_dim):\n",
    "        \"\"\"\n",
    "        @param vocab_size: size of the vocabulary. \n",
    "        @param emb_dim: size of the word embedding\n",
    "        \"\"\"\n",
    "        super(BagOfNgrams, self).__init__()\n",
    "        # pay attention to padding_idx \n",
    "        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        self.linear = nn.Linear(emb_dim,20)\n",
    "    \n",
    "    def forward(self, data, length):\n",
    "        \"\"\"\n",
    "        \n",
    "        @param data: matrix of size (batch_size, max_sentence_length). Each row in data represents a \n",
    "            review that is represented using n-gram index. Note that they are padded to have same length.\n",
    "        @param length: an int tensor of size (batch_size), which represents the non-trivial (excludes padding)\n",
    "            length of each sentences in the data.\n",
    "        \"\"\"\n",
    "        out = self.embed(data)\n",
    "        out = torch.sum(out, dim=1)\n",
    "        out /= length.view(length.size()[0],1).expand_as(out).float()\n",
    "     \n",
    "        # return logits\n",
    "        out = self.linear(out.float())\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for testing the model\n",
    "def test_model(loader, model):\n",
    "    \"\"\"\n",
    "    Help function that tests the model's performance on a dataset\n",
    "    @param: loader - data loader for the dataset to test against\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    for data, lengths, labels in loader:\n",
    "        data_batch, length_batch, label_batch = data, lengths, labels\n",
    "        outputs = F.softmax(model(data_batch, length_batch), dim=1)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "    return (100 * correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.01, 1, 25000, 100, 64),\n",
       " (0.01, 2, 25000, 100, 64),\n",
       " (0.1, 1, 25000, 100, 64),\n",
       " (0.1, 2, 25000, 100, 64)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = [[1e-2,1e-1], ## learning rates\n",
    "          list(range(1,3)), ## ngrams\n",
    "          [25000], ## vocab size\n",
    "          [100], ## embedding size\n",
    "#          [100,200], ## max sentence length\n",
    "          [64] ## batch size\n",
    "         ]\n",
    "\n",
    "# params = [[1e-1,1,2,5], ## learning rates\n",
    "#           list(range(1,2)), ## ngrams\n",
    "#           [1e5], ## vocab size\n",
    "#           [100], ## embedding size\n",
    "#           [100], ## max sentence length\n",
    "#           [64] ## batch size\n",
    "#          ]\n",
    "\n",
    "print(len([*itertools.product(*params)]))\n",
    "[*itertools.product(*params)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hyperparameter_search(hyperparameter_space=params,\n",
    "                          epochs=5,\n",
    "                          optimizer_name = \"Adam\",\n",
    "                          lemmatize = False):\n",
    "\n",
    "    # returns all the permutations of the parameter search space\n",
    "    param_space = [*itertools.product(*params)]\n",
    "    \n",
    "    # validation loss dictionary\n",
    "    val_losses = {}\n",
    "    \n",
    "    # counter for progress\n",
    "    count = 0\n",
    "    \n",
    "    for param_comb in param_space:\n",
    "        print(\"-----------------------------------------------------------\")\n",
    "        print(\"Parameter Combination = \" + str(count+1) + \" / \" + str(len(param_space)))\n",
    "        count = count + 1      \n",
    "        \n",
    "        NUM_EPOCHS = epochs\n",
    "        lr_rate = param_comb[0]             # learning rate\n",
    "        grams = param_comb[1]               # n-grams\n",
    "        max_vocab_size = int(param_comb[2]) # vocabulary size\n",
    "        embed_dimension = param_comb[3]     # embedding vector size\n",
    "        #max_sentence_length = int(param_comb[4]) # max sentence length of data loader\n",
    "        BATCH_SIZE = param_comb[4]\n",
    "        \n",
    "        print(\"Learning Rate = \" + str(lr_rate))\n",
    "        print(\"Ngram = \" + str(grams))\n",
    "        print(\"Vocab Size = \" + str(max_vocab_size))\n",
    "        print(\"Embedding Dimension = \" + str(embed_dimension))\n",
    "        #print(\"Max Sentence Length = \" + str(max_sentence_length))\n",
    "        print(\"Batch Size = \" + str(BATCH_SIZE))\n",
    "\n",
    "        # Tokenization\n",
    "        # All tokens are created before the hyperparameter search loop\n",
    "        # Load the tokens here\n",
    "        if lemmatize == True:\n",
    "            grams = str(grams) +\"_lemma\"\n",
    "        \n",
    "        train_data_tokens = pkl.load(open(\"train_data_tokens_\"+str(grams)+\".p\", \"rb\"))\n",
    "        all_train_tokens = pkl.load(open(\"all_train_tokens_\"+str(grams)+\".p\", \"rb\"))\n",
    "\n",
    "        val_data_tokens = pkl.load(open(\"val_data_tokens_\"+str(grams)+\".p\", \"rb\"))\n",
    "        \n",
    "        print(\"Train dataset size is {}\".format(len(train_data_tokens)))\n",
    "        print(\"Val dataset size is {}\".format(len(val_data_tokens)))\n",
    "        print(\"Total number of tokens in train dataset is {}\".format(len(all_train_tokens)))\n",
    "        \n",
    "        # Building Vocabulary\n",
    "        # implicitly gets the max_vocab_size parameter\n",
    "        token2id, id2token = build_vocab(all_train_tokens,\n",
    "                                         max_vocab_size=max_vocab_size)\n",
    "        \n",
    "        # Lets check the dictionary by loading random token from it\n",
    "        random_token_id = random.randint(0, len(id2token)-1)\n",
    "        random_token = id2token[random_token_id]\n",
    "        print (\"Token id {} -> token {}\".format(random_token_id, id2token[random_token_id]))\n",
    "        print (\"Token {} -> token id {}\".format(random_token, token2id[random_token]))\n",
    "        \n",
    "        train_data_indices = token2index_dataset(train_data_tokens, \n",
    "                                                 token2id = token2id)\n",
    "        val_data_indices = token2index_dataset(val_data_tokens, \n",
    "                                               token2id = token2id)\n",
    "        # double checking\n",
    "        print (\"Train dataset size is {}\".format(len(train_data_indices)))\n",
    "        print (\"Val dataset size is {}\".format(len(val_data_indices)))\n",
    "        \n",
    "        \n",
    "\n",
    "        # Load training and validation data\n",
    "        train_dataset = IMDBDataset(train_data_indices, \n",
    "                                    training_labels)\n",
    "        train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                                   batch_size=BATCH_SIZE,\n",
    "                                                   collate_fn=imdb_func,\n",
    "                                                   shuffle=True)\n",
    "\n",
    "        val_dataset = IMDBDataset(val_data_indices, \n",
    "                                  validation_labels)\n",
    "        val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                                   batch_size=BATCH_SIZE,\n",
    "                                                   collate_fn=imdb_func,\n",
    "                                                   shuffle=True)  \n",
    "\n",
    "        # Initialize the N-gram Model\n",
    "        model = BagOfNgrams(len(id2token), embed_dimension)\n",
    "        \n",
    "        # Both Adam and SGD will be tried\n",
    "        if optimizer_name == \"Adam\":\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=lr_rate)\n",
    "        elif optimizer_name == \"SGD\":\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=lr_rate)\n",
    "        else:\n",
    "            print(\"this optimizer is not implemented yet\")\n",
    "        \n",
    "        # Cross Entropy Loss will be used\n",
    "        criterion = torch.nn.CrossEntropyLoss()  \n",
    "        \n",
    "        # Validation Losses will be stored in a list\n",
    "        # Caution: Two different optimizers\n",
    "        val_losses[param_comb] = []\n",
    "        \n",
    "    #for optimizer in optimizers:\n",
    "        print(\"Optimization Start\")\n",
    "        print(optimizer)\n",
    "\n",
    "        for epoch in range(NUM_EPOCHS):\n",
    "            for i, (data, lengths, labels) in enumerate(train_loader):\n",
    "                model.train()\n",
    "                data_batch, length_batch, label_batch = data, lengths, labels\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(data_batch, length_batch)\n",
    "                loss = criterion(outputs, label_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                # Validate every 100 iterations\n",
    "                # Adjust it to accustom changing batch sizes\n",
    "                if i > 0 and i % (50 * (64 / BATCH_SIZE)) == 0:\n",
    "\n",
    "                    # Accuracy Calculations\n",
    "                    train_acc = test_model(train_loader, model)\n",
    "                    val_acc = test_model(val_loader, model)\n",
    "                    val_losses[param_comb].append(val_acc)\n",
    "\n",
    "                    # Logging\n",
    "                    print('Epoch:[{}/{}],Step:[{}/{}],Training Acc:{},Validation Acc:{}'.format( \n",
    "                               epoch+1, NUM_EPOCHS, \n",
    "                                i+1, len(train_loader), \n",
    "                                train_acc, val_acc))\n",
    "                      \n",
    "    return val_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# param_val_losses_adam_nolemma = hyperparameter_search(hyperparameter_space = params,\n",
    "#                                          epochs = 5,\n",
    "#                                          optimizer_name = \"Adam\",\n",
    "#                                           lemmatize = False)\n",
    "# pkl.dump(param_val_losses_adam_nolemma, \n",
    "#          open(\"param_val_losses_adam_nolemma.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# param_val_losses_adam_lemma = hyperparameter_search(hyperparameter_space = params,\n",
    "#                                          epochs = 5,\n",
    "#                                          optimizer_name = \"Adam\",\n",
    "#                                           lemmatize = True)\n",
    "# pkl.dump(param_val_losses_adam_lemma, \n",
    "#          open(\"param_val_losses_adam_lemma.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "Parameter Combination = 1 / 96\n",
      "Learning Rate = 0.01\n",
      "Ngram = 1\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 4764439\n",
      "Token id 3518 -> token jet\n",
      "Token jet -> token id 3518\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:50.02,Validation Acc:50.36\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:50.255,Validation Acc:50.32\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:50.65,Validation Acc:50.86\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:51.425,Validation Acc:51.3\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:51.92,Validation Acc:51.8\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:52.33,Validation Acc:52.38\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:54.66,Validation Acc:53.4\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:56.325,Validation Acc:55.0\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:56.89,Validation Acc:55.46\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:56.995,Validation Acc:55.98\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:57.625,Validation Acc:55.94\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:58.055,Validation Acc:57.1\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:58.48,Validation Acc:57.84\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:58.725,Validation Acc:58.18\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:58.95,Validation Acc:58.62\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:58.655,Validation Acc:58.84\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:59.415,Validation Acc:59.02\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:59.76,Validation Acc:59.34\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:59.975,Validation Acc:59.34\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:60.275,Validation Acc:59.46\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:60.44,Validation Acc:59.8\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:60.385,Validation Acc:60.12\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:60.59,Validation Acc:60.16\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:60.875,Validation Acc:60.36\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:61.07,Validation Acc:60.5\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:61.045,Validation Acc:60.54\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:61.17,Validation Acc:60.78\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:61.55,Validation Acc:61.08\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:61.675,Validation Acc:61.06\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:61.835,Validation Acc:61.12\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 2 / 96\n",
      "Learning Rate = 0.01\n",
      "Ngram = 1\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 4764439\n",
      "Token id 35600 -> token overtone\n",
      "Token overtone -> token id 35600\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:38.345,Validation Acc:39.32\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:50.11,Validation Acc:51.08\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:50.85,Validation Acc:51.52\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:51.49,Validation Acc:51.94\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:52.045,Validation Acc:52.62\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:52.955,Validation Acc:52.84\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:53.675,Validation Acc:53.24\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:54.21,Validation Acc:53.68\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:54.525,Validation Acc:53.92\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:54.94,Validation Acc:54.5\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:55.41,Validation Acc:54.7\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:55.895,Validation Acc:55.26\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:56.475,Validation Acc:55.8\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:56.555,Validation Acc:55.64\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:56.47,Validation Acc:56.26\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:57.04,Validation Acc:56.28\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:57.36,Validation Acc:56.34\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:58.06,Validation Acc:56.88\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:58.1,Validation Acc:56.72\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:58.405,Validation Acc:56.88\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:58.745,Validation Acc:57.08\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:58.765,Validation Acc:57.34\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:59.245,Validation Acc:57.7\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:60.145,Validation Acc:58.44\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:60.315,Validation Acc:58.68\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:60.375,Validation Acc:58.88\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:60.925,Validation Acc:59.16\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:60.92,Validation Acc:59.24\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:60.775,Validation Acc:59.3\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:61.105,Validation Acc:59.68\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 3 / 96\n",
      "Learning Rate = 0.01\n",
      "Ngram = 1\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 4764439\n",
      "Token id 65043 -> token running.3\n",
      "Token running.3 -> token id 65043\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:53.44,Validation Acc:53.06\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:54.055,Validation Acc:53.32\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:55.085,Validation Acc:54.12\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:55.835,Validation Acc:54.92\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:56.585,Validation Acc:55.66\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:58.035,Validation Acc:57.14\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:58.96,Validation Acc:57.64\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:59.365,Validation Acc:57.9\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:59.33,Validation Acc:57.62\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:59.685,Validation Acc:57.8\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:60.21,Validation Acc:58.6\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:61.0,Validation Acc:59.24\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:60.325,Validation Acc:58.9\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:61.525,Validation Acc:60.02\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:61.59,Validation Acc:59.78\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:61.81,Validation Acc:60.34\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:61.65,Validation Acc:60.06\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:61.44,Validation Acc:59.82\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:60.955,Validation Acc:59.26\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:62.055,Validation Acc:60.48\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:61.78,Validation Acc:60.12\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:61.895,Validation Acc:60.12\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:62.715,Validation Acc:61.06\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:62.71,Validation Acc:60.78\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:62.64,Validation Acc:60.8\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:62.76,Validation Acc:60.84\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:62.855,Validation Acc:61.06\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:62.885,Validation Acc:61.06\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:62.6,Validation Acc:60.84\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:63.015,Validation Acc:61.2\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 4 / 96\n",
      "Learning Rate = 0.01\n",
      "Ngram = 1\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 4764439\n",
      "Token id 29028 -> token motiveless\n",
      "Token motiveless -> token id 29028\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:46.56,Validation Acc:47.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[1/5],Step:[51/157],Training Acc:47.235,Validation Acc:47.74\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:47.96,Validation Acc:47.98\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:48.655,Validation Acc:49.04\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:49.54,Validation Acc:49.8\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:50.105,Validation Acc:50.5\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:51.0,Validation Acc:51.52\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:52.23,Validation Acc:51.58\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:53.29,Validation Acc:52.36\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:54.035,Validation Acc:53.58\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:54.96,Validation Acc:54.46\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:55.515,Validation Acc:55.02\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:56.61,Validation Acc:56.12\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:57.105,Validation Acc:56.58\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:57.26,Validation Acc:56.2\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:58.325,Validation Acc:57.4\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:58.805,Validation Acc:57.82\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:58.93,Validation Acc:58.14\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:59.92,Validation Acc:58.84\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:60.315,Validation Acc:59.06\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:60.85,Validation Acc:59.56\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:60.835,Validation Acc:59.96\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:60.89,Validation Acc:59.42\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:61.175,Validation Acc:59.66\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:61.085,Validation Acc:59.76\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:61.565,Validation Acc:59.84\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:61.9,Validation Acc:60.26\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:62.445,Validation Acc:60.96\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:62.485,Validation Acc:61.2\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:63.09,Validation Acc:61.48\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 5 / 96\n",
      "Learning Rate = 0.01\n",
      "Ngram = 1\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 4764439\n",
      "Token id 70455 -> token footprint\n",
      "Token footprint -> token id 70455\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:48.57,Validation Acc:48.34\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:49.84,Validation Acc:48.94\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:50.7,Validation Acc:50.14\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:51.49,Validation Acc:51.14\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:52.115,Validation Acc:51.58\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:52.53,Validation Acc:51.84\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:53.82,Validation Acc:52.9\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:54.96,Validation Acc:53.74\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:55.34,Validation Acc:54.16\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:55.655,Validation Acc:54.64\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:56.65,Validation Acc:55.66\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:56.6,Validation Acc:55.5\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:57.315,Validation Acc:55.98\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:57.85,Validation Acc:56.9\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:57.825,Validation Acc:56.96\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:58.81,Validation Acc:57.68\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:59.5,Validation Acc:58.14\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:58.815,Validation Acc:57.68\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:59.59,Validation Acc:58.18\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:59.08,Validation Acc:58.04\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:59.625,Validation Acc:58.66\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:60.67,Validation Acc:58.9\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:60.87,Validation Acc:59.08\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:60.62,Validation Acc:59.48\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:60.715,Validation Acc:59.5\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:61.08,Validation Acc:59.96\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:61.43,Validation Acc:59.56\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:61.32,Validation Acc:60.0\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:61.295,Validation Acc:60.04\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:61.445,Validation Acc:59.96\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 6 / 96\n",
      "Learning Rate = 0.01\n",
      "Ngram = 1\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 4764439\n",
      "Token id 8159 -> token della\n",
      "Token della -> token id 8159\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:38.565,Validation Acc:39.82\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:49.735,Validation Acc:50.0\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:50.515,Validation Acc:50.52\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:51.38,Validation Acc:51.28\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:51.75,Validation Acc:52.18\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:52.275,Validation Acc:52.8\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:53.05,Validation Acc:53.32\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:53.85,Validation Acc:53.94\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:53.865,Validation Acc:53.92\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:54.2,Validation Acc:54.3\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:55.005,Validation Acc:54.6\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:55.775,Validation Acc:55.66\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:55.915,Validation Acc:55.64\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:56.2,Validation Acc:56.06\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:56.685,Validation Acc:56.38\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:57.21,Validation Acc:56.74\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:57.675,Validation Acc:57.28\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:57.965,Validation Acc:57.26\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:57.8,Validation Acc:57.12\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:58.63,Validation Acc:57.56\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:58.75,Validation Acc:57.76\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:59.145,Validation Acc:57.94\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:59.205,Validation Acc:58.28\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:59.475,Validation Acc:58.16\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:59.51,Validation Acc:58.44\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:59.66,Validation Acc:58.6\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:60.14,Validation Acc:58.98\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:60.095,Validation Acc:59.0\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:60.33,Validation Acc:59.04\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:60.29,Validation Acc:59.22\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 7 / 96\n",
      "Learning Rate = 0.01\n",
      "Ngram = 1\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 4764439\n",
      "Token id 74767 -> token playing).for\n",
      "Token playing).for -> token id 74767\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:50.2,Validation Acc:49.74\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:51.095,Validation Acc:51.38\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:52.73,Validation Acc:52.32\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:54.77,Validation Acc:52.82\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:56.245,Validation Acc:54.24\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:57.605,Validation Acc:55.56\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:58.76,Validation Acc:56.04\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:59.7,Validation Acc:57.3\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:60.075,Validation Acc:57.82\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:60.64,Validation Acc:58.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[2/5],Step:[251/313],Training Acc:60.675,Validation Acc:58.2\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:61.26,Validation Acc:58.72\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:61.11,Validation Acc:58.38\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:61.27,Validation Acc:58.58\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:61.885,Validation Acc:59.54\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:62.78,Validation Acc:60.2\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:62.665,Validation Acc:59.7\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:62.845,Validation Acc:60.06\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:63.23,Validation Acc:60.66\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:63.27,Validation Acc:60.22\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:63.14,Validation Acc:60.26\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:62.995,Validation Acc:60.12\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:63.505,Validation Acc:60.44\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:63.855,Validation Acc:61.22\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:63.825,Validation Acc:61.0\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:63.99,Validation Acc:61.24\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:63.935,Validation Acc:61.0\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:64.1,Validation Acc:61.24\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:64.23,Validation Acc:61.22\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:64.23,Validation Acc:61.72\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 8 / 96\n",
      "Learning Rate = 0.01\n",
      "Ngram = 1\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 4764439\n",
      "Token id 42978 -> token orgazmo\n",
      "Token orgazmo -> token id 42978\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:51.14,Validation Acc:50.36\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:52.135,Validation Acc:51.06\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:53.04,Validation Acc:52.14\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:52.925,Validation Acc:52.3\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:53.345,Validation Acc:52.54\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:54.72,Validation Acc:53.7\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:54.745,Validation Acc:54.3\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:55.35,Validation Acc:54.42\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:56.74,Validation Acc:55.92\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:57.87,Validation Acc:56.76\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:58.0,Validation Acc:57.06\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:58.33,Validation Acc:57.34\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:57.81,Validation Acc:57.06\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:59.09,Validation Acc:57.82\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:59.435,Validation Acc:58.24\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:59.885,Validation Acc:58.56\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:60.105,Validation Acc:58.84\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:60.18,Validation Acc:58.9\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:60.895,Validation Acc:59.5\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:61.16,Validation Acc:59.64\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:61.37,Validation Acc:60.04\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:61.15,Validation Acc:59.52\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:61.63,Validation Acc:60.08\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:61.1,Validation Acc:59.66\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:61.765,Validation Acc:60.08\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:62.205,Validation Acc:60.56\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:62.225,Validation Acc:60.5\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:62.2,Validation Acc:60.5\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:62.775,Validation Acc:61.02\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:62.6,Validation Acc:60.78\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 9 / 96\n",
      "Learning Rate = 0.01\n",
      "Ngram = 2\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 9508878\n",
      "Token id 4298 -> token vehicle\n",
      "Token vehicle -> token id 4298\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:50.01,Validation Acc:49.72\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:50.025,Validation Acc:49.4\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:50.1,Validation Acc:49.34\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:50.445,Validation Acc:49.56\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:50.335,Validation Acc:49.68\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:50.635,Validation Acc:49.82\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:50.84,Validation Acc:49.9\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:51.315,Validation Acc:50.34\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:53.34,Validation Acc:51.96\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:54.835,Validation Acc:54.0\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:54.915,Validation Acc:54.0\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:55.415,Validation Acc:53.98\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:56.07,Validation Acc:55.2\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:56.695,Validation Acc:55.68\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:56.905,Validation Acc:55.9\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:57.2,Validation Acc:56.06\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:57.105,Validation Acc:55.9\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:56.885,Validation Acc:54.84\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:57.665,Validation Acc:56.6\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:58.275,Validation Acc:56.42\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:58.405,Validation Acc:56.76\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:57.95,Validation Acc:55.96\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:58.625,Validation Acc:56.8\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:58.835,Validation Acc:56.94\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:58.795,Validation Acc:56.74\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:59.15,Validation Acc:57.3\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:59.185,Validation Acc:57.44\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:59.245,Validation Acc:57.36\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:59.595,Validation Acc:57.36\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:59.735,Validation Acc:57.46\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 10 / 96\n",
      "Learning Rate = 0.01\n",
      "Ngram = 2\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 9508878\n",
      "Token id 91232 -> token force behind\n",
      "Token force behind -> token id 91232\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:47.695,Validation Acc:46.98\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:48.805,Validation Acc:48.0\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:48.9,Validation Acc:48.12\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:49.105,Validation Acc:48.7\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:49.24,Validation Acc:48.52\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:49.275,Validation Acc:48.52\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:49.61,Validation Acc:49.7\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:49.71,Validation Acc:49.56\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:49.905,Validation Acc:49.38\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:50.245,Validation Acc:49.68\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:50.23,Validation Acc:49.84\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:50.43,Validation Acc:49.9\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:50.66,Validation Acc:50.38\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:50.875,Validation Acc:50.86\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:51.33,Validation Acc:51.08\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:51.695,Validation Acc:51.3\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:51.715,Validation Acc:51.4\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:52.095,Validation Acc:51.7\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:52.06,Validation Acc:51.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[4/5],Step:[51/157],Training Acc:52.59,Validation Acc:52.4\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:52.81,Validation Acc:52.54\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:52.97,Validation Acc:53.02\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:53.23,Validation Acc:53.3\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:53.685,Validation Acc:53.32\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:54.04,Validation Acc:53.82\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:54.02,Validation Acc:53.9\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:54.37,Validation Acc:54.1\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:54.905,Validation Acc:54.3\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:55.175,Validation Acc:54.58\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:55.335,Validation Acc:54.62\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 11 / 96\n",
      "Learning Rate = 0.01\n",
      "Ngram = 2\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 9508878\n",
      "Token id 5983 -> token caring\n",
      "Token caring -> token id 5983\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:50.82,Validation Acc:50.16\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:51.815,Validation Acc:51.06\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:52.49,Validation Acc:51.44\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:53.86,Validation Acc:52.94\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:54.2,Validation Acc:53.06\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:54.155,Validation Acc:52.6\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:56.765,Validation Acc:55.7\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:56.005,Validation Acc:54.5\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:59.05,Validation Acc:57.8\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:59.835,Validation Acc:57.8\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:60.755,Validation Acc:59.02\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:60.55,Validation Acc:58.72\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:61.49,Validation Acc:59.74\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:61.285,Validation Acc:59.76\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:61.005,Validation Acc:59.62\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:61.59,Validation Acc:60.16\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:62.165,Validation Acc:60.64\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:63.095,Validation Acc:61.28\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:63.32,Validation Acc:61.46\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:62.945,Validation Acc:61.54\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:62.78,Validation Acc:61.58\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:62.7,Validation Acc:61.46\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:63.995,Validation Acc:62.36\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:64.065,Validation Acc:62.5\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:63.63,Validation Acc:62.52\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:64.19,Validation Acc:62.9\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:64.35,Validation Acc:62.58\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:63.765,Validation Acc:62.36\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:62.56,Validation Acc:60.66\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:63.63,Validation Acc:62.28\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 12 / 96\n",
      "Learning Rate = 0.01\n",
      "Ngram = 2\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 9508878\n",
      "Token id 57072 -> token making things\n",
      "Token making things -> token id 57072\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:50.075,Validation Acc:49.68\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:50.725,Validation Acc:50.08\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:51.215,Validation Acc:51.02\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:51.925,Validation Acc:51.72\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:52.52,Validation Acc:52.48\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:52.995,Validation Acc:52.68\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:52.95,Validation Acc:52.12\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:53.025,Validation Acc:52.48\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:54.465,Validation Acc:53.68\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:54.55,Validation Acc:54.06\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:55.315,Validation Acc:54.34\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:55.91,Validation Acc:55.36\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:56.39,Validation Acc:55.94\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:56.14,Validation Acc:56.08\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:57.035,Validation Acc:56.68\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:57.265,Validation Acc:57.12\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:57.395,Validation Acc:57.28\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:57.525,Validation Acc:57.48\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:57.62,Validation Acc:57.6\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:58.19,Validation Acc:58.04\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:58.445,Validation Acc:58.06\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:58.52,Validation Acc:58.22\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:58.82,Validation Acc:58.52\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:58.995,Validation Acc:58.48\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:59.29,Validation Acc:58.38\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:59.45,Validation Acc:58.78\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:59.31,Validation Acc:58.98\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:59.11,Validation Acc:58.78\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:59.89,Validation Acc:59.1\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:60.25,Validation Acc:59.06\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 13 / 96\n",
      "Learning Rate = 0.01\n",
      "Ngram = 2\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 9508878\n",
      "Token id 128883 -> token submissive\n",
      "Token submissive -> token id 128883\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:49.67,Validation Acc:48.8\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:50.14,Validation Acc:48.96\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:49.92,Validation Acc:49.3\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:51.28,Validation Acc:50.5\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:51.465,Validation Acc:50.6\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:51.75,Validation Acc:50.86\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:52.275,Validation Acc:51.42\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:52.765,Validation Acc:51.74\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:53.08,Validation Acc:51.98\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:53.355,Validation Acc:52.22\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:53.625,Validation Acc:52.48\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:53.525,Validation Acc:52.46\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:54.29,Validation Acc:53.02\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:54.75,Validation Acc:53.46\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:55.08,Validation Acc:53.5\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:55.045,Validation Acc:53.72\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:55.135,Validation Acc:54.06\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:55.595,Validation Acc:54.38\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:55.895,Validation Acc:54.72\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:56.14,Validation Acc:54.76\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:56.45,Validation Acc:55.08\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:56.53,Validation Acc:55.1\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:56.83,Validation Acc:55.5\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:57.12,Validation Acc:55.76\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:56.99,Validation Acc:55.7\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:57.54,Validation Acc:56.16\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:57.64,Validation Acc:56.28\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:57.8,Validation Acc:56.66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[5/5],Step:[251/313],Training Acc:57.855,Validation Acc:56.74\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:57.985,Validation Acc:56.96\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 14 / 96\n",
      "Learning Rate = 0.01\n",
      "Ngram = 2\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 9508878\n",
      "Token id 415264 -> token her haughty\n",
      "Token her haughty -> token id 415264\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:49.71,Validation Acc:49.38\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:50.43,Validation Acc:50.68\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:50.565,Validation Acc:50.78\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:50.88,Validation Acc:50.76\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:51.185,Validation Acc:50.88\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:51.185,Validation Acc:51.0\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:52.005,Validation Acc:51.28\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:52.19,Validation Acc:51.5\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:52.545,Validation Acc:51.7\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:52.83,Validation Acc:51.98\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:53.225,Validation Acc:52.18\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:53.475,Validation Acc:52.24\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:54.185,Validation Acc:52.82\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:54.54,Validation Acc:53.58\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:54.745,Validation Acc:52.98\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:55.08,Validation Acc:53.6\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:55.425,Validation Acc:54.2\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:55.465,Validation Acc:53.84\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:55.76,Validation Acc:54.54\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:56.015,Validation Acc:54.68\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:56.22,Validation Acc:54.94\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:56.42,Validation Acc:55.28\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:56.505,Validation Acc:55.16\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:56.69,Validation Acc:55.96\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:56.71,Validation Acc:56.1\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:57.055,Validation Acc:56.18\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:57.39,Validation Acc:56.32\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:57.32,Validation Acc:56.46\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:57.385,Validation Acc:56.64\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:57.4,Validation Acc:56.64\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 15 / 96\n",
      "Learning Rate = 0.01\n",
      "Ngram = 2\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 9508878\n",
      "Token id 570035 -> token 've hated\n",
      "Token 've hated -> token id 570035\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:50.42,Validation Acc:49.96\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:51.19,Validation Acc:50.76\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:52.285,Validation Acc:51.56\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:53.65,Validation Acc:52.92\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:54.75,Validation Acc:53.46\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:55.285,Validation Acc:53.82\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:56.345,Validation Acc:54.86\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:56.455,Validation Acc:55.16\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:56.945,Validation Acc:55.28\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:58.105,Validation Acc:56.26\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:58.155,Validation Acc:56.3\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:58.62,Validation Acc:56.7\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:59.03,Validation Acc:57.18\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:59.54,Validation Acc:57.86\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:59.73,Validation Acc:58.24\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:59.68,Validation Acc:57.6\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:59.9,Validation Acc:57.76\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:60.565,Validation Acc:59.04\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:60.675,Validation Acc:59.36\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:60.88,Validation Acc:59.5\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:61.0,Validation Acc:59.5\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:61.32,Validation Acc:59.44\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:61.26,Validation Acc:59.34\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:61.385,Validation Acc:59.48\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:61.385,Validation Acc:59.42\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:61.415,Validation Acc:59.68\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:61.62,Validation Acc:59.88\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:61.905,Validation Acc:60.18\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:61.97,Validation Acc:60.64\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:61.92,Validation Acc:60.76\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 16 / 96\n",
      "Learning Rate = 0.01\n",
      "Ngram = 2\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 9508878\n",
      "Token id 331056 -> token her train\n",
      "Token her train -> token id 331056\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:48.295,Validation Acc:44.9\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:49.64,Validation Acc:49.3\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:49.865,Validation Acc:49.96\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:50.48,Validation Acc:50.4\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:50.86,Validation Acc:50.56\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:51.165,Validation Acc:50.72\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:52.34,Validation Acc:51.9\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:52.68,Validation Acc:52.34\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:53.27,Validation Acc:51.84\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:53.85,Validation Acc:52.86\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:54.615,Validation Acc:53.18\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:55.01,Validation Acc:53.48\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:55.33,Validation Acc:54.04\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:55.82,Validation Acc:53.86\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:56.135,Validation Acc:54.28\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:56.49,Validation Acc:54.66\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:56.645,Validation Acc:55.56\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:56.965,Validation Acc:56.08\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:56.755,Validation Acc:55.98\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:57.285,Validation Acc:56.76\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:57.56,Validation Acc:56.82\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:57.85,Validation Acc:57.14\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:58.265,Validation Acc:57.5\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:58.385,Validation Acc:57.8\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:58.535,Validation Acc:58.04\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:58.32,Validation Acc:57.58\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:58.585,Validation Acc:58.08\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:59.215,Validation Acc:58.58\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:59.605,Validation Acc:58.78\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:59.595,Validation Acc:59.1\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 17 / 96\n",
      "Learning Rate = 0.01\n",
      "Ngram = 3\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 14233317\n",
      "Token id 80784 -> token have a better\n",
      "Token have a better -> token id 80784\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[1/5],Step:[51/313],Training Acc:50.76,Validation Acc:51.08\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:52.59,Validation Acc:52.68\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:53.07,Validation Acc:53.16\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:53.445,Validation Acc:53.38\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:54.415,Validation Acc:54.82\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:54.89,Validation Acc:54.94\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:54.57,Validation Acc:54.54\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:55.97,Validation Acc:55.82\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:56.5,Validation Acc:56.54\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:55.99,Validation Acc:56.3\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:56.75,Validation Acc:56.84\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:57.22,Validation Acc:56.84\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:57.175,Validation Acc:56.82\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:58.02,Validation Acc:57.54\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:57.88,Validation Acc:57.28\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:58.18,Validation Acc:57.98\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:58.61,Validation Acc:58.0\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:58.415,Validation Acc:57.44\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:58.65,Validation Acc:58.44\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:59.195,Validation Acc:58.34\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:59.255,Validation Acc:59.1\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:59.175,Validation Acc:58.64\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:59.875,Validation Acc:59.38\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:59.49,Validation Acc:59.02\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:59.625,Validation Acc:59.08\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:59.65,Validation Acc:59.02\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:60.63,Validation Acc:60.18\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:60.73,Validation Acc:59.92\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:60.635,Validation Acc:60.36\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:60.66,Validation Acc:59.72\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 18 / 96\n",
      "Learning Rate = 0.01\n",
      "Ngram = 3\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 14233317\n",
      "Token id 399 -> token a lot of\n",
      "Token a lot of -> token id 399\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:49.01,Validation Acc:49.06\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:49.685,Validation Acc:49.54\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:49.745,Validation Acc:49.62\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:49.96,Validation Acc:49.82\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:50.05,Validation Acc:49.68\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:50.1,Validation Acc:49.72\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:50.135,Validation Acc:49.68\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:50.405,Validation Acc:49.66\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:50.325,Validation Acc:49.82\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:50.56,Validation Acc:50.18\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:50.865,Validation Acc:50.34\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:51.185,Validation Acc:50.46\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:51.58,Validation Acc:50.64\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:51.97,Validation Acc:50.98\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:52.105,Validation Acc:51.28\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:53.17,Validation Acc:51.44\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:53.62,Validation Acc:52.5\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:54.5,Validation Acc:53.04\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:54.84,Validation Acc:53.48\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:55.255,Validation Acc:54.12\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:54.76,Validation Acc:53.7\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:55.33,Validation Acc:54.28\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:55.9,Validation Acc:55.02\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:56.655,Validation Acc:55.3\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:57.105,Validation Acc:55.34\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:57.12,Validation Acc:55.68\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:57.34,Validation Acc:55.7\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:57.33,Validation Acc:56.1\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:57.49,Validation Acc:56.12\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:57.445,Validation Acc:56.06\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 19 / 96\n",
      "Learning Rate = 0.01\n",
      "Ngram = 3\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 14233317\n",
      "Token id 41074 -> token takes him\n",
      "Token takes him -> token id 41074\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:53.255,Validation Acc:52.46\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:53.49,Validation Acc:53.72\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:54.23,Validation Acc:53.74\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:55.225,Validation Acc:54.66\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:55.28,Validation Acc:55.06\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:56.58,Validation Acc:55.88\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:57.04,Validation Acc:56.34\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:58.01,Validation Acc:57.22\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:57.71,Validation Acc:57.34\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:58.26,Validation Acc:58.02\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:58.68,Validation Acc:58.34\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:59.51,Validation Acc:59.32\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:59.88,Validation Acc:59.34\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:60.16,Validation Acc:59.42\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:60.775,Validation Acc:60.16\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:60.605,Validation Acc:60.08\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:60.55,Validation Acc:59.86\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:60.94,Validation Acc:60.58\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:60.675,Validation Acc:59.8\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:61.065,Validation Acc:59.92\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:61.08,Validation Acc:59.94\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:61.055,Validation Acc:60.44\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:61.52,Validation Acc:61.18\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:62.215,Validation Acc:61.36\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:62.63,Validation Acc:61.2\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:62.325,Validation Acc:61.26\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:62.01,Validation Acc:60.82\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:62.235,Validation Acc:61.58\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:61.945,Validation Acc:60.68\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:62.465,Validation Acc:61.5\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 20 / 96\n",
      "Learning Rate = 0.01\n",
      "Ngram = 3\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 14233317\n",
      "Token id 48016 -> token hanging around\n",
      "Token hanging around -> token id 48016\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:47.6,Validation Acc:47.52\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:47.875,Validation Acc:48.12\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:47.885,Validation Acc:48.12\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:48.885,Validation Acc:48.88\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:49.42,Validation Acc:49.62\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:49.665,Validation Acc:49.6\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:50.335,Validation Acc:50.3\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:50.395,Validation Acc:50.88\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:50.735,Validation Acc:51.06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[2/5],Step:[101/157],Training Acc:51.135,Validation Acc:51.72\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:51.73,Validation Acc:51.36\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:52.155,Validation Acc:52.74\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:52.73,Validation Acc:52.96\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:53.175,Validation Acc:53.4\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:53.545,Validation Acc:53.52\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:54.015,Validation Acc:53.96\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:54.42,Validation Acc:54.52\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:54.41,Validation Acc:54.28\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:54.68,Validation Acc:54.72\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:55.045,Validation Acc:54.82\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:55.855,Validation Acc:54.74\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:55.485,Validation Acc:55.52\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:56.33,Validation Acc:55.16\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:56.395,Validation Acc:55.72\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:57.18,Validation Acc:55.84\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:56.975,Validation Acc:56.4\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:57.16,Validation Acc:56.6\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:57.14,Validation Acc:56.86\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:57.805,Validation Acc:56.78\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:58.22,Validation Acc:57.24\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 21 / 96\n",
      "Learning Rate = 0.01\n",
      "Ngram = 3\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 14233317\n",
      "Token id 700275 -> token feel anything for\n",
      "Token feel anything for -> token id 700275\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:49.95,Validation Acc:50.2\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:49.955,Validation Acc:50.26\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:49.985,Validation Acc:50.4\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:50.01,Validation Acc:50.48\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:50.155,Validation Acc:50.66\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:51.255,Validation Acc:50.74\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:52.39,Validation Acc:52.62\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:53.26,Validation Acc:53.3\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:54.065,Validation Acc:53.6\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:54.915,Validation Acc:54.5\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:55.435,Validation Acc:54.78\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:55.695,Validation Acc:55.2\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:56.07,Validation Acc:55.36\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:56.205,Validation Acc:55.28\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:56.56,Validation Acc:55.42\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:56.68,Validation Acc:56.08\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:56.88,Validation Acc:55.84\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:57.17,Validation Acc:56.52\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:57.445,Validation Acc:56.56\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:57.55,Validation Acc:56.44\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:57.685,Validation Acc:56.76\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:57.82,Validation Acc:57.02\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:58.135,Validation Acc:56.84\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:58.295,Validation Acc:57.22\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:58.485,Validation Acc:57.44\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:58.46,Validation Acc:57.26\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:58.6,Validation Acc:57.16\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:58.81,Validation Acc:57.62\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:58.97,Validation Acc:57.5\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:59.295,Validation Acc:57.68\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 22 / 96\n",
      "Learning Rate = 0.01\n",
      "Ngram = 3\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 14233317\n",
      "Token id 282379 -> token way across the\n",
      "Token way across the -> token id 282379\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:49.87,Validation Acc:49.94\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:49.96,Validation Acc:50.0\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:50.095,Validation Acc:49.96\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:50.045,Validation Acc:50.0\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:50.365,Validation Acc:50.36\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:50.35,Validation Acc:50.18\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:50.435,Validation Acc:50.26\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:50.61,Validation Acc:50.6\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:50.935,Validation Acc:50.76\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:51.125,Validation Acc:50.64\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:51.75,Validation Acc:51.16\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:52.05,Validation Acc:51.46\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:52.29,Validation Acc:51.66\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:53.285,Validation Acc:52.48\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:53.435,Validation Acc:52.6\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:53.58,Validation Acc:52.76\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:54.075,Validation Acc:53.12\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:54.28,Validation Acc:53.38\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:54.585,Validation Acc:53.9\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:54.725,Validation Acc:53.88\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:55.26,Validation Acc:54.54\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:55.29,Validation Acc:54.58\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:55.39,Validation Acc:54.76\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:55.44,Validation Acc:54.76\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:55.975,Validation Acc:54.76\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:55.97,Validation Acc:55.16\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:55.88,Validation Acc:55.2\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:56.07,Validation Acc:55.22\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:56.085,Validation Acc:55.42\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:56.2,Validation Acc:55.36\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 23 / 96\n",
      "Learning Rate = 0.01\n",
      "Ngram = 3\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 14233317\n",
      "Token id 558354 -> token hmmm maybe\n",
      "Token hmmm maybe -> token id 558354\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:52.135,Validation Acc:52.34\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:52.54,Validation Acc:53.0\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:54.02,Validation Acc:53.7\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:54.68,Validation Acc:54.32\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:55.6,Validation Acc:54.84\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:55.91,Validation Acc:55.38\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:57.48,Validation Acc:56.68\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:58.6,Validation Acc:58.46\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:59.02,Validation Acc:58.42\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:58.55,Validation Acc:58.18\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:59.275,Validation Acc:58.58\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:59.41,Validation Acc:58.68\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:60.57,Validation Acc:59.32\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:60.75,Validation Acc:59.54\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:60.855,Validation Acc:59.62\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:61.24,Validation Acc:60.04\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:61.6,Validation Acc:60.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[3/5],Step:[301/313],Training Acc:61.8,Validation Acc:60.22\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:61.65,Validation Acc:60.42\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:62.04,Validation Acc:60.5\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:62.33,Validation Acc:60.38\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:62.4,Validation Acc:60.9\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:62.6,Validation Acc:60.66\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:62.62,Validation Acc:60.9\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:62.685,Validation Acc:61.22\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:62.695,Validation Acc:61.16\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:62.74,Validation Acc:61.1\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:62.915,Validation Acc:61.18\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:63.18,Validation Acc:61.34\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:63.23,Validation Acc:61.08\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 24 / 96\n",
      "Learning Rate = 0.01\n",
      "Ngram = 3\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 14233317\n",
      "Token id 622298 -> token down only\n",
      "Token down only -> token id 622298\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:51.69,Validation Acc:51.36\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:52.235,Validation Acc:51.86\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:52.06,Validation Acc:51.72\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:52.155,Validation Acc:51.72\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:52.55,Validation Acc:51.94\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:53.525,Validation Acc:53.02\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:54.575,Validation Acc:53.58\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:55.1,Validation Acc:53.76\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:55.48,Validation Acc:54.02\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:55.505,Validation Acc:54.22\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:57.555,Validation Acc:55.78\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:58.34,Validation Acc:56.7\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:59.105,Validation Acc:57.2\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:59.25,Validation Acc:57.28\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:59.365,Validation Acc:57.58\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:59.175,Validation Acc:57.04\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:59.695,Validation Acc:58.1\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:60.39,Validation Acc:58.72\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:61.065,Validation Acc:59.36\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:60.6,Validation Acc:58.56\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:60.915,Validation Acc:59.32\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:60.78,Validation Acc:58.92\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:61.035,Validation Acc:58.9\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:61.345,Validation Acc:59.14\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:61.38,Validation Acc:59.4\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:61.58,Validation Acc:59.4\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:61.64,Validation Acc:59.46\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:62.17,Validation Acc:59.92\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:62.115,Validation Acc:59.74\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:62.04,Validation Acc:59.66\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 25 / 96\n",
      "Learning Rate = 0.1\n",
      "Ngram = 1\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 4764439\n",
      "Token id 73108 -> token me)---\n",
      "Token me)--- -> token id 73108\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:59.115,Validation Acc:58.96\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:60.57,Validation Acc:60.1\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:61.85,Validation Acc:61.26\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:62.54,Validation Acc:62.34\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:62.805,Validation Acc:61.8\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:63.435,Validation Acc:62.98\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:63.63,Validation Acc:62.86\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:64.17,Validation Acc:63.16\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:64.49,Validation Acc:63.7\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:63.69,Validation Acc:62.58\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:64.49,Validation Acc:63.46\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:64.83,Validation Acc:64.0\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:64.89,Validation Acc:63.66\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:65.31,Validation Acc:64.64\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:65.46,Validation Acc:65.14\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:65.295,Validation Acc:64.4\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:65.605,Validation Acc:64.6\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:65.93,Validation Acc:65.48\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:65.595,Validation Acc:64.6\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:65.685,Validation Acc:64.64\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:66.125,Validation Acc:65.2\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:66.275,Validation Acc:65.4\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:65.925,Validation Acc:65.12\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:65.975,Validation Acc:65.1\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:66.025,Validation Acc:65.18\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:66.325,Validation Acc:65.84\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:66.545,Validation Acc:65.82\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:66.655,Validation Acc:65.98\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:66.15,Validation Acc:65.1\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:66.575,Validation Acc:65.44\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 26 / 96\n",
      "Learning Rate = 0.1\n",
      "Ngram = 1\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 4764439\n",
      "Token id 26898 -> token creole\n",
      "Token creole -> token id 26898\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:54.67,Validation Acc:54.28\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:55.7,Validation Acc:55.64\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:57.58,Validation Acc:57.18\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:59.59,Validation Acc:58.86\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:59.99,Validation Acc:59.38\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:60.35,Validation Acc:59.08\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:61.465,Validation Acc:60.2\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:61.685,Validation Acc:60.28\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:60.575,Validation Acc:59.54\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:61.67,Validation Acc:60.6\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:62.395,Validation Acc:60.92\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:62.555,Validation Acc:61.4\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:62.67,Validation Acc:61.62\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:63.02,Validation Acc:61.72\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:63.08,Validation Acc:61.86\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:63.29,Validation Acc:61.6\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:63.085,Validation Acc:61.86\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:63.04,Validation Acc:61.54\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:63.37,Validation Acc:61.92\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:63.74,Validation Acc:62.32\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:63.79,Validation Acc:62.4\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:63.985,Validation Acc:62.32\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:64.095,Validation Acc:62.66\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:64.04,Validation Acc:62.58\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:64.3,Validation Acc:62.52\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:64.38,Validation Acc:62.68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[5/5],Step:[76/157],Training Acc:64.345,Validation Acc:62.64\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:64.495,Validation Acc:62.72\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:64.34,Validation Acc:62.76\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:64.565,Validation Acc:62.84\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 27 / 96\n",
      "Learning Rate = 0.1\n",
      "Ngram = 1\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 4764439\n",
      "Token id 6 -> token to\n",
      "Token to -> token id 6\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:58.39,Validation Acc:57.2\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:61.735,Validation Acc:60.74\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:62.895,Validation Acc:61.56\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:64.135,Validation Acc:62.46\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:64.665,Validation Acc:63.34\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:65.5,Validation Acc:63.94\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:66.01,Validation Acc:64.48\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:66.04,Validation Acc:64.5\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:66.48,Validation Acc:65.32\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:66.64,Validation Acc:64.78\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:67.215,Validation Acc:65.76\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:67.39,Validation Acc:65.62\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:67.16,Validation Acc:65.98\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:67.84,Validation Acc:66.24\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:68.225,Validation Acc:66.82\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:68.485,Validation Acc:66.88\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:68.245,Validation Acc:67.02\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:68.575,Validation Acc:67.34\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:69.125,Validation Acc:67.66\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:69.085,Validation Acc:67.78\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:69.065,Validation Acc:67.7\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:69.34,Validation Acc:68.02\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:69.775,Validation Acc:68.66\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:69.8,Validation Acc:68.58\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:69.935,Validation Acc:68.48\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:69.725,Validation Acc:68.44\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:70.2,Validation Acc:68.84\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:70.3,Validation Acc:69.0\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:70.105,Validation Acc:68.7\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:70.305,Validation Acc:68.86\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 28 / 96\n",
      "Learning Rate = 0.1\n",
      "Ngram = 1\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 4764439\n",
      "Token id 19847 -> token progressing\n",
      "Token progressing -> token id 19847\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:53.645,Validation Acc:53.64\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:59.735,Validation Acc:58.86\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:60.58,Validation Acc:58.56\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:63.39,Validation Acc:61.42\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:64.545,Validation Acc:62.48\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:64.255,Validation Acc:62.18\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:65.305,Validation Acc:63.06\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:65.255,Validation Acc:63.24\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:65.265,Validation Acc:63.4\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:65.42,Validation Acc:63.98\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:66.095,Validation Acc:64.08\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:66.14,Validation Acc:64.3\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:65.695,Validation Acc:64.1\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:66.175,Validation Acc:64.28\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:66.67,Validation Acc:64.88\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:66.47,Validation Acc:65.02\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:66.85,Validation Acc:64.86\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:66.95,Validation Acc:65.48\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:67.0,Validation Acc:65.38\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:67.105,Validation Acc:65.1\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:67.21,Validation Acc:65.54\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:67.27,Validation Acc:65.38\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:67.515,Validation Acc:65.66\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:67.47,Validation Acc:66.1\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:67.29,Validation Acc:65.38\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:67.38,Validation Acc:65.56\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:67.93,Validation Acc:66.0\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:67.8,Validation Acc:65.94\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:67.77,Validation Acc:66.2\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:67.965,Validation Acc:66.46\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 29 / 96\n",
      "Learning Rate = 0.1\n",
      "Ngram = 1\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 4764439\n",
      "Token id 28753 -> token bedding\n",
      "Token bedding -> token id 28753\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:58.18,Validation Acc:56.36\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:60.765,Validation Acc:59.08\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:60.22,Validation Acc:57.4\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:61.14,Validation Acc:60.04\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:62.71,Validation Acc:60.48\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:62.725,Validation Acc:60.34\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:62.645,Validation Acc:59.96\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:63.785,Validation Acc:61.7\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:63.83,Validation Acc:61.4\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:63.86,Validation Acc:61.38\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:64.1,Validation Acc:61.92\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:64.085,Validation Acc:61.58\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:64.8,Validation Acc:62.18\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:65.02,Validation Acc:62.38\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:65.005,Validation Acc:62.9\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:65.14,Validation Acc:62.66\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:65.17,Validation Acc:62.9\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:65.355,Validation Acc:63.08\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:64.975,Validation Acc:62.52\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:65.125,Validation Acc:62.72\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:65.45,Validation Acc:63.44\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:65.585,Validation Acc:63.08\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:65.78,Validation Acc:63.74\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:65.995,Validation Acc:63.82\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:66.115,Validation Acc:64.04\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:66.19,Validation Acc:64.02\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:66.17,Validation Acc:64.06\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:66.395,Validation Acc:63.98\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:66.395,Validation Acc:64.04\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:66.54,Validation Acc:64.2\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 30 / 96\n",
      "Learning Rate = 0.1\n",
      "Ngram = 1\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 4764439\n",
      "Token id 13213 -> token swings\n",
      "Token swings -> token id 13213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:50.655,Validation Acc:50.7\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:53.29,Validation Acc:53.4\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:57.13,Validation Acc:57.22\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:59.015,Validation Acc:59.44\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:60.245,Validation Acc:60.54\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:61.385,Validation Acc:60.88\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:60.86,Validation Acc:60.48\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:62.7,Validation Acc:61.64\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:62.92,Validation Acc:62.34\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:62.61,Validation Acc:61.28\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:63.1,Validation Acc:62.2\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:63.285,Validation Acc:62.34\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:63.64,Validation Acc:62.68\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:63.395,Validation Acc:62.38\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:63.78,Validation Acc:62.6\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:64.055,Validation Acc:62.94\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:64.17,Validation Acc:63.26\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:64.15,Validation Acc:62.96\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:64.475,Validation Acc:63.08\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:64.62,Validation Acc:63.22\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:64.3,Validation Acc:63.28\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:64.69,Validation Acc:63.52\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:64.45,Validation Acc:63.3\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:64.925,Validation Acc:63.3\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:64.73,Validation Acc:63.58\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:65.135,Validation Acc:63.36\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:64.985,Validation Acc:63.5\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:65.225,Validation Acc:63.5\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:65.395,Validation Acc:63.78\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:65.035,Validation Acc:63.84\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 31 / 96\n",
      "Learning Rate = 0.1\n",
      "Ngram = 1\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 4764439\n",
      "Token id 47797 -> token gigantically\n",
      "Token gigantically -> token id 47797\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:58.115,Validation Acc:58.3\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:60.735,Validation Acc:58.94\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:61.87,Validation Acc:60.38\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:64.69,Validation Acc:62.88\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:65.79,Validation Acc:63.98\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:66.265,Validation Acc:63.86\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:66.69,Validation Acc:64.38\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:66.465,Validation Acc:64.84\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:67.265,Validation Acc:65.0\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:66.715,Validation Acc:64.84\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:67.38,Validation Acc:65.06\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:67.65,Validation Acc:65.52\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:67.105,Validation Acc:65.02\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:67.66,Validation Acc:65.6\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:67.85,Validation Acc:66.08\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:68.31,Validation Acc:66.18\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:68.32,Validation Acc:66.48\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:68.43,Validation Acc:66.38\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:68.355,Validation Acc:66.58\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:68.195,Validation Acc:65.76\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:68.32,Validation Acc:65.98\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:68.975,Validation Acc:67.08\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:69.045,Validation Acc:67.06\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:69.195,Validation Acc:67.36\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:69.18,Validation Acc:67.26\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:69.32,Validation Acc:67.24\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:68.99,Validation Acc:67.5\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:69.465,Validation Acc:66.82\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:69.225,Validation Acc:67.06\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:69.73,Validation Acc:67.4\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 32 / 96\n",
      "Learning Rate = 0.1\n",
      "Ngram = 1\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 4764439\n",
      "Token id 52987 -> token oscillators\n",
      "Token oscillators -> token id 52987\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:55.205,Validation Acc:54.34\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:60.25,Validation Acc:58.62\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:60.845,Validation Acc:59.94\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:62.92,Validation Acc:61.38\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:63.605,Validation Acc:61.8\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:64.73,Validation Acc:63.06\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:64.815,Validation Acc:62.22\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:65.64,Validation Acc:63.6\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:65.74,Validation Acc:63.86\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:65.265,Validation Acc:63.4\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:65.96,Validation Acc:64.1\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:66.695,Validation Acc:64.6\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:66.325,Validation Acc:64.42\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:66.92,Validation Acc:65.1\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:66.815,Validation Acc:64.84\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:67.31,Validation Acc:65.68\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:67.39,Validation Acc:65.58\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:67.475,Validation Acc:65.74\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:67.51,Validation Acc:65.36\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:67.69,Validation Acc:65.5\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:67.86,Validation Acc:66.34\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:67.205,Validation Acc:64.88\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:68.065,Validation Acc:65.92\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:68.06,Validation Acc:66.14\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:68.065,Validation Acc:65.98\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:67.39,Validation Acc:64.98\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:68.31,Validation Acc:66.4\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:68.27,Validation Acc:66.24\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:68.485,Validation Acc:66.64\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:68.57,Validation Acc:67.0\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 33 / 96\n",
      "Learning Rate = 0.1\n",
      "Ngram = 2\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 9508878\n",
      "Token id 8067 -> token margaret\n",
      "Token margaret -> token id 8067\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:52.275,Validation Acc:51.72\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:55.05,Validation Acc:54.32\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:58.535,Validation Acc:56.76\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:57.815,Validation Acc:56.0\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:60.82,Validation Acc:59.1\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:61.485,Validation Acc:60.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[2/5],Step:[51/313],Training Acc:61.83,Validation Acc:59.6\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:61.74,Validation Acc:61.0\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:60.16,Validation Acc:58.04\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:61.97,Validation Acc:60.94\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:62.705,Validation Acc:61.84\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:63.39,Validation Acc:62.12\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:63.46,Validation Acc:62.54\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:63.67,Validation Acc:62.52\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:63.615,Validation Acc:62.56\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:63.375,Validation Acc:62.62\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:62.735,Validation Acc:59.7\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:63.865,Validation Acc:62.74\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:63.04,Validation Acc:61.8\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:64.105,Validation Acc:63.0\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:64.095,Validation Acc:62.24\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:64.155,Validation Acc:63.2\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:64.145,Validation Acc:62.82\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:64.0,Validation Acc:62.74\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:64.295,Validation Acc:63.38\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:64.005,Validation Acc:62.98\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:64.545,Validation Acc:63.68\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:64.625,Validation Acc:63.76\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:64.65,Validation Acc:63.8\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:64.75,Validation Acc:63.78\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 34 / 96\n",
      "Learning Rate = 0.1\n",
      "Ngram = 2\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 9508878\n",
      "Token id 61261 -> token than 90\n",
      "Token than 90 -> token id 61261\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:53.78,Validation Acc:53.3\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:56.785,Validation Acc:56.22\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:58.78,Validation Acc:57.76\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:59.555,Validation Acc:57.94\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:59.19,Validation Acc:59.36\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:61.015,Validation Acc:59.82\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:61.295,Validation Acc:60.12\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:61.505,Validation Acc:60.38\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:61.31,Validation Acc:60.88\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:60.93,Validation Acc:59.64\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:61.605,Validation Acc:60.82\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:61.66,Validation Acc:60.08\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:61.865,Validation Acc:60.44\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:61.54,Validation Acc:60.02\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:61.96,Validation Acc:60.32\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:61.895,Validation Acc:60.72\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:61.875,Validation Acc:60.14\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:62.085,Validation Acc:60.88\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:62.1,Validation Acc:60.36\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:61.79,Validation Acc:61.06\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:62.335,Validation Acc:61.0\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:62.435,Validation Acc:60.46\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:62.435,Validation Acc:60.56\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:62.43,Validation Acc:60.74\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:62.46,Validation Acc:61.32\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:62.705,Validation Acc:60.86\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:62.61,Validation Acc:60.78\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:62.37,Validation Acc:60.9\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:62.18,Validation Acc:61.38\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:62.89,Validation Acc:61.06\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 35 / 96\n",
      "Learning Rate = 0.1\n",
      "Ngram = 2\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 9508878\n",
      "Token id 97170 -> token is sexy\n",
      "Token is sexy -> token id 97170\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:60.805,Validation Acc:58.74\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:61.345,Validation Acc:60.28\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:59.92,Validation Acc:58.68\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:63.385,Validation Acc:61.54\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:63.03,Validation Acc:61.98\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:63.825,Validation Acc:61.36\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:64.945,Validation Acc:63.44\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:65.18,Validation Acc:62.6\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:65.545,Validation Acc:62.96\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:65.47,Validation Acc:64.36\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:65.92,Validation Acc:63.74\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:65.96,Validation Acc:64.36\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:66.125,Validation Acc:63.98\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:66.675,Validation Acc:64.84\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:66.675,Validation Acc:64.22\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:66.925,Validation Acc:64.78\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:67.14,Validation Acc:65.3\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:66.72,Validation Acc:64.64\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:66.185,Validation Acc:63.92\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:67.06,Validation Acc:64.74\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:67.19,Validation Acc:64.94\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:67.72,Validation Acc:65.9\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:67.975,Validation Acc:66.0\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:68.0,Validation Acc:65.7\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:67.56,Validation Acc:65.34\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:68.105,Validation Acc:65.98\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:67.31,Validation Acc:65.48\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:68.3,Validation Acc:66.54\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:68.415,Validation Acc:66.6\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:68.46,Validation Acc:66.36\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 36 / 96\n",
      "Learning Rate = 0.1\n",
      "Ngram = 2\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 9508878\n",
      "Token id 74448 -> token for first\n",
      "Token for first -> token id 74448\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:53.345,Validation Acc:53.22\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:57.655,Validation Acc:56.28\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:55.775,Validation Acc:55.52\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:60.845,Validation Acc:59.36\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:60.205,Validation Acc:58.44\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:62.295,Validation Acc:61.3\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:63.55,Validation Acc:61.52\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:63.32,Validation Acc:61.44\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:64.71,Validation Acc:63.42\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:64.905,Validation Acc:63.12\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:63.06,Validation Acc:61.16\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:65.26,Validation Acc:64.38\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:65.375,Validation Acc:63.42\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:65.52,Validation Acc:63.64\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:65.985,Validation Acc:64.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[3/5],Step:[101/157],Training Acc:66.135,Validation Acc:64.64\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:66.335,Validation Acc:64.96\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:66.38,Validation Acc:64.98\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:66.06,Validation Acc:64.36\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:66.53,Validation Acc:64.66\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:66.875,Validation Acc:65.38\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:66.98,Validation Acc:65.26\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:67.14,Validation Acc:65.48\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:66.93,Validation Acc:65.26\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:66.955,Validation Acc:65.92\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:67.4,Validation Acc:66.0\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:66.995,Validation Acc:65.44\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:67.725,Validation Acc:66.2\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:67.49,Validation Acc:65.96\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:67.4,Validation Acc:65.82\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 37 / 96\n",
      "Learning Rate = 0.1\n",
      "Ngram = 2\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 9508878\n",
      "Token id 378449 -> token life continues\n",
      "Token life continues -> token id 378449\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:53.705,Validation Acc:52.46\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:54.165,Validation Acc:54.1\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:56.49,Validation Acc:54.28\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:58.23,Validation Acc:56.5\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:57.67,Validation Acc:56.74\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:57.95,Validation Acc:55.2\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:59.275,Validation Acc:58.64\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:60.82,Validation Acc:58.66\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:60.99,Validation Acc:58.64\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:60.68,Validation Acc:58.6\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:61.055,Validation Acc:59.16\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:61.215,Validation Acc:59.26\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:61.485,Validation Acc:59.76\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:61.83,Validation Acc:60.0\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:61.47,Validation Acc:60.02\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:61.97,Validation Acc:60.32\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:62.05,Validation Acc:60.38\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:62.145,Validation Acc:60.24\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:62.12,Validation Acc:60.46\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:62.205,Validation Acc:60.56\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:61.785,Validation Acc:60.16\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:62.525,Validation Acc:60.7\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:62.74,Validation Acc:60.86\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:62.005,Validation Acc:60.96\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:62.46,Validation Acc:61.22\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:62.76,Validation Acc:61.6\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:62.605,Validation Acc:61.52\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:62.965,Validation Acc:61.34\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:62.68,Validation Acc:61.4\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:62.945,Validation Acc:61.66\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 38 / 96\n",
      "Learning Rate = 0.1\n",
      "Ngram = 2\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 9508878\n",
      "Token id 268179 -> token rickshaws\n",
      "Token rickshaws -> token id 268179\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:51.66,Validation Acc:51.46\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:54.12,Validation Acc:53.36\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:55.415,Validation Acc:55.74\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:57.975,Validation Acc:56.34\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:59.21,Validation Acc:56.74\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:60.085,Validation Acc:57.64\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:60.295,Validation Acc:57.58\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:60.97,Validation Acc:58.4\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:61.555,Validation Acc:60.36\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:61.665,Validation Acc:60.56\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:60.795,Validation Acc:57.98\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:62.255,Validation Acc:60.0\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:62.64,Validation Acc:60.52\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:62.485,Validation Acc:60.38\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:62.51,Validation Acc:60.24\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:62.62,Validation Acc:60.4\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:62.97,Validation Acc:61.3\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:63.28,Validation Acc:61.06\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:63.145,Validation Acc:61.08\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:63.275,Validation Acc:60.96\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:63.315,Validation Acc:60.82\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:63.72,Validation Acc:61.56\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:63.785,Validation Acc:61.5\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:63.725,Validation Acc:61.66\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:63.705,Validation Acc:61.94\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:64.045,Validation Acc:61.62\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:64.23,Validation Acc:61.7\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:64.385,Validation Acc:61.66\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:64.43,Validation Acc:62.06\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:64.485,Validation Acc:62.06\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 39 / 96\n",
      "Learning Rate = 0.1\n",
      "Ngram = 2\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 9508878\n",
      "Token id 629007 -> token bitterman barney\n",
      "Token bitterman barney -> token id 629007\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:57.67,Validation Acc:56.52\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:60.2,Validation Acc:58.8\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:61.97,Validation Acc:60.6\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:60.93,Validation Acc:59.5\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:62.755,Validation Acc:61.82\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:64.39,Validation Acc:63.14\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:64.925,Validation Acc:63.52\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:65.12,Validation Acc:63.86\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:65.025,Validation Acc:63.48\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:65.39,Validation Acc:64.36\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:66.05,Validation Acc:64.54\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:66.065,Validation Acc:65.18\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:66.42,Validation Acc:65.84\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:66.705,Validation Acc:65.32\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:66.57,Validation Acc:64.98\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:66.735,Validation Acc:65.76\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:66.97,Validation Acc:65.28\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:67.155,Validation Acc:65.9\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:67.215,Validation Acc:65.48\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:67.62,Validation Acc:66.6\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:67.395,Validation Acc:66.5\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:67.79,Validation Acc:66.28\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:67.84,Validation Acc:66.58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[4/5],Step:[301/313],Training Acc:67.85,Validation Acc:66.54\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:68.05,Validation Acc:66.6\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:68.045,Validation Acc:66.96\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:68.16,Validation Acc:66.98\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:68.18,Validation Acc:67.04\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:68.36,Validation Acc:67.14\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:68.485,Validation Acc:67.38\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 40 / 96\n",
      "Learning Rate = 0.1\n",
      "Ngram = 2\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 9508878\n",
      "Token id 585345 -> token other tepid\n",
      "Token other tepid -> token id 585345\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:57.995,Validation Acc:56.48\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:58.555,Validation Acc:58.32\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:61.585,Validation Acc:59.12\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:62.72,Validation Acc:60.92\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:63.225,Validation Acc:61.72\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:63.505,Validation Acc:62.2\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:63.86,Validation Acc:62.72\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:64.395,Validation Acc:62.3\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:64.36,Validation Acc:63.28\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:64.465,Validation Acc:63.72\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:64.74,Validation Acc:63.3\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:64.895,Validation Acc:63.94\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:64.92,Validation Acc:63.7\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:65.205,Validation Acc:64.26\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:65.34,Validation Acc:64.44\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:65.49,Validation Acc:64.58\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:65.44,Validation Acc:64.12\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:65.905,Validation Acc:64.84\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:65.93,Validation Acc:64.78\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:66.32,Validation Acc:65.02\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:66.365,Validation Acc:65.34\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:66.485,Validation Acc:65.32\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:66.545,Validation Acc:65.5\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:66.4,Validation Acc:65.34\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:66.81,Validation Acc:65.2\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:66.69,Validation Acc:65.82\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:67.15,Validation Acc:65.82\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:67.165,Validation Acc:65.86\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:67.14,Validation Acc:65.86\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:67.055,Validation Acc:66.0\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 41 / 96\n",
      "Learning Rate = 0.1\n",
      "Ngram = 3\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 14233317\n",
      "Token id 92833 -> token kind the\n",
      "Token kind the -> token id 92833\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:52.165,Validation Acc:52.22\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:53.88,Validation Acc:54.0\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:59.575,Validation Acc:58.12\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:58.63,Validation Acc:57.74\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:60.3,Validation Acc:59.0\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:59.3,Validation Acc:58.56\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:59.94,Validation Acc:59.56\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:62.215,Validation Acc:60.24\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:59.93,Validation Acc:59.26\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:62.255,Validation Acc:61.6\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:62.475,Validation Acc:61.54\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:62.315,Validation Acc:60.04\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:63.425,Validation Acc:61.8\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:62.265,Validation Acc:60.66\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:63.175,Validation Acc:61.4\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:62.93,Validation Acc:61.76\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:62.175,Validation Acc:60.54\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:63.725,Validation Acc:61.8\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:63.34,Validation Acc:61.48\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:64.2,Validation Acc:62.26\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:62.42,Validation Acc:60.78\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:63.79,Validation Acc:62.14\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:64.085,Validation Acc:62.32\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:63.63,Validation Acc:62.0\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:62.77,Validation Acc:61.96\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:63.5,Validation Acc:61.7\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:64.365,Validation Acc:62.56\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:64.43,Validation Acc:62.52\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:63.545,Validation Acc:61.5\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:64.525,Validation Acc:62.56\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 42 / 96\n",
      "Learning Rate = 0.1\n",
      "Ngram = 3\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 14233317\n",
      "Token id 39009 -> token structure of\n",
      "Token structure of -> token id 39009\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:51.06,Validation Acc:49.94\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:53.615,Validation Acc:52.54\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:55.5,Validation Acc:54.02\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:56.445,Validation Acc:54.72\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:55.715,Validation Acc:54.22\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:57.575,Validation Acc:55.56\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:58.765,Validation Acc:57.0\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:59.075,Validation Acc:57.02\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:59.25,Validation Acc:57.3\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:59.995,Validation Acc:58.44\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:59.86,Validation Acc:58.58\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:60.25,Validation Acc:59.06\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:60.505,Validation Acc:59.0\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:60.135,Validation Acc:59.02\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:60.89,Validation Acc:58.82\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:61.28,Validation Acc:59.8\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:61.325,Validation Acc:59.68\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:60.9,Validation Acc:59.26\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:60.0,Validation Acc:58.7\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:61.61,Validation Acc:59.96\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:61.77,Validation Acc:59.98\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:61.61,Validation Acc:60.14\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:62.055,Validation Acc:60.26\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:60.69,Validation Acc:59.36\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:62.115,Validation Acc:60.12\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:62.485,Validation Acc:60.42\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:62.13,Validation Acc:60.52\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:62.21,Validation Acc:60.3\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:61.905,Validation Acc:60.62\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:62.605,Validation Acc:60.66\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 43 / 96\n",
      "Learning Rate = 0.1\n",
      "Ngram = 3\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 14233317\n",
      "Token id 93738 -> token dialogue are\n",
      "Token dialogue are -> token id 93738\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:57.115,Validation Acc:55.4\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:57.8,Validation Acc:57.14\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:62.65,Validation Acc:61.5\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:62.5,Validation Acc:60.82\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:61.57,Validation Acc:59.9\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:63.34,Validation Acc:61.86\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:62.32,Validation Acc:61.28\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:64.165,Validation Acc:62.54\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:64.66,Validation Acc:62.98\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:64.71,Validation Acc:63.14\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:65.485,Validation Acc:64.32\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:65.78,Validation Acc:64.4\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:65.97,Validation Acc:64.58\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:66.36,Validation Acc:65.28\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:65.495,Validation Acc:63.94\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:66.595,Validation Acc:65.28\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:66.88,Validation Acc:65.74\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:66.705,Validation Acc:65.76\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:67.115,Validation Acc:65.88\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:66.515,Validation Acc:65.48\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:67.58,Validation Acc:66.5\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:67.75,Validation Acc:66.64\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:67.77,Validation Acc:66.84\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:66.465,Validation Acc:65.38\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:67.17,Validation Acc:66.44\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:67.905,Validation Acc:66.74\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:67.665,Validation Acc:66.84\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:68.315,Validation Acc:67.14\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:68.35,Validation Acc:67.2\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:68.485,Validation Acc:67.26\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 44 / 96\n",
      "Learning Rate = 0.1\n",
      "Ngram = 3\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 14233317\n",
      "Token id 11725 -> token works in\n",
      "Token works in -> token id 11725\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:53.59,Validation Acc:53.92\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:54.935,Validation Acc:55.36\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:59.045,Validation Acc:58.58\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:61.645,Validation Acc:59.82\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:60.675,Validation Acc:59.46\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:62.47,Validation Acc:61.6\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:61.885,Validation Acc:59.84\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:63.77,Validation Acc:62.24\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:63.6,Validation Acc:62.58\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:63.65,Validation Acc:62.66\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:63.72,Validation Acc:62.36\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:64.655,Validation Acc:63.18\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:65.02,Validation Acc:63.64\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:64.91,Validation Acc:63.72\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:64.98,Validation Acc:63.7\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:65.115,Validation Acc:63.7\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:65.19,Validation Acc:63.7\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:64.97,Validation Acc:63.36\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:65.495,Validation Acc:63.9\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:65.905,Validation Acc:64.22\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:64.51,Validation Acc:63.04\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:66.145,Validation Acc:64.34\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:66.185,Validation Acc:64.52\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:66.4,Validation Acc:64.52\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:66.41,Validation Acc:64.6\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:65.94,Validation Acc:64.12\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:66.565,Validation Acc:65.0\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:66.625,Validation Acc:64.68\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:66.645,Validation Acc:65.12\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:66.65,Validation Acc:65.0\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 45 / 96\n",
      "Learning Rate = 0.1\n",
      "Ngram = 3\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 14233317\n",
      "Token id 694670 -> token inexplicable behavior\n",
      "Token inexplicable behavior -> token id 694670\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:53.92,Validation Acc:52.22\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:57.64,Validation Acc:56.52\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:58.215,Validation Acc:57.0\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:60.03,Validation Acc:58.08\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:58.72,Validation Acc:56.1\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:61.255,Validation Acc:59.36\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:61.415,Validation Acc:59.22\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:61.855,Validation Acc:59.66\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:61.31,Validation Acc:58.94\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:62.18,Validation Acc:60.34\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:62.865,Validation Acc:60.88\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:63.005,Validation Acc:60.74\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:62.655,Validation Acc:60.56\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:62.84,Validation Acc:60.96\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:63.05,Validation Acc:61.18\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:63.41,Validation Acc:60.52\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:63.57,Validation Acc:61.08\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:63.48,Validation Acc:61.5\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:63.63,Validation Acc:60.92\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:63.97,Validation Acc:61.64\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:64.135,Validation Acc:61.64\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:64.19,Validation Acc:61.7\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:64.095,Validation Acc:61.68\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:64.315,Validation Acc:61.74\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:64.43,Validation Acc:61.74\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:64.435,Validation Acc:61.7\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:64.545,Validation Acc:61.56\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:64.695,Validation Acc:61.98\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:64.925,Validation Acc:61.88\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:64.935,Validation Acc:62.46\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 46 / 96\n",
      "Learning Rate = 0.1\n",
      "Ngram = 3\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 14233317\n",
      "Token id 573515 -> token be right to\n",
      "Token be right to -> token id 573515\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:50.255,Validation Acc:50.78\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:53.075,Validation Acc:52.88\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:55.62,Validation Acc:53.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[1/5],Step:[101/157],Training Acc:55.44,Validation Acc:55.08\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:57.645,Validation Acc:56.84\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:59.175,Validation Acc:57.4\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:60.41,Validation Acc:58.18\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:61.04,Validation Acc:59.06\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:60.22,Validation Acc:57.86\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:61.885,Validation Acc:59.6\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:59.73,Validation Acc:57.26\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:61.97,Validation Acc:60.82\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:61.345,Validation Acc:60.2\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:62.37,Validation Acc:59.62\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:62.3,Validation Acc:59.98\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:62.615,Validation Acc:60.24\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:62.465,Validation Acc:60.02\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:62.475,Validation Acc:60.16\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:62.405,Validation Acc:60.96\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:62.42,Validation Acc:59.76\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:62.325,Validation Acc:59.64\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:62.625,Validation Acc:61.0\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:62.385,Validation Acc:59.84\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:62.935,Validation Acc:60.64\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:62.68,Validation Acc:60.02\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:62.935,Validation Acc:60.56\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:63.115,Validation Acc:60.88\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:63.195,Validation Acc:60.82\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:63.175,Validation Acc:60.86\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:63.275,Validation Acc:60.92\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 47 / 96\n",
      "Learning Rate = 0.1\n",
      "Ngram = 3\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 14233317\n",
      "Token id 631702 -> token because this could\n",
      "Token because this could -> token id 631702\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:54.12,Validation Acc:53.04\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:60.955,Validation Acc:58.52\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:59.33,Validation Acc:58.06\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:63.36,Validation Acc:61.08\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:63.685,Validation Acc:61.48\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:63.315,Validation Acc:60.06\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:64.06,Validation Acc:61.56\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:64.64,Validation Acc:62.08\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:64.645,Validation Acc:62.88\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:64.685,Validation Acc:63.18\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:65.215,Validation Acc:63.24\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:65.615,Validation Acc:63.34\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:65.855,Validation Acc:63.0\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:65.94,Validation Acc:64.06\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:66.315,Validation Acc:64.5\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:66.67,Validation Acc:64.5\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:66.53,Validation Acc:63.46\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:66.36,Validation Acc:65.24\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:67.005,Validation Acc:64.5\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:67.185,Validation Acc:65.34\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:66.935,Validation Acc:64.14\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:67.495,Validation Acc:65.96\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:67.46,Validation Acc:65.48\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:67.625,Validation Acc:65.76\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:67.6,Validation Acc:65.68\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:67.525,Validation Acc:65.84\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:68.005,Validation Acc:66.46\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:67.36,Validation Acc:65.68\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:68.025,Validation Acc:66.34\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:68.26,Validation Acc:66.62\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 48 / 96\n",
      "Learning Rate = 0.1\n",
      "Ngram = 3\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 14233317\n",
      "Token id 345748 -> token not work at\n",
      "Token not work at -> token id 345748\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:54.91,Validation Acc:53.1\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:57.2,Validation Acc:56.1\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:58.34,Validation Acc:56.4\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:60.285,Validation Acc:58.6\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:59.645,Validation Acc:58.3\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:61.945,Validation Acc:59.82\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:62.035,Validation Acc:59.26\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:62.77,Validation Acc:59.98\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:62.805,Validation Acc:60.08\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:63.085,Validation Acc:60.08\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:63.415,Validation Acc:60.54\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:63.355,Validation Acc:61.76\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:63.78,Validation Acc:60.86\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:63.925,Validation Acc:60.88\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:63.995,Validation Acc:61.34\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:63.835,Validation Acc:62.32\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:64.005,Validation Acc:60.84\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:64.48,Validation Acc:61.22\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:64.63,Validation Acc:61.74\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:64.445,Validation Acc:61.38\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:64.705,Validation Acc:61.84\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:64.64,Validation Acc:61.9\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:64.79,Validation Acc:61.88\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:64.93,Validation Acc:62.26\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:64.955,Validation Acc:62.7\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:65.065,Validation Acc:62.9\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:65.115,Validation Acc:62.58\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:65.065,Validation Acc:62.0\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:65.345,Validation Acc:63.06\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:65.455,Validation Acc:62.7\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 49 / 96\n",
      "Learning Rate = 1\n",
      "Ngram = 1\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 4764439\n",
      "Token id 61303 -> token himmelen/\n",
      "Token himmelen/ -> token id 61303\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:62.81,Validation Acc:60.1\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:58.165,Validation Acc:57.48\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:65.22,Validation Acc:63.06\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:63.21,Validation Acc:61.92\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:63.49,Validation Acc:62.02\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:64.955,Validation Acc:63.44\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:62.575,Validation Acc:61.46\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:68.405,Validation Acc:66.44\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:68.65,Validation Acc:66.88\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:68.705,Validation Acc:66.92\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:68.905,Validation Acc:66.66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[2/5],Step:[301/313],Training Acc:69.565,Validation Acc:67.32\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:69.195,Validation Acc:67.8\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:68.98,Validation Acc:67.0\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:71.61,Validation Acc:69.64\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:67.05,Validation Acc:65.36\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:71.245,Validation Acc:69.24\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:72.58,Validation Acc:70.28\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:72.855,Validation Acc:71.08\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:72.055,Validation Acc:70.14\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:73.37,Validation Acc:70.9\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:73.3,Validation Acc:71.32\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:73.935,Validation Acc:71.82\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:74.2,Validation Acc:72.24\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:74.535,Validation Acc:72.5\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:74.745,Validation Acc:72.7\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:75.06,Validation Acc:72.64\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:74.93,Validation Acc:72.76\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:75.47,Validation Acc:73.18\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:75.52,Validation Acc:72.96\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 50 / 96\n",
      "Learning Rate = 1\n",
      "Ngram = 1\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 4764439\n",
      "Token id 16481 -> token grades\n",
      "Token grades -> token id 16481\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:59.355,Validation Acc:57.32\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:61.135,Validation Acc:60.56\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:64.89,Validation Acc:63.64\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:60.26,Validation Acc:60.98\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:66.15,Validation Acc:64.7\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:66.575,Validation Acc:65.22\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:67.075,Validation Acc:66.12\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:66.735,Validation Acc:65.06\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:67.455,Validation Acc:66.62\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:67.6,Validation Acc:66.9\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:67.905,Validation Acc:66.76\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:67.325,Validation Acc:66.36\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:68.505,Validation Acc:67.42\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:68.83,Validation Acc:67.84\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:68.38,Validation Acc:67.74\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:69.21,Validation Acc:68.24\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:68.19,Validation Acc:66.7\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:69.79,Validation Acc:68.32\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:69.96,Validation Acc:68.54\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:70.29,Validation Acc:68.78\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:70.03,Validation Acc:68.24\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:70.655,Validation Acc:68.84\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:69.975,Validation Acc:68.26\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:69.055,Validation Acc:67.8\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:71.38,Validation Acc:69.52\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:68.73,Validation Acc:67.96\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:71.37,Validation Acc:69.66\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:71.91,Validation Acc:69.78\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:71.745,Validation Acc:70.46\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:72.245,Validation Acc:70.32\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 51 / 96\n",
      "Learning Rate = 1\n",
      "Ngram = 1\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 4764439\n",
      "Token id 12145 -> token incomplete\n",
      "Token incomplete -> token id 12145\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:65.33,Validation Acc:64.58\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:67.385,Validation Acc:65.88\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:67.86,Validation Acc:66.04\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:68.14,Validation Acc:66.24\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:70.69,Validation Acc:70.04\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:69.135,Validation Acc:68.02\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:71.175,Validation Acc:70.2\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:68.81,Validation Acc:67.5\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:68.095,Validation Acc:67.0\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:73.29,Validation Acc:72.6\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:73.615,Validation Acc:73.02\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:72.89,Validation Acc:71.7\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:73.845,Validation Acc:72.74\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:73.56,Validation Acc:72.52\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:71.455,Validation Acc:69.68\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:75.16,Validation Acc:74.14\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:74.14,Validation Acc:73.0\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:75.62,Validation Acc:75.08\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:75.91,Validation Acc:75.1\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:75.785,Validation Acc:74.36\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:76.245,Validation Acc:75.22\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:72.765,Validation Acc:71.16\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:74.76,Validation Acc:73.16\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:75.64,Validation Acc:74.36\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:76.915,Validation Acc:75.34\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:77.325,Validation Acc:76.12\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:76.675,Validation Acc:74.96\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:77.81,Validation Acc:76.42\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:76.9,Validation Acc:74.9\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:76.21,Validation Acc:75.06\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 52 / 96\n",
      "Learning Rate = 1\n",
      "Ngram = 1\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 4764439\n",
      "Token id 68720 -> token agusti\n",
      "Token agusti -> token id 68720\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:63.88,Validation Acc:62.5\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:63.435,Validation Acc:62.44\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:68.085,Validation Acc:65.54\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:68.945,Validation Acc:67.22\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:65.73,Validation Acc:63.12\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:69.69,Validation Acc:67.8\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:68.835,Validation Acc:67.08\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:70.455,Validation Acc:67.88\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:69.045,Validation Acc:67.34\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:69.36,Validation Acc:67.82\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:71.18,Validation Acc:67.94\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:71.135,Validation Acc:69.14\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:71.975,Validation Acc:69.52\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:69.99,Validation Acc:67.38\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:71.335,Validation Acc:68.22\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:72.435,Validation Acc:68.82\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:72.965,Validation Acc:70.34\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:73.1,Validation Acc:69.6\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:73.345,Validation Acc:70.22\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:71.04,Validation Acc:69.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[4/5],Step:[76/157],Training Acc:73.15,Validation Acc:69.42\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:73.69,Validation Acc:70.18\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:71.8,Validation Acc:68.12\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:71.015,Validation Acc:69.82\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:74.215,Validation Acc:71.94\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:72.755,Validation Acc:68.6\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:74.225,Validation Acc:72.2\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:73.85,Validation Acc:69.88\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:74.625,Validation Acc:72.32\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:74.86,Validation Acc:71.2\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 53 / 96\n",
      "Learning Rate = 1\n",
      "Ngram = 1\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 4764439\n",
      "Token id 68638 -> token weasing\n",
      "Token weasing -> token id 68638\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:60.41,Validation Acc:58.94\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:64.825,Validation Acc:63.12\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:65.265,Validation Acc:63.24\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:66.865,Validation Acc:64.64\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:67.12,Validation Acc:65.58\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:67.185,Validation Acc:65.38\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:67.455,Validation Acc:66.04\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:68.575,Validation Acc:67.16\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:69.39,Validation Acc:68.18\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:69.295,Validation Acc:67.68\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:69.75,Validation Acc:68.16\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:69.835,Validation Acc:68.12\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:68.665,Validation Acc:67.26\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:71.195,Validation Acc:69.44\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:71.31,Validation Acc:69.88\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:72.04,Validation Acc:70.64\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:72.34,Validation Acc:70.56\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:72.08,Validation Acc:71.12\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:72.425,Validation Acc:70.98\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:73.32,Validation Acc:71.94\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:72.535,Validation Acc:70.8\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:73.36,Validation Acc:72.1\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:72.305,Validation Acc:71.62\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:71.91,Validation Acc:71.04\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:73.94,Validation Acc:73.06\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:74.63,Validation Acc:72.82\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:74.945,Validation Acc:73.76\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:74.305,Validation Acc:72.48\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:75.415,Validation Acc:74.02\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:75.7,Validation Acc:74.52\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 54 / 96\n",
      "Learning Rate = 1\n",
      "Ngram = 1\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 4764439\n",
      "Token id 52488 -> token tableware\n",
      "Token tableware -> token id 52488\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:57.185,Validation Acc:56.4\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:61.78,Validation Acc:60.26\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:64.975,Validation Acc:63.2\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:65.67,Validation Acc:63.3\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:64.66,Validation Acc:62.88\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:63.87,Validation Acc:62.48\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:66.675,Validation Acc:64.24\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:66.315,Validation Acc:64.62\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:65.82,Validation Acc:63.8\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:67.875,Validation Acc:65.5\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:66.0,Validation Acc:64.24\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:67.485,Validation Acc:65.16\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:68.425,Validation Acc:65.88\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:68.295,Validation Acc:66.06\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:68.11,Validation Acc:65.94\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:69.12,Validation Acc:66.64\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:69.405,Validation Acc:66.98\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:68.725,Validation Acc:67.0\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:69.745,Validation Acc:67.76\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:69.345,Validation Acc:66.58\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:69.72,Validation Acc:67.82\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:70.07,Validation Acc:67.94\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:69.975,Validation Acc:67.66\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:70.725,Validation Acc:68.86\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:70.72,Validation Acc:68.64\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:70.98,Validation Acc:69.22\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:70.095,Validation Acc:67.78\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:71.145,Validation Acc:69.18\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:71.305,Validation Acc:69.44\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:71.555,Validation Acc:69.84\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 55 / 96\n",
      "Learning Rate = 1\n",
      "Ngram = 1\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 4764439\n",
      "Token id 8703 -> token tina\n",
      "Token tina -> token id 8703\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:51.985,Validation Acc:52.38\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:66.5,Validation Acc:65.68\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:65.925,Validation Acc:65.72\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:69.64,Validation Acc:67.92\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:62.54,Validation Acc:60.38\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:70.64,Validation Acc:68.88\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:71.26,Validation Acc:69.06\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:70.51,Validation Acc:68.78\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:71.835,Validation Acc:69.96\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:72.685,Validation Acc:71.02\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:72.785,Validation Acc:70.68\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:73.425,Validation Acc:70.94\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:72.325,Validation Acc:71.06\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:73.8,Validation Acc:71.86\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:73.655,Validation Acc:71.54\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:73.675,Validation Acc:71.56\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:73.905,Validation Acc:71.64\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:75.015,Validation Acc:73.04\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:75.405,Validation Acc:73.56\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:75.635,Validation Acc:73.76\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:72.73,Validation Acc:71.4\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:76.055,Validation Acc:74.18\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:76.6,Validation Acc:74.76\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:76.755,Validation Acc:74.98\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:76.28,Validation Acc:73.94\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:77.095,Validation Acc:75.1\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:77.445,Validation Acc:75.08\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:76.565,Validation Acc:74.12\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:77.56,Validation Acc:75.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[5/5],Step:[301/313],Training Acc:77.735,Validation Acc:75.66\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 56 / 96\n",
      "Learning Rate = 1\n",
      "Ngram = 1\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 4764439\n",
      "Token id 38097 -> token frizzy\n",
      "Token frizzy -> token id 38097\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:63.775,Validation Acc:62.72\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:67.71,Validation Acc:66.48\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:69.34,Validation Acc:67.56\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:70.285,Validation Acc:68.46\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:67.23,Validation Acc:65.86\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:70.625,Validation Acc:68.58\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:71.695,Validation Acc:69.22\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:68.995,Validation Acc:67.64\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:70.815,Validation Acc:69.8\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:70.87,Validation Acc:69.2\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:70.73,Validation Acc:69.38\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:72.63,Validation Acc:70.8\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:72.055,Validation Acc:70.82\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:69.735,Validation Acc:68.28\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:72.24,Validation Acc:70.68\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:73.35,Validation Acc:71.46\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:72.95,Validation Acc:71.24\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:74.34,Validation Acc:72.6\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:74.315,Validation Acc:72.74\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:74.215,Validation Acc:72.48\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:74.85,Validation Acc:72.74\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:72.565,Validation Acc:71.18\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:75.18,Validation Acc:73.12\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:74.795,Validation Acc:72.72\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:73.79,Validation Acc:72.22\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:75.25,Validation Acc:73.12\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:75.27,Validation Acc:73.6\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:75.335,Validation Acc:73.46\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:75.58,Validation Acc:73.42\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:74.33,Validation Acc:73.0\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 57 / 96\n",
      "Learning Rate = 1\n",
      "Ngram = 2\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 9508878\n",
      "Token id 98865 -> token any special\n",
      "Token any special -> token id 98865\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:50.35,Validation Acc:50.0\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:62.775,Validation Acc:60.56\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:64.15,Validation Acc:62.44\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:67.025,Validation Acc:65.24\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:63.545,Validation Acc:62.94\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:65.975,Validation Acc:64.18\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:62.415,Validation Acc:60.94\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:65.815,Validation Acc:64.0\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:68.92,Validation Acc:67.44\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:68.44,Validation Acc:66.7\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:68.32,Validation Acc:67.0\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:70.655,Validation Acc:68.98\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:71.1,Validation Acc:69.2\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:66.68,Validation Acc:65.24\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:71.535,Validation Acc:70.3\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:72.005,Validation Acc:70.28\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:70.89,Validation Acc:69.72\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:72.68,Validation Acc:71.08\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:71.82,Validation Acc:70.18\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:71.23,Validation Acc:68.94\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:73.18,Validation Acc:71.68\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:71.06,Validation Acc:69.66\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:72.01,Validation Acc:70.26\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:73.89,Validation Acc:72.12\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:72.86,Validation Acc:71.2\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:67.675,Validation Acc:66.1\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:74.535,Validation Acc:72.52\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:74.02,Validation Acc:72.82\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:74.705,Validation Acc:73.44\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:73.025,Validation Acc:71.3\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 58 / 96\n",
      "Learning Rate = 1\n",
      "Ngram = 2\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 9508878\n",
      "Token id 29055 -> token attributes\n",
      "Token attributes -> token id 29055\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:60.22,Validation Acc:59.2\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:61.835,Validation Acc:61.14\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:57.475,Validation Acc:57.24\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:62.445,Validation Acc:61.34\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:63.2,Validation Acc:61.72\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:63.615,Validation Acc:62.04\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:61.905,Validation Acc:61.26\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:64.44,Validation Acc:63.02\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:63.41,Validation Acc:63.38\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:64.9,Validation Acc:64.44\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:65.69,Validation Acc:64.58\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:59.9,Validation Acc:58.56\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:65.8,Validation Acc:65.36\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:65.815,Validation Acc:65.52\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:64.69,Validation Acc:63.92\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:66.49,Validation Acc:65.04\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:66.36,Validation Acc:65.12\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:66.065,Validation Acc:65.4\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:67.03,Validation Acc:66.94\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:67.705,Validation Acc:67.46\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:63.665,Validation Acc:62.74\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:68.225,Validation Acc:67.52\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:68.22,Validation Acc:67.68\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:68.62,Validation Acc:67.88\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:68.525,Validation Acc:67.38\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:67.74,Validation Acc:66.82\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:68.2,Validation Acc:67.76\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:65.515,Validation Acc:64.52\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:68.875,Validation Acc:68.24\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:68.29,Validation Acc:67.1\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 59 / 96\n",
      "Learning Rate = 1\n",
      "Ngram = 2\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 9508878\n",
      "Token id 63721 -> token teal'c\n",
      "Token teal'c -> token id 63721\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[1/5],Step:[51/313],Training Acc:60.51,Validation Acc:59.58\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:57.63,Validation Acc:56.8\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:55.555,Validation Acc:55.0\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:67.745,Validation Acc:66.0\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:68.68,Validation Acc:67.42\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:68.91,Validation Acc:67.42\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:67.935,Validation Acc:66.48\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:70.385,Validation Acc:68.76\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:70.55,Validation Acc:69.82\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:70.855,Validation Acc:69.8\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:67.53,Validation Acc:65.88\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:71.155,Validation Acc:69.72\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:72.165,Validation Acc:71.16\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:69.415,Validation Acc:67.44\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:71.81,Validation Acc:69.68\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:72.76,Validation Acc:71.26\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:72.91,Validation Acc:71.26\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:71.235,Validation Acc:69.72\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:73.89,Validation Acc:72.92\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:72.405,Validation Acc:70.9\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:70.475,Validation Acc:68.52\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:73.255,Validation Acc:71.46\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:74.3,Validation Acc:72.62\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:70.25,Validation Acc:68.72\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:71.765,Validation Acc:70.54\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:75.08,Validation Acc:72.82\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:73.665,Validation Acc:72.08\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:75.135,Validation Acc:73.58\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:73.82,Validation Acc:72.32\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:75.37,Validation Acc:73.9\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 60 / 96\n",
      "Learning Rate = 1\n",
      "Ngram = 2\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 9508878\n",
      "Token id 19411 -> token a boat\n",
      "Token a boat -> token id 19411\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:63.95,Validation Acc:62.34\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:60.03,Validation Acc:58.36\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:64.935,Validation Acc:64.44\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:65.795,Validation Acc:64.96\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:67.94,Validation Acc:66.84\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:67.465,Validation Acc:65.96\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:69.175,Validation Acc:68.16\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:68.765,Validation Acc:67.22\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:69.905,Validation Acc:68.52\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:65.74,Validation Acc:64.3\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:69.615,Validation Acc:68.54\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:69.725,Validation Acc:68.68\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:66.615,Validation Acc:65.12\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:70.74,Validation Acc:69.84\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:69.57,Validation Acc:68.68\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:70.38,Validation Acc:69.16\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:70.465,Validation Acc:69.42\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:71.595,Validation Acc:69.96\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:71.54,Validation Acc:70.34\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:68.05,Validation Acc:66.66\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:72.38,Validation Acc:71.2\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:68.795,Validation Acc:67.84\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:72.635,Validation Acc:71.56\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:69.195,Validation Acc:67.82\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:72.145,Validation Acc:71.42\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:70.975,Validation Acc:69.76\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:73.185,Validation Acc:71.54\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:70.255,Validation Acc:69.06\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:72.895,Validation Acc:71.72\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:71.68,Validation Acc:70.74\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 61 / 96\n",
      "Learning Rate = 1\n",
      "Ngram = 2\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 9508878\n",
      "Token id 592392 -> token with grendel\n",
      "Token with grendel -> token id 592392\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:58.76,Validation Acc:57.5\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:59.34,Validation Acc:57.58\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:61.685,Validation Acc:61.6\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:59.575,Validation Acc:58.52\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:64.365,Validation Acc:62.6\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:64.825,Validation Acc:63.78\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:64.81,Validation Acc:63.9\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:66.085,Validation Acc:63.78\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:65.87,Validation Acc:65.08\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:66.07,Validation Acc:64.24\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:64.295,Validation Acc:62.72\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:67.835,Validation Acc:66.4\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:65.68,Validation Acc:64.58\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:68.44,Validation Acc:67.28\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:69.1,Validation Acc:67.66\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:68.59,Validation Acc:67.54\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:69.8,Validation Acc:68.1\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:70.45,Validation Acc:68.72\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:70.2,Validation Acc:68.16\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:70.235,Validation Acc:68.72\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:67.76,Validation Acc:66.1\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:71.095,Validation Acc:69.6\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:69.405,Validation Acc:68.16\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:71.68,Validation Acc:70.14\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:72.575,Validation Acc:71.12\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:72.74,Validation Acc:70.32\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:71.365,Validation Acc:69.9\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:73.205,Validation Acc:72.1\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:71.315,Validation Acc:69.7\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:73.2,Validation Acc:71.46\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 62 / 96\n",
      "Learning Rate = 1\n",
      "Ngram = 2\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 9508878\n",
      "Token id 730093 -> token expert talking\n",
      "Token expert talking -> token id 730093\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:62.295,Validation Acc:61.34\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:62.39,Validation Acc:60.8\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:62.72,Validation Acc:61.24\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:63.16,Validation Acc:62.24\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:64.28,Validation Acc:63.1\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:64.81,Validation Acc:63.44\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:64.65,Validation Acc:63.96\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:65.05,Validation Acc:63.94\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:65.705,Validation Acc:65.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[2/5],Step:[101/157],Training Acc:65.685,Validation Acc:64.96\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:65.46,Validation Acc:63.68\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:66.33,Validation Acc:65.5\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:66.575,Validation Acc:65.9\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:66.22,Validation Acc:65.16\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:66.125,Validation Acc:65.12\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:66.425,Validation Acc:65.42\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:67.27,Validation Acc:66.64\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:67.455,Validation Acc:66.7\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:67.67,Validation Acc:66.96\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:67.14,Validation Acc:66.26\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:67.655,Validation Acc:67.12\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:68.045,Validation Acc:67.18\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:68.175,Validation Acc:67.26\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:67.675,Validation Acc:66.56\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:68.535,Validation Acc:67.84\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:68.64,Validation Acc:67.92\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:68.82,Validation Acc:67.84\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:65.95,Validation Acc:64.58\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:69.13,Validation Acc:68.12\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:68.11,Validation Acc:66.72\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 63 / 96\n",
      "Learning Rate = 1\n",
      "Ngram = 2\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 9508878\n",
      "Token id 960745 -> token hofeus offer\n",
      "Token hofeus offer -> token id 960745\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:61.61,Validation Acc:59.66\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:65.61,Validation Acc:64.32\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:66.53,Validation Acc:64.76\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:67.72,Validation Acc:66.42\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:64.47,Validation Acc:63.32\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:65.61,Validation Acc:65.04\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:69.13,Validation Acc:67.56\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:70.175,Validation Acc:68.88\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:70.415,Validation Acc:68.62\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:70.575,Validation Acc:69.02\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:71.305,Validation Acc:69.12\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:69.85,Validation Acc:68.96\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:71.81,Validation Acc:70.68\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:72.02,Validation Acc:71.2\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:72.505,Validation Acc:70.88\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:72.305,Validation Acc:70.74\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:71.915,Validation Acc:70.84\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:73.205,Validation Acc:72.14\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:73.525,Validation Acc:72.14\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:71.465,Validation Acc:71.02\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:72.08,Validation Acc:70.76\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:73.02,Validation Acc:71.18\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:73.78,Validation Acc:72.7\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:74.71,Validation Acc:73.56\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:72.875,Validation Acc:70.98\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:75.005,Validation Acc:73.56\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:73.78,Validation Acc:72.38\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:75.705,Validation Acc:74.2\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:75.745,Validation Acc:74.4\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:74.19,Validation Acc:72.16\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 64 / 96\n",
      "Learning Rate = 1\n",
      "Ngram = 2\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 9508878\n",
      "Token id 155214 -> token hardly but\n",
      "Token hardly but -> token id 155214\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:59.9,Validation Acc:59.02\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:64.065,Validation Acc:61.74\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:64.815,Validation Acc:62.82\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:66.135,Validation Acc:64.38\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:65.995,Validation Acc:63.38\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:67.185,Validation Acc:64.8\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:67.69,Validation Acc:65.62\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:67.935,Validation Acc:65.86\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:66.44,Validation Acc:64.96\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:68.58,Validation Acc:66.02\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:68.2,Validation Acc:65.62\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:67.73,Validation Acc:66.34\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:68.27,Validation Acc:67.04\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:69.55,Validation Acc:67.86\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:69.575,Validation Acc:68.46\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:68.97,Validation Acc:66.68\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:67.49,Validation Acc:66.3\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:69.365,Validation Acc:66.86\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:70.345,Validation Acc:68.62\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:70.705,Validation Acc:68.48\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:69.515,Validation Acc:68.04\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:70.375,Validation Acc:68.88\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:71.335,Validation Acc:69.36\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:71.22,Validation Acc:68.76\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:71.165,Validation Acc:69.66\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:71.01,Validation Acc:69.44\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:71.67,Validation Acc:69.58\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:71.875,Validation Acc:70.08\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:71.265,Validation Acc:68.78\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:71.255,Validation Acc:69.22\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 65 / 96\n",
      "Learning Rate = 1\n",
      "Ngram = 3\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 14233317\n",
      "Token id 18617 -> token looking for the\n",
      "Token looking for the -> token id 18617\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:61.625,Validation Acc:59.64\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:53.97,Validation Acc:53.92\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:56.45,Validation Acc:55.92\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:60.365,Validation Acc:59.58\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:64.37,Validation Acc:62.38\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:63.675,Validation Acc:62.72\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:65.155,Validation Acc:63.46\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:67.89,Validation Acc:65.28\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:68.15,Validation Acc:66.2\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:59.11,Validation Acc:59.02\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:66.725,Validation Acc:64.62\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:69.135,Validation Acc:66.8\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:67.865,Validation Acc:67.22\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:68.865,Validation Acc:67.74\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:68.29,Validation Acc:67.3\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:69.7,Validation Acc:68.3\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:69.87,Validation Acc:69.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[3/5],Step:[301/313],Training Acc:64.62,Validation Acc:63.42\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:70.835,Validation Acc:70.04\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:70.295,Validation Acc:69.0\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:67.29,Validation Acc:65.82\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:72.135,Validation Acc:70.12\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:70.79,Validation Acc:69.48\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:72.3,Validation Acc:70.26\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:66.98,Validation Acc:66.44\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:71.945,Validation Acc:71.08\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:71.93,Validation Acc:69.48\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:71.42,Validation Acc:69.18\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:73.65,Validation Acc:71.48\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:73.705,Validation Acc:71.92\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 66 / 96\n",
      "Learning Rate = 1\n",
      "Ngram = 3\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 14233317\n",
      "Token id 20027 -> token better for\n",
      "Token better for -> token id 20027\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:55.74,Validation Acc:54.34\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:53.225,Validation Acc:52.78\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:57.095,Validation Acc:56.26\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:62.69,Validation Acc:61.32\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:62.285,Validation Acc:60.74\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:60.4,Validation Acc:58.9\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:63.41,Validation Acc:61.66\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:61.09,Validation Acc:59.56\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:58.92,Validation Acc:58.42\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:64.45,Validation Acc:62.88\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:60.825,Validation Acc:59.8\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:64.62,Validation Acc:62.86\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:64.33,Validation Acc:62.52\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:60.45,Validation Acc:59.98\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:65.895,Validation Acc:64.02\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:60.64,Validation Acc:60.02\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:64.235,Validation Acc:62.8\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:65.99,Validation Acc:64.9\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:60.89,Validation Acc:59.96\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:62.495,Validation Acc:61.24\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:66.635,Validation Acc:64.8\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:64.62,Validation Acc:63.22\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:62.385,Validation Acc:61.28\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:61.11,Validation Acc:60.0\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:65.47,Validation Acc:63.64\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:67.0,Validation Acc:64.82\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:68.01,Validation Acc:66.38\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:67.205,Validation Acc:65.38\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:66.88,Validation Acc:65.16\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:63.58,Validation Acc:62.4\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 67 / 96\n",
      "Learning Rate = 1\n",
      "Ngram = 3\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 14233317\n",
      "Token id 11379 -> token charming and\n",
      "Token charming and -> token id 11379\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:64.355,Validation Acc:62.6\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:52.765,Validation Acc:52.72\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:60.875,Validation Acc:59.36\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:65.12,Validation Acc:64.32\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:68.635,Validation Acc:66.82\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:57.565,Validation Acc:56.12\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:69.975,Validation Acc:68.18\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:67.86,Validation Acc:65.98\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:66.67,Validation Acc:66.08\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:71.645,Validation Acc:70.08\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:64.845,Validation Acc:63.7\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:70.215,Validation Acc:68.82\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:67.775,Validation Acc:66.42\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:70.125,Validation Acc:68.36\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:71.985,Validation Acc:71.02\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:68.6,Validation Acc:67.3\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:73.96,Validation Acc:72.24\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:67.815,Validation Acc:66.5\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:74.125,Validation Acc:72.2\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:74.075,Validation Acc:71.8\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:69.475,Validation Acc:67.52\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:72.93,Validation Acc:70.68\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:70.66,Validation Acc:68.52\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:73.05,Validation Acc:71.86\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:75.71,Validation Acc:73.84\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:74.12,Validation Acc:72.76\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:75.885,Validation Acc:73.94\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:73.12,Validation Acc:71.26\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:75.915,Validation Acc:73.92\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:76.05,Validation Acc:75.1\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 68 / 96\n",
      "Learning Rate = 1\n",
      "Ngram = 3\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 14233317\n",
      "Token id 96113 -> token celestine prophecy\n",
      "Token celestine prophecy -> token id 96113\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:50.145,Validation Acc:49.96\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:50.345,Validation Acc:50.46\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:57.955,Validation Acc:56.2\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:61.025,Validation Acc:59.56\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:56.82,Validation Acc:56.0\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:63.14,Validation Acc:62.32\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:65.145,Validation Acc:63.94\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:60.63,Validation Acc:60.12\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:68.2,Validation Acc:66.06\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:60.625,Validation Acc:59.36\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:66.695,Validation Acc:65.24\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:68.905,Validation Acc:66.96\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:70.33,Validation Acc:67.76\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:65.62,Validation Acc:64.22\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:66.99,Validation Acc:65.4\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:68.22,Validation Acc:66.66\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:71.065,Validation Acc:68.6\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:69.27,Validation Acc:67.7\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:71.205,Validation Acc:69.72\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:71.635,Validation Acc:69.2\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:67.51,Validation Acc:65.94\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:69.73,Validation Acc:67.18\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:71.575,Validation Acc:69.26\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:66.255,Validation Acc:65.24\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:71.785,Validation Acc:69.62\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:71.29,Validation Acc:69.46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[5/5],Step:[76/157],Training Acc:70.595,Validation Acc:69.06\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:72.17,Validation Acc:69.9\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:72.77,Validation Acc:70.38\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:72.4,Validation Acc:70.54\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 69 / 96\n",
      "Learning Rate = 1\n",
      "Ngram = 3\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 14233317\n",
      "Token id 866805 -> token share of clunkers\n",
      "Token share of clunkers -> token id 866805\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:61.54,Validation Acc:59.62\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:63.44,Validation Acc:61.4\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:60.845,Validation Acc:58.66\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:64.215,Validation Acc:61.72\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:61.74,Validation Acc:60.14\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:64.86,Validation Acc:63.26\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:65.62,Validation Acc:62.86\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:66.865,Validation Acc:65.16\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:66.815,Validation Acc:64.48\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:66.985,Validation Acc:65.08\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:67.975,Validation Acc:66.4\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:67.845,Validation Acc:66.26\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:68.17,Validation Acc:66.64\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:68.86,Validation Acc:67.68\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:66.805,Validation Acc:65.62\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:69.35,Validation Acc:68.02\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:69.1,Validation Acc:68.46\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:69.8,Validation Acc:68.94\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:70.25,Validation Acc:69.06\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:70.615,Validation Acc:69.24\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:70.88,Validation Acc:69.38\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:71.155,Validation Acc:69.84\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:69.285,Validation Acc:66.34\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:70.29,Validation Acc:68.26\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:72.24,Validation Acc:70.96\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:72.605,Validation Acc:70.28\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:72.355,Validation Acc:70.98\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:72.625,Validation Acc:70.38\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:72.975,Validation Acc:70.96\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:70.01,Validation Acc:67.7\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 70 / 96\n",
      "Learning Rate = 1\n",
      "Ngram = 3\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 14233317\n",
      "Token id 8293 -> token endearing\n",
      "Token endearing -> token id 8293\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:51.375,Validation Acc:50.86\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:58.795,Validation Acc:57.82\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:62.84,Validation Acc:61.14\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:62.49,Validation Acc:60.02\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:63.89,Validation Acc:62.0\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:62.575,Validation Acc:60.62\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:63.855,Validation Acc:61.94\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:61.46,Validation Acc:59.04\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:65.19,Validation Acc:63.14\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:65.31,Validation Acc:63.66\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:63.985,Validation Acc:62.4\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:65.73,Validation Acc:64.18\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:64.775,Validation Acc:63.0\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:66.27,Validation Acc:64.76\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:66.41,Validation Acc:64.72\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:65.51,Validation Acc:63.84\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:66.955,Validation Acc:65.42\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:67.145,Validation Acc:65.74\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:66.55,Validation Acc:64.24\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:67.665,Validation Acc:65.88\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:67.475,Validation Acc:65.94\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:67.89,Validation Acc:66.36\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:68.22,Validation Acc:66.5\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:68.195,Validation Acc:66.02\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:68.59,Validation Acc:66.88\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:68.405,Validation Acc:66.2\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:68.65,Validation Acc:67.04\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:68.86,Validation Acc:66.94\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:68.95,Validation Acc:66.98\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:68.02,Validation Acc:66.34\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 71 / 96\n",
      "Learning Rate = 1\n",
      "Ngram = 3\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 14233317\n",
      "Token id 139695 -> token tracked down\n",
      "Token tracked down -> token id 139695\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:63.135,Validation Acc:62.28\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:65.215,Validation Acc:61.62\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:58.915,Validation Acc:58.88\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:68.91,Validation Acc:66.68\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:69.69,Validation Acc:67.44\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:66.64,Validation Acc:65.48\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:70.19,Validation Acc:68.48\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:71.075,Validation Acc:69.7\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:70.815,Validation Acc:69.24\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:68.865,Validation Acc:67.68\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:71.715,Validation Acc:70.16\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:71.96,Validation Acc:70.54\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:71.555,Validation Acc:69.7\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:72.975,Validation Acc:71.34\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:72.685,Validation Acc:70.88\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:72.41,Validation Acc:70.02\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:73.105,Validation Acc:71.76\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:66.515,Validation Acc:63.46\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:73.555,Validation Acc:71.64\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:72.12,Validation Acc:70.54\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:74.2,Validation Acc:72.7\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:74.405,Validation Acc:72.6\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:74.175,Validation Acc:72.74\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:73.64,Validation Acc:71.26\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:74.035,Validation Acc:72.28\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:75.39,Validation Acc:73.86\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:75.67,Validation Acc:73.54\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:75.64,Validation Acc:73.96\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:74.325,Validation Acc:71.6\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:75.885,Validation Acc:73.68\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 72 / 96\n",
      "Learning Rate = 1\n",
      "Ngram = 3\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens in train dataset is 14233317\n",
      "Token id 526082 -> token profanity female nudity\n",
      "Token profanity female nudity -> token id 526082\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:58.47,Validation Acc:56.12\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:57.32,Validation Acc:57.88\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:65.295,Validation Acc:63.8\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:61.395,Validation Acc:60.78\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:66.32,Validation Acc:65.0\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:66.815,Validation Acc:65.8\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:68.38,Validation Acc:66.9\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:65.545,Validation Acc:65.04\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:68.79,Validation Acc:67.96\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:68.97,Validation Acc:67.4\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:69.6,Validation Acc:68.72\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:68.035,Validation Acc:66.98\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:69.68,Validation Acc:68.24\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:70.205,Validation Acc:68.78\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:70.005,Validation Acc:69.62\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:70.18,Validation Acc:68.86\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:70.49,Validation Acc:69.72\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:70.83,Validation Acc:69.82\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:70.655,Validation Acc:69.54\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:70.975,Validation Acc:70.18\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:69.31,Validation Acc:68.14\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:70.615,Validation Acc:68.9\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:71.44,Validation Acc:69.84\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:70.105,Validation Acc:69.32\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:71.43,Validation Acc:69.9\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:70.12,Validation Acc:68.16\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:72.05,Validation Acc:71.06\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:72.155,Validation Acc:70.78\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:71.995,Validation Acc:70.52\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:71.53,Validation Acc:70.16\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 73 / 96\n",
      "Learning Rate = 2\n",
      "Ngram = 1\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 4764439\n",
      "Token id 13773 -> token visiteurs\n",
      "Token visiteurs -> token id 13773\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 2\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:51.62,Validation Acc:51.4\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:64.735,Validation Acc:63.64\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:66.32,Validation Acc:64.94\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:70.085,Validation Acc:68.06\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:58.34,Validation Acc:57.62\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:63.325,Validation Acc:62.38\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:70.62,Validation Acc:69.0\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:70.495,Validation Acc:68.86\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:69.065,Validation Acc:68.28\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:70.99,Validation Acc:70.02\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:71.845,Validation Acc:70.8\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:73.04,Validation Acc:70.68\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:75.38,Validation Acc:74.5\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:75.205,Validation Acc:72.46\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:74.96,Validation Acc:72.14\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:73.55,Validation Acc:71.12\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:75.615,Validation Acc:74.28\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:74.33,Validation Acc:71.42\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:78.045,Validation Acc:76.0\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:77.905,Validation Acc:76.02\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:78.44,Validation Acc:76.72\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:78.035,Validation Acc:75.42\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:78.73,Validation Acc:76.68\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:78.855,Validation Acc:76.76\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:77.28,Validation Acc:74.14\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:78.765,Validation Acc:76.92\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:79.52,Validation Acc:77.26\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:78.03,Validation Acc:74.96\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:78.8,Validation Acc:75.44\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:79.62,Validation Acc:76.92\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 74 / 96\n",
      "Learning Rate = 2\n",
      "Ngram = 1\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 4764439\n",
      "Token id 53964 -> token starletta\n",
      "Token starletta -> token id 53964\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 2\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:62.005,Validation Acc:60.82\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:64.7,Validation Acc:63.16\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:63.58,Validation Acc:62.2\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:58.37,Validation Acc:56.96\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:67.57,Validation Acc:66.36\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:67.885,Validation Acc:66.7\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:68.29,Validation Acc:67.06\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:69.3,Validation Acc:67.9\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:65.915,Validation Acc:64.92\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:64.945,Validation Acc:63.44\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:66.16,Validation Acc:64.84\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:71.09,Validation Acc:69.7\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:71.5,Validation Acc:69.78\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:71.35,Validation Acc:70.04\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:69.35,Validation Acc:67.66\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:66.235,Validation Acc:65.08\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:69.54,Validation Acc:68.58\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:72.37,Validation Acc:71.64\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:71.185,Validation Acc:70.3\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:71.13,Validation Acc:70.1\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:74.0,Validation Acc:72.74\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:74.41,Validation Acc:72.98\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:71.51,Validation Acc:70.54\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:74.395,Validation Acc:72.92\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:75.08,Validation Acc:73.66\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:75.16,Validation Acc:73.7\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:72.89,Validation Acc:71.98\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:73.685,Validation Acc:72.76\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:73.04,Validation Acc:71.22\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:76.25,Validation Acc:74.38\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 75 / 96\n",
      "Learning Rate = 2\n",
      "Ngram = 1\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 4764439\n",
      "Token id 32031 -> token dramatisation\n",
      "Token dramatisation -> token id 32031\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 2\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:66.91,Validation Acc:65.46\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:67.505,Validation Acc:64.96\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:69.475,Validation Acc:67.48\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:71.64,Validation Acc:69.32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[1/5],Step:[251/313],Training Acc:71.325,Validation Acc:68.94\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:73.675,Validation Acc:71.78\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:62.98,Validation Acc:63.36\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:60.96,Validation Acc:58.74\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:72.695,Validation Acc:72.3\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:63.605,Validation Acc:63.24\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:75.425,Validation Acc:74.02\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:75.475,Validation Acc:74.68\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:76.815,Validation Acc:75.16\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:76.485,Validation Acc:75.72\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:76.74,Validation Acc:74.96\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:76.085,Validation Acc:73.76\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:74.655,Validation Acc:74.6\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:76.215,Validation Acc:73.64\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:77.275,Validation Acc:76.58\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:78.13,Validation Acc:76.16\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:74.925,Validation Acc:74.34\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:76.41,Validation Acc:75.44\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:79.03,Validation Acc:77.06\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:77.14,Validation Acc:75.86\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:79.685,Validation Acc:77.84\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:77.76,Validation Acc:76.44\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:79.75,Validation Acc:78.38\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:79.28,Validation Acc:77.94\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:80.47,Validation Acc:79.18\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:80.65,Validation Acc:79.26\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 76 / 96\n",
      "Learning Rate = 2\n",
      "Ngram = 1\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 4764439\n",
      "Token id 43989 -> token mate(1934\n",
      "Token mate(1934 -> token id 43989\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 2\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:50.93,Validation Acc:50.48\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:64.13,Validation Acc:62.72\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:60.495,Validation Acc:58.68\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:54.665,Validation Acc:54.12\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:70.4,Validation Acc:68.32\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:56.09,Validation Acc:55.52\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:71.0,Validation Acc:69.0\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:71.455,Validation Acc:69.72\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:69.805,Validation Acc:67.8\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:70.305,Validation Acc:68.36\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:60.975,Validation Acc:59.76\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:72.58,Validation Acc:70.54\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:71.23,Validation Acc:69.9\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:64.055,Validation Acc:61.98\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:72.19,Validation Acc:70.58\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:72.33,Validation Acc:70.76\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:67.62,Validation Acc:66.34\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:75.355,Validation Acc:73.4\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:75.45,Validation Acc:73.84\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:75.645,Validation Acc:73.9\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:70.19,Validation Acc:68.76\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:73.255,Validation Acc:71.98\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:75.595,Validation Acc:74.02\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:76.21,Validation Acc:74.86\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:65.905,Validation Acc:63.86\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:76.295,Validation Acc:75.3\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:74.38,Validation Acc:73.2\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:77.355,Validation Acc:75.8\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:77.645,Validation Acc:75.76\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:74.3,Validation Acc:72.68\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 77 / 96\n",
      "Learning Rate = 2\n",
      "Ngram = 1\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 4764439\n",
      "Token id 363 -> token production\n",
      "Token production -> token id 363\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 2\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:65.245,Validation Acc:63.24\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:66.075,Validation Acc:64.22\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:60.685,Validation Acc:60.04\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:68.38,Validation Acc:66.92\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:69.445,Validation Acc:67.68\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:64.12,Validation Acc:63.7\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:69.88,Validation Acc:68.08\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:71.56,Validation Acc:69.72\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:72.285,Validation Acc:70.54\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:67.16,Validation Acc:66.32\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:71.6,Validation Acc:70.06\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:73.48,Validation Acc:71.28\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:71.1,Validation Acc:69.16\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:75.145,Validation Acc:72.78\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:75.11,Validation Acc:73.12\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:75.5,Validation Acc:73.46\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:74.95,Validation Acc:72.9\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:74.855,Validation Acc:72.98\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:72.585,Validation Acc:70.86\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:76.575,Validation Acc:74.5\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:77.685,Validation Acc:75.4\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:75.32,Validation Acc:73.22\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:76.74,Validation Acc:74.66\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:76.735,Validation Acc:74.8\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:75.27,Validation Acc:73.26\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:77.535,Validation Acc:75.44\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:78.485,Validation Acc:76.72\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:79.08,Validation Acc:76.9\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:79.11,Validation Acc:76.88\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:78.965,Validation Acc:76.96\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 78 / 96\n",
      "Learning Rate = 2\n",
      "Ngram = 1\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 4764439\n",
      "Token id 78875 -> token jerico\n",
      "Token jerico -> token id 78875\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 2\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:51.685,Validation Acc:50.98\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:53.135,Validation Acc:52.32\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:57.945,Validation Acc:57.58\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:55.65,Validation Acc:55.6\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:68.22,Validation Acc:67.8\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:68.98,Validation Acc:67.64\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:69.755,Validation Acc:68.8\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:69.86,Validation Acc:68.86\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:70.34,Validation Acc:68.58\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:71.08,Validation Acc:70.18\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:70.725,Validation Acc:68.56\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:70.38,Validation Acc:68.62\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:71.95,Validation Acc:70.64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[3/5],Step:[51/157],Training Acc:72.205,Validation Acc:70.48\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:64.4,Validation Acc:63.36\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:60.565,Validation Acc:60.14\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:69.435,Validation Acc:67.96\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:73.915,Validation Acc:71.86\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:72.85,Validation Acc:71.34\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:68.185,Validation Acc:67.64\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:74.115,Validation Acc:72.56\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:75.07,Validation Acc:73.02\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:74.39,Validation Acc:72.32\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:69.4,Validation Acc:68.48\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:75.475,Validation Acc:73.68\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:72.34,Validation Acc:70.56\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:76.245,Validation Acc:74.12\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:75.44,Validation Acc:73.44\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:75.95,Validation Acc:73.76\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:76.145,Validation Acc:74.24\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 79 / 96\n",
      "Learning Rate = 2\n",
      "Ngram = 1\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 4764439\n",
      "Token id 45383 -> token heathcliffe\n",
      "Token heathcliffe -> token id 45383\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 2\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:57.93,Validation Acc:56.44\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:66.815,Validation Acc:64.92\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:61.2,Validation Acc:58.98\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:68.685,Validation Acc:67.5\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:73.255,Validation Acc:71.22\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:70.75,Validation Acc:70.22\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:72.39,Validation Acc:71.74\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:68.32,Validation Acc:67.44\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:74.64,Validation Acc:71.64\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:73.865,Validation Acc:70.84\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:73.5,Validation Acc:72.74\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:74.54,Validation Acc:73.48\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:77.01,Validation Acc:74.34\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:69.35,Validation Acc:68.66\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:77.81,Validation Acc:74.7\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:77.375,Validation Acc:74.14\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:77.14,Validation Acc:74.1\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:72.405,Validation Acc:69.32\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:75.465,Validation Acc:74.62\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:78.61,Validation Acc:76.2\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:79.24,Validation Acc:76.64\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:77.425,Validation Acc:73.46\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:79.45,Validation Acc:75.96\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:78.725,Validation Acc:75.14\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:78.735,Validation Acc:77.56\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:76.83,Validation Acc:75.36\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:74.52,Validation Acc:71.26\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:80.145,Validation Acc:78.78\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:80.79,Validation Acc:77.76\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:78.395,Validation Acc:75.08\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 80 / 96\n",
      "Learning Rate = 2\n",
      "Ngram = 1\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 4764439\n",
      "Token id 4229 -> token stinks\n",
      "Token stinks -> token id 4229\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 2\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:50.345,Validation Acc:49.82\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:60.135,Validation Acc:58.98\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:54.575,Validation Acc:54.38\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:55.265,Validation Acc:55.02\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:67.815,Validation Acc:66.22\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:71.09,Validation Acc:68.62\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:70.77,Validation Acc:69.12\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:70.08,Validation Acc:69.4\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:61.61,Validation Acc:59.4\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:72.195,Validation Acc:69.84\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:66.005,Validation Acc:66.04\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:71.3,Validation Acc:69.9\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:72.405,Validation Acc:69.38\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:73.23,Validation Acc:71.88\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:71.17,Validation Acc:70.44\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:66.87,Validation Acc:67.04\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:72.95,Validation Acc:72.04\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:68.115,Validation Acc:65.44\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:65.58,Validation Acc:62.74\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:75.4,Validation Acc:72.58\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:75.84,Validation Acc:73.66\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:71.63,Validation Acc:71.0\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:75.655,Validation Acc:74.1\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:74.54,Validation Acc:73.2\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:75.42,Validation Acc:72.0\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:75.14,Validation Acc:73.96\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:75.255,Validation Acc:72.12\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:77.285,Validation Acc:75.44\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:77.4,Validation Acc:75.16\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:77.455,Validation Acc:75.68\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 81 / 96\n",
      "Learning Rate = 2\n",
      "Ngram = 2\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 9508878\n",
      "Token id 51601 -> token be associated\n",
      "Token be associated -> token id 51601\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 2\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:56.37,Validation Acc:55.06\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:63.645,Validation Acc:62.08\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:65.025,Validation Acc:63.56\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:54.435,Validation Acc:53.66\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:67.57,Validation Acc:66.38\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:68.33,Validation Acc:66.38\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:63.87,Validation Acc:62.76\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:69.455,Validation Acc:67.94\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:67.055,Validation Acc:66.1\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:68.925,Validation Acc:67.36\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:63.53,Validation Acc:61.92\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:71.325,Validation Acc:70.2\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:69.52,Validation Acc:68.16\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:72.53,Validation Acc:71.52\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:72.295,Validation Acc:71.3\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:73.21,Validation Acc:71.74\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:73.955,Validation Acc:72.64\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:74.36,Validation Acc:72.96\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:74.92,Validation Acc:73.6\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:74.2,Validation Acc:73.2\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:72.81,Validation Acc:70.68\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:74.375,Validation Acc:73.64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[4/5],Step:[251/313],Training Acc:72.68,Validation Acc:71.48\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:75.33,Validation Acc:74.1\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:72.935,Validation Acc:70.78\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:75.08,Validation Acc:74.22\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:71.8,Validation Acc:70.06\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:71.855,Validation Acc:70.54\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:77.595,Validation Acc:76.06\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:73.395,Validation Acc:70.84\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 82 / 96\n",
      "Learning Rate = 2\n",
      "Ngram = 2\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 9508878\n",
      "Token id 48136 -> token holes is\n",
      "Token holes is -> token id 48136\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 2\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:62.17,Validation Acc:59.98\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:52.8,Validation Acc:52.36\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:53.11,Validation Acc:52.98\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:60.925,Validation Acc:59.52\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:65.41,Validation Acc:62.9\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:62.21,Validation Acc:60.02\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:58.245,Validation Acc:56.84\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:65.9,Validation Acc:63.62\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:67.28,Validation Acc:65.02\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:67.24,Validation Acc:65.66\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:67.785,Validation Acc:65.88\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:68.545,Validation Acc:66.66\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:60.765,Validation Acc:59.6\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:54.455,Validation Acc:53.78\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:69.15,Validation Acc:67.0\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:65.725,Validation Acc:63.4\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:64.48,Validation Acc:62.38\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:69.675,Validation Acc:68.14\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:69.31,Validation Acc:67.26\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:66.855,Validation Acc:64.62\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:71.295,Validation Acc:69.02\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:70.485,Validation Acc:69.3\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:71.22,Validation Acc:69.98\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:71.495,Validation Acc:69.06\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:71.84,Validation Acc:70.5\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:67.72,Validation Acc:66.22\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:66.77,Validation Acc:65.32\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:73.075,Validation Acc:71.02\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:73.18,Validation Acc:71.32\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:66.465,Validation Acc:64.7\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 83 / 96\n",
      "Learning Rate = 2\n",
      "Ngram = 2\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 9508878\n",
      "Token id 32017 -> token they always\n",
      "Token they always -> token id 32017\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 2\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:50.595,Validation Acc:50.18\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:52.99,Validation Acc:52.66\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:60.615,Validation Acc:59.3\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:57.3,Validation Acc:56.06\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:62.135,Validation Acc:60.92\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:71.21,Validation Acc:70.94\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:59.68,Validation Acc:59.44\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:72.59,Validation Acc:71.22\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:71.11,Validation Acc:69.48\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:72.47,Validation Acc:71.62\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:71.98,Validation Acc:70.8\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:73.25,Validation Acc:71.74\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:73.405,Validation Acc:71.86\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:73.15,Validation Acc:72.26\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:73.67,Validation Acc:71.9\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:67.58,Validation Acc:66.24\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:74.135,Validation Acc:72.52\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:76.78,Validation Acc:74.7\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:74.085,Validation Acc:72.92\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:76.68,Validation Acc:75.42\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:72.745,Validation Acc:71.3\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:77.095,Validation Acc:75.36\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:77.44,Validation Acc:75.72\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:75.015,Validation Acc:73.32\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:78.0,Validation Acc:76.16\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:78.505,Validation Acc:76.32\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:77.83,Validation Acc:75.9\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:75.32,Validation Acc:73.0\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:79.07,Validation Acc:77.14\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:79.005,Validation Acc:77.0\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 84 / 96\n",
      "Learning Rate = 2\n",
      "Ngram = 2\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 9508878\n",
      "Token id 61599 -> token no message\n",
      "Token no message -> token id 61599\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 2\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:49.95,Validation Acc:50.2\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:50.51,Validation Acc:50.34\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:55.17,Validation Acc:54.96\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:63.095,Validation Acc:62.0\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:56.27,Validation Acc:56.04\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:63.355,Validation Acc:62.48\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:68.545,Validation Acc:67.6\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:63.48,Validation Acc:62.94\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:66.795,Validation Acc:66.5\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:61.27,Validation Acc:59.84\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:71.67,Validation Acc:71.16\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:68.065,Validation Acc:67.52\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:66.86,Validation Acc:66.08\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:64.385,Validation Acc:63.22\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:68.68,Validation Acc:66.78\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:62.925,Validation Acc:61.5\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:71.875,Validation Acc:71.16\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:73.67,Validation Acc:73.26\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:74.02,Validation Acc:73.26\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:74.0,Validation Acc:73.2\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:74.485,Validation Acc:73.84\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:64.44,Validation Acc:62.82\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:74.445,Validation Acc:73.86\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:74.71,Validation Acc:73.96\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:75.225,Validation Acc:74.48\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:74.085,Validation Acc:72.88\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:73.11,Validation Acc:71.7\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:75.27,Validation Acc:74.5\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:76.155,Validation Acc:75.0\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:74.755,Validation Acc:73.64\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 85 / 96\n",
      "Learning Rate = 2\n",
      "Ngram = 2\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 9508878\n",
      "Token id 433084 -> token jake richardson\n",
      "Token jake richardson -> token id 433084\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 2\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:50.23,Validation Acc:49.84\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:60.09,Validation Acc:58.44\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:65.815,Validation Acc:63.16\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:66.315,Validation Acc:64.96\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:67.31,Validation Acc:65.94\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:67.72,Validation Acc:66.3\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:69.395,Validation Acc:67.62\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:69.72,Validation Acc:68.0\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:70.355,Validation Acc:68.0\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:70.3,Validation Acc:68.82\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:66.815,Validation Acc:66.0\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:71.825,Validation Acc:70.9\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:72.845,Validation Acc:70.4\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:73.115,Validation Acc:71.52\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:73.42,Validation Acc:71.2\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:71.22,Validation Acc:69.88\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:74.53,Validation Acc:72.74\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:73.005,Validation Acc:70.38\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:75.7,Validation Acc:73.7\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:73.005,Validation Acc:70.44\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:74.495,Validation Acc:72.96\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:76.335,Validation Acc:74.24\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:72.705,Validation Acc:71.38\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:76.92,Validation Acc:74.62\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:73.88,Validation Acc:71.36\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:76.375,Validation Acc:73.42\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:77.95,Validation Acc:75.34\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:77.555,Validation Acc:74.98\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:78.125,Validation Acc:75.26\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:78.015,Validation Acc:75.62\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 86 / 96\n",
      "Learning Rate = 2\n",
      "Ngram = 2\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 9508878\n",
      "Token id 391878 -> token this held\n",
      "Token this held -> token id 391878\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 2\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:52.325,Validation Acc:50.76\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:63.685,Validation Acc:61.08\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:65.985,Validation Acc:63.8\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:64.67,Validation Acc:64.16\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:65.82,Validation Acc:64.86\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:62.08,Validation Acc:61.94\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:57.19,Validation Acc:55.14\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:66.815,Validation Acc:65.3\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:63.565,Validation Acc:62.1\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:69.175,Validation Acc:68.08\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:68.71,Validation Acc:66.84\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:68.99,Validation Acc:67.32\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:70.295,Validation Acc:69.0\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:66.01,Validation Acc:64.5\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:68.885,Validation Acc:67.14\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:70.77,Validation Acc:69.06\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:71.325,Validation Acc:69.76\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:66.86,Validation Acc:64.66\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:71.87,Validation Acc:70.32\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:72.355,Validation Acc:70.84\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:64.29,Validation Acc:62.62\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:71.13,Validation Acc:69.18\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:70.33,Validation Acc:68.08\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:71.29,Validation Acc:69.76\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:71.475,Validation Acc:69.24\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:73.06,Validation Acc:71.6\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:68.595,Validation Acc:66.96\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:73.77,Validation Acc:72.42\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:73.505,Validation Acc:71.84\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:74.01,Validation Acc:73.04\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 87 / 96\n",
      "Learning Rate = 2\n",
      "Ngram = 2\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 9508878\n",
      "Token id 663834 -> token pumphrey\n",
      "Token pumphrey -> token id 663834\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 2\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:65.165,Validation Acc:62.92\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:68.285,Validation Acc:66.82\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:66.11,Validation Acc:65.68\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:61.16,Validation Acc:61.08\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:68.01,Validation Acc:68.04\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:69.23,Validation Acc:65.82\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:66.925,Validation Acc:66.9\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:72.935,Validation Acc:71.4\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:72.015,Validation Acc:70.82\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:73.615,Validation Acc:72.3\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:74.44,Validation Acc:72.86\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:74.605,Validation Acc:73.44\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:70.995,Validation Acc:68.72\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:75.315,Validation Acc:73.76\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:71.235,Validation Acc:70.66\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:71.79,Validation Acc:70.06\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:70.22,Validation Acc:68.06\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:76.605,Validation Acc:74.74\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:76.19,Validation Acc:74.32\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:75.77,Validation Acc:74.28\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:75.73,Validation Acc:74.24\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:77.645,Validation Acc:75.92\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:77.47,Validation Acc:75.58\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:77.87,Validation Acc:75.94\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:76.63,Validation Acc:74.82\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:77.035,Validation Acc:74.9\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:78.485,Validation Acc:76.02\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:78.73,Validation Acc:76.3\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:78.335,Validation Acc:75.62\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:74.89,Validation Acc:73.14\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 88 / 96\n",
      "Learning Rate = 2\n",
      "Ngram = 2\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 9508878\n",
      "Token id 121835 -> token are dated\n",
      "Token are dated -> token id 121835\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 2\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:57.725,Validation Acc:54.7\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:50.745,Validation Acc:50.46\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:51.355,Validation Acc:50.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[1/5],Step:[101/157],Training Acc:64.27,Validation Acc:62.08\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:60.055,Validation Acc:57.84\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:69.855,Validation Acc:67.5\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:60.455,Validation Acc:58.1\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:60.32,Validation Acc:59.0\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:69.055,Validation Acc:66.36\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:71.0,Validation Acc:68.26\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:71.915,Validation Acc:69.44\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:65.565,Validation Acc:63.9\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:66.87,Validation Acc:66.02\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:70.845,Validation Acc:68.58\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:72.355,Validation Acc:69.6\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:73.165,Validation Acc:70.3\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:70.365,Validation Acc:68.46\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:69.905,Validation Acc:67.04\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:70.915,Validation Acc:68.48\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:72.215,Validation Acc:69.9\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:74.38,Validation Acc:72.04\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:69.455,Validation Acc:67.86\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:67.24,Validation Acc:64.98\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:73.87,Validation Acc:71.72\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:74.245,Validation Acc:71.7\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:74.26,Validation Acc:71.84\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:74.335,Validation Acc:72.18\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:70.675,Validation Acc:68.64\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:75.01,Validation Acc:72.2\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:75.555,Validation Acc:72.72\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 89 / 96\n",
      "Learning Rate = 2\n",
      "Ngram = 3\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 14233317\n",
      "Token id 51751 -> token hit on\n",
      "Token hit on -> token id 51751\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 2\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:61.155,Validation Acc:60.32\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:58.25,Validation Acc:57.84\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:53.89,Validation Acc:54.36\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:57.84,Validation Acc:57.3\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:58.915,Validation Acc:58.42\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:61.89,Validation Acc:61.44\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:61.195,Validation Acc:60.38\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:70.985,Validation Acc:70.6\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:69.86,Validation Acc:69.32\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:59.34,Validation Acc:59.12\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:71.855,Validation Acc:71.56\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:68.425,Validation Acc:66.94\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:72.81,Validation Acc:71.66\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:73.125,Validation Acc:72.18\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:71.99,Validation Acc:70.92\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:73.13,Validation Acc:71.66\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:71.865,Validation Acc:70.88\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:65.44,Validation Acc:64.3\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:66.7,Validation Acc:65.42\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:67.91,Validation Acc:66.54\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:74.18,Validation Acc:74.26\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:76.025,Validation Acc:74.86\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:71.845,Validation Acc:70.2\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:73.35,Validation Acc:72.5\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:71.055,Validation Acc:69.86\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:76.94,Validation Acc:76.36\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:76.395,Validation Acc:76.16\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:74.625,Validation Acc:73.68\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:75.045,Validation Acc:73.34\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:71.35,Validation Acc:69.62\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 90 / 96\n",
      "Learning Rate = 2\n",
      "Ngram = 3\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 14233317\n",
      "Token id 80149 -> token translator\n",
      "Token translator -> token id 80149\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 2\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:49.99,Validation Acc:50.22\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:62.2,Validation Acc:60.2\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:53.84,Validation Acc:53.58\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:65.68,Validation Acc:64.02\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:58.6,Validation Acc:57.4\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:64.135,Validation Acc:62.0\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:65.42,Validation Acc:63.56\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:57.745,Validation Acc:57.24\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:66.635,Validation Acc:64.66\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:66.545,Validation Acc:65.02\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:68.04,Validation Acc:66.76\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:60.27,Validation Acc:59.22\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:67.345,Validation Acc:65.06\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:67.08,Validation Acc:65.28\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:70.08,Validation Acc:67.88\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:66.355,Validation Acc:64.76\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:62.69,Validation Acc:61.6\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:71.355,Validation Acc:69.2\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:64.02,Validation Acc:62.54\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:65.035,Validation Acc:64.92\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:66.215,Validation Acc:64.84\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:71.91,Validation Acc:70.06\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:72.48,Validation Acc:70.78\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:68.455,Validation Acc:67.06\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:71.11,Validation Acc:69.46\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:71.565,Validation Acc:70.82\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:66.87,Validation Acc:65.02\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:72.805,Validation Acc:70.88\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:73.165,Validation Acc:71.34\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:70.615,Validation Acc:69.02\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 91 / 96\n",
      "Learning Rate = 2\n",
      "Ngram = 3\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 14233317\n",
      "Token id 45952 -> token episodes the\n",
      "Token episodes the -> token id 45952\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 2\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:57.28,Validation Acc:55.34\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:67.115,Validation Acc:65.24\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:66.9,Validation Acc:65.08\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:67.24,Validation Acc:65.42\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:66.435,Validation Acc:64.58\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:71.23,Validation Acc:69.72\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:72.325,Validation Acc:71.02\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:65.955,Validation Acc:63.74\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:70.585,Validation Acc:69.06\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:71.525,Validation Acc:70.14\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:66.9,Validation Acc:66.72\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:72.57,Validation Acc:70.92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[3/5],Step:[51/313],Training Acc:74.9,Validation Acc:73.38\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:73.895,Validation Acc:72.4\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:74.775,Validation Acc:72.58\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:73.375,Validation Acc:71.6\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:74.09,Validation Acc:72.92\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:74.53,Validation Acc:73.38\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:69.785,Validation Acc:68.74\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:75.075,Validation Acc:73.6\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:72.745,Validation Acc:71.22\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:75.745,Validation Acc:74.12\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:72.53,Validation Acc:70.98\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:74.64,Validation Acc:73.12\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:69.96,Validation Acc:68.66\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:75.415,Validation Acc:73.8\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:73.86,Validation Acc:72.0\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:76.99,Validation Acc:75.34\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:72.245,Validation Acc:70.66\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:76.29,Validation Acc:75.0\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 92 / 96\n",
      "Learning Rate = 2\n",
      "Ngram = 3\n",
      "Vocab Size = 100000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 14233317\n",
      "Token id 89435 -> token his lost\n",
      "Token his lost -> token id 89435\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 2\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:49.95,Validation Acc:50.2\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:53.965,Validation Acc:53.06\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:62.615,Validation Acc:61.74\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:57.88,Validation Acc:56.06\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:64.095,Validation Acc:63.54\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:69.19,Validation Acc:67.8\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:67.0,Validation Acc:64.26\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:61.605,Validation Acc:61.08\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:63.285,Validation Acc:60.98\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:66.935,Validation Acc:64.5\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:62.465,Validation Acc:61.82\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:70.245,Validation Acc:69.46\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:61.86,Validation Acc:59.76\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:62.43,Validation Acc:62.12\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:64.1,Validation Acc:62.16\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:66.12,Validation Acc:64.08\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:73.28,Validation Acc:70.64\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:73.29,Validation Acc:71.32\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:73.645,Validation Acc:71.76\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:72.51,Validation Acc:69.74\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:73.05,Validation Acc:72.02\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:72.59,Validation Acc:69.72\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:68.11,Validation Acc:67.26\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:74.09,Validation Acc:71.22\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:72.77,Validation Acc:71.0\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:72.355,Validation Acc:69.68\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:68.85,Validation Acc:66.48\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:66.45,Validation Acc:64.54\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:74.945,Validation Acc:71.92\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:73.18,Validation Acc:70.36\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 93 / 96\n",
      "Learning Rate = 2\n",
      "Ngram = 3\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 14233317\n",
      "Token id 524131 -> token remember spending\n",
      "Token remember spending -> token id 524131\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 2\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:61.015,Validation Acc:60.16\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:63.485,Validation Acc:61.86\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:59.76,Validation Acc:59.68\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:61.075,Validation Acc:58.94\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:55.855,Validation Acc:54.3\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:64.11,Validation Acc:62.08\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:66.185,Validation Acc:64.3\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:68.465,Validation Acc:67.74\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:68.9,Validation Acc:67.14\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:68.89,Validation Acc:67.42\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:70.805,Validation Acc:69.8\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:71.965,Validation Acc:70.6\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:71.915,Validation Acc:69.8\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:72.715,Validation Acc:70.66\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:64.27,Validation Acc:64.02\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:68.035,Validation Acc:65.98\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:73.54,Validation Acc:72.56\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:74.405,Validation Acc:73.3\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:67.885,Validation Acc:65.48\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:74.715,Validation Acc:74.2\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:74.525,Validation Acc:73.36\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:75.545,Validation Acc:74.82\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:73.735,Validation Acc:72.32\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:73.47,Validation Acc:71.06\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:74.155,Validation Acc:73.34\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:75.92,Validation Acc:75.08\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:72.055,Validation Acc:69.72\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:77.34,Validation Acc:75.82\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:76.39,Validation Acc:73.98\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:77.29,Validation Acc:75.36\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 94 / 96\n",
      "Learning Rate = 2\n",
      "Ngram = 3\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 100\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 14233317\n",
      "Token id 597231 -> token been putting out\n",
      "Token been putting out -> token id 597231\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 2\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:53.195,Validation Acc:52.56\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:58.85,Validation Acc:56.72\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:63.16,Validation Acc:61.26\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:64.695,Validation Acc:63.14\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:64.51,Validation Acc:62.26\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:66.135,Validation Acc:64.2\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:63.32,Validation Acc:61.74\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:66.115,Validation Acc:64.62\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:66.665,Validation Acc:64.68\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:61.13,Validation Acc:60.42\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:68.295,Validation Acc:66.64\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:67.82,Validation Acc:66.08\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:68.88,Validation Acc:66.72\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:68.33,Validation Acc:66.22\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:65.785,Validation Acc:64.34\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:68.57,Validation Acc:66.8\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:69.69,Validation Acc:67.7\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:70.04,Validation Acc:68.22\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:70.815,Validation Acc:69.38\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:70.62,Validation Acc:68.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[4/5],Step:[76/157],Training Acc:63.565,Validation Acc:62.58\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:71.445,Validation Acc:69.76\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:70.68,Validation Acc:69.12\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:72.46,Validation Acc:69.98\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:71.345,Validation Acc:70.1\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:71.745,Validation Acc:70.48\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:72.115,Validation Acc:70.84\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:72.665,Validation Acc:70.9\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:73.55,Validation Acc:71.8\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:73.0,Validation Acc:71.84\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 95 / 96\n",
      "Learning Rate = 2\n",
      "Ngram = 3\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 64\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 14233317\n",
      "Token id 781804 -> token an aged norman\n",
      "Token an aged norman -> token id 781804\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 2\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[51/313],Training Acc:60.32,Validation Acc:59.44\n",
      "Epoch:[1/5],Step:[101/313],Training Acc:63.94,Validation Acc:62.24\n",
      "Epoch:[1/5],Step:[151/313],Training Acc:65.19,Validation Acc:62.38\n",
      "Epoch:[1/5],Step:[201/313],Training Acc:68.145,Validation Acc:66.98\n",
      "Epoch:[1/5],Step:[251/313],Training Acc:57.94,Validation Acc:56.4\n",
      "Epoch:[1/5],Step:[301/313],Training Acc:69.745,Validation Acc:67.52\n",
      "Epoch:[2/5],Step:[51/313],Training Acc:69.565,Validation Acc:67.92\n",
      "Epoch:[2/5],Step:[101/313],Training Acc:69.51,Validation Acc:67.26\n",
      "Epoch:[2/5],Step:[151/313],Training Acc:69.47,Validation Acc:68.42\n",
      "Epoch:[2/5],Step:[201/313],Training Acc:70.005,Validation Acc:68.18\n",
      "Epoch:[2/5],Step:[251/313],Training Acc:72.215,Validation Acc:70.04\n",
      "Epoch:[2/5],Step:[301/313],Training Acc:69.25,Validation Acc:67.72\n",
      "Epoch:[3/5],Step:[51/313],Training Acc:72.255,Validation Acc:70.3\n",
      "Epoch:[3/5],Step:[101/313],Training Acc:65.025,Validation Acc:64.12\n",
      "Epoch:[3/5],Step:[151/313],Training Acc:74.545,Validation Acc:72.2\n",
      "Epoch:[3/5],Step:[201/313],Training Acc:73.075,Validation Acc:70.78\n",
      "Epoch:[3/5],Step:[251/313],Training Acc:74.21,Validation Acc:71.66\n",
      "Epoch:[3/5],Step:[301/313],Training Acc:74.55,Validation Acc:73.02\n",
      "Epoch:[4/5],Step:[51/313],Training Acc:75.075,Validation Acc:72.9\n",
      "Epoch:[4/5],Step:[101/313],Training Acc:75.245,Validation Acc:73.32\n",
      "Epoch:[4/5],Step:[151/313],Training Acc:73.61,Validation Acc:71.52\n",
      "Epoch:[4/5],Step:[201/313],Training Acc:73.55,Validation Acc:71.68\n",
      "Epoch:[4/5],Step:[251/313],Training Acc:72.375,Validation Acc:71.16\n",
      "Epoch:[4/5],Step:[301/313],Training Acc:76.67,Validation Acc:74.02\n",
      "Epoch:[5/5],Step:[51/313],Training Acc:76.26,Validation Acc:73.5\n",
      "Epoch:[5/5],Step:[101/313],Training Acc:76.395,Validation Acc:73.68\n",
      "Epoch:[5/5],Step:[151/313],Training Acc:78.055,Validation Acc:76.04\n",
      "Epoch:[5/5],Step:[201/313],Training Acc:77.67,Validation Acc:75.46\n",
      "Epoch:[5/5],Step:[251/313],Training Acc:74.26,Validation Acc:70.72\n",
      "Epoch:[5/5],Step:[301/313],Training Acc:77.91,Validation Acc:74.98\n",
      "-----------------------------------------------------------\n",
      "Parameter Combination = 96 / 96\n",
      "Learning Rate = 2\n",
      "Ngram = 3\n",
      "Vocab Size = 1000000\n",
      "Embedding Dimension = 200\n",
      "Batch Size = 128\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Total number of tokens in train dataset is 14233317\n",
      "Token id 641143 -> token up will be\n",
      "Token up will be -> token id 641143\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Optimization Start\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 2\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch:[1/5],Step:[26/157],Training Acc:49.99,Validation Acc:50.22\n",
      "Epoch:[1/5],Step:[51/157],Training Acc:65.91,Validation Acc:63.5\n",
      "Epoch:[1/5],Step:[76/157],Training Acc:67.34,Validation Acc:64.4\n",
      "Epoch:[1/5],Step:[101/157],Training Acc:52.785,Validation Acc:52.58\n",
      "Epoch:[1/5],Step:[126/157],Training Acc:56.3,Validation Acc:56.02\n",
      "Epoch:[1/5],Step:[151/157],Training Acc:68.125,Validation Acc:66.92\n",
      "Epoch:[2/5],Step:[26/157],Training Acc:69.06,Validation Acc:67.32\n",
      "Epoch:[2/5],Step:[51/157],Training Acc:61.725,Validation Acc:62.32\n",
      "Epoch:[2/5],Step:[76/157],Training Acc:70.27,Validation Acc:69.38\n",
      "Epoch:[2/5],Step:[101/157],Training Acc:65.095,Validation Acc:62.16\n",
      "Epoch:[2/5],Step:[126/157],Training Acc:63.12,Validation Acc:64.02\n",
      "Epoch:[2/5],Step:[151/157],Training Acc:69.835,Validation Acc:67.38\n",
      "Epoch:[3/5],Step:[26/157],Training Acc:65.735,Validation Acc:65.74\n",
      "Epoch:[3/5],Step:[51/157],Training Acc:72.72,Validation Acc:70.12\n",
      "Epoch:[3/5],Step:[76/157],Training Acc:67.985,Validation Acc:66.88\n",
      "Epoch:[3/5],Step:[101/157],Training Acc:67.675,Validation Acc:64.72\n",
      "Epoch:[3/5],Step:[126/157],Training Acc:73.265,Validation Acc:71.4\n",
      "Epoch:[3/5],Step:[151/157],Training Acc:71.95,Validation Acc:69.74\n",
      "Epoch:[4/5],Step:[26/157],Training Acc:73.75,Validation Acc:71.58\n",
      "Epoch:[4/5],Step:[51/157],Training Acc:73.855,Validation Acc:71.26\n",
      "Epoch:[4/5],Step:[76/157],Training Acc:74.52,Validation Acc:71.82\n",
      "Epoch:[4/5],Step:[101/157],Training Acc:70.635,Validation Acc:69.58\n",
      "Epoch:[4/5],Step:[126/157],Training Acc:73.545,Validation Acc:70.98\n",
      "Epoch:[4/5],Step:[151/157],Training Acc:74.895,Validation Acc:72.34\n",
      "Epoch:[5/5],Step:[26/157],Training Acc:75.09,Validation Acc:72.92\n",
      "Epoch:[5/5],Step:[51/157],Training Acc:67.24,Validation Acc:66.9\n",
      "Epoch:[5/5],Step:[76/157],Training Acc:73.83,Validation Acc:71.58\n",
      "Epoch:[5/5],Step:[101/157],Training Acc:74.24,Validation Acc:71.14\n",
      "Epoch:[5/5],Step:[126/157],Training Acc:73.785,Validation Acc:72.26\n",
      "Epoch:[5/5],Step:[151/157],Training Acc:73.095,Validation Acc:71.58\n"
     ]
    }
   ],
   "source": [
    "param_val_losses_sgd_nolemma = hyperparameter_search(hyperparameter_space = params,\n",
    "                                         epochs = 5,\n",
    "                                         optimizer_name = \"SGD\",\n",
    "                                          lemmatize = False)\n",
    "pkl.dump(param_val_losses_sgd_nolemma,\n",
    "         open(\"param_val_losses_sgd_nolemma.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# param_val_losses_sgd_lemma = hyperparameter_search(hyperparameter_space = params,\n",
    "#                                          epochs = 5,\n",
    "#                                          optimizer_name = \"SGD\",\n",
    "#                                           lemmatize = True)\n",
    "# pkl.dump(param_val_losses_sgd_lemma,\n",
    "#          open(\"param_val_losses_sgd_lemma.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
