{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"tocheading\">Table of Contents</h1>\n",
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script uses bag-of-ngrams approach to sentiment classification using the IMDB review dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset was downloaded from: http://ai.stanford.edu/~amaas/data/sentiment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_loc = \"data/imdb_reviews/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_txt_files(folder_path):\n",
    "    \"\"\"Reads all .txt files in a folder to a list\"\"\"\n",
    "    \n",
    "    file_list = os.listdir(folder_path)\n",
    "    # for debugging, printing out the folder path and some files in it\n",
    "    print(folder_path)\n",
    "    print(file_list[:10])\n",
    "    \n",
    "    all_reviews = []\n",
    "    for file_path in file_list:\n",
    "        f = open(folder_path + file_path,\"r\")\n",
    "        all_reviews.append(f.readline())\n",
    "        \n",
    "    return all_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/imdb_reviews/train/pos/\n",
      "['4715_9.txt', '12390_8.txt', '8329_7.txt', '9063_8.txt', '3092_10.txt', '9865_8.txt', '6639_10.txt', '10460_10.txt', '10331_10.txt', '11606_10.txt']\n",
      "12500\n",
      "data/imdb_reviews/train/neg/\n",
      "['1821_4.txt', '10402_1.txt', '1062_4.txt', '9056_1.txt', '5392_3.txt', '2682_3.txt', '3351_4.txt', '399_2.txt', '10447_1.txt', '10096_1.txt']\n",
      "12500\n",
      "data/imdb_reviews/test/pos/\n",
      "['4715_9.txt', '1930_9.txt', '3205_9.txt', '10186_10.txt', '147_10.txt', '7511_7.txt', '616_10.txt', '10460_10.txt', '3240_9.txt', '1975_9.txt']\n",
      "12500\n",
      "data/imdb_reviews/test/neg/\n",
      "['1821_4.txt', '9487_1.txt', '4604_4.txt', '2828_2.txt', '10890_1.txt', '3351_4.txt', '8070_2.txt', '1027_4.txt', '8248_3.txt', '4290_4.txt']\n",
      "12500\n"
     ]
    }
   ],
   "source": [
    "train_pos = read_txt_files(folder_path=data_loc+\"train/pos/\")\n",
    "print(len(train_pos))\n",
    "train_neg = read_txt_files(folder_path=data_loc+\"train/neg/\")\n",
    "print(len(train_neg))\n",
    "test_pos = read_txt_files(folder_path=data_loc+\"test/pos/\")\n",
    "print(len(test_pos))\n",
    "test_neg = read_txt_files(folder_path=data_loc+\"test/neg/\")\n",
    "print(len(test_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12297\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Sudden Impact is the best of the five Dirty Harry movies. They don't come any leaner and meaner than this as Harry romps through a series of violent clashes, with the bad guys getting their just desserts. Which is just the way I like it. Great story too and ably directed by Clint himself. Excellent entertainment.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_text = np.random.randint(1, high=len(train_pos)-1)\n",
    "print(random_text)\n",
    "train_pos[random_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Positive examples = 12500\n",
      "Train Negative examples = 12500\n",
      "Test Positive examples = 12500\n",
      "Test Negative examples = 12500\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Positive examples = \" + str(len(train_pos)))\n",
    "print(\"Train Negative examples = \" + str(len(train_neg)))\n",
    "print(\"Test Positive examples = \" + str(len(test_pos)))\n",
    "print(\"Test Negative examples = \" + str(len(test_neg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pos_labels = np.ones((len(train_pos),), dtype=int)\n",
    "train_pos_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_neg_labels = np.zeros((len(train_neg),), dtype=int)\n",
    "train_neg_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_labels = np.concatenate((train_pos_labels,train_neg_labels))\n",
    "train_data_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the labels of the test set for Test Error Measuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pos_labels = np.ones((len(test_pos),), dtype=int)\n",
    "test_neg_labels = np.zeros((len(test_neg),), dtype=int)\n",
    "test_data_labels = np.concatenate((test_pos_labels,test_neg_labels))\n",
    "print(len(test_data_labels))\n",
    "test_data_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing HTML tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sudden Impact is the best of the five Dirty Harry movies. They don't come any leaner and meaner than this as Harry romps through a series of violent clashes, with the bad guys getting their just desserts. Which is just the way I like it. Great story too and ably directed by Clint himself. Excellent entertainment.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pos[random_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_pos_clean = [cleanhtml(x) for x in train_pos]\n",
    "train_neg_clean = [cleanhtml(x) for x in train_neg]\n",
    "\n",
    "test_pos_clean = [cleanhtml(x) for x in test_pos]\n",
    "test_neg_clean = [cleanhtml(x) for x in test_neg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sudden Impact is the best of the five Dirty Harry movies. They don't come any leaner and meaner than this as Harry romps through a series of violent clashes, with the bad guys getting their just desserts. Which is just the way I like it. Great story too and ably directed by Clint himself. Excellent entertainment.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pos_clean[random_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing dots & question marks & paranthesis with space\n",
    "\n",
    "It seems that punctuations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\"asdasdasds.asdasda\".replace(\".\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def remove_dqmp(review):\n",
    "    \n",
    "#     review = review.replace(\".\",\" \")\n",
    "#     review = review.replace(\"?\",\" \")\n",
    "#     review = review.replace(\")\",\" \")\n",
    "#     review = review.replace(\"(\",\" \")\n",
    "    \n",
    "#     return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remove_dqmp(train_pos_clean[random_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_pos_clean = [remove_dqmp(x) for x in train_pos_clean]\n",
    "# train_neg_clean = [remove_dqmp(x) for x in train_neg_clean]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import string\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "tokenizer = spacy.load('en_core_web_sm')\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# This is word tokenizer\n",
    "# # lowercase and remove punctuation\n",
    "# def tokenize(sent):\n",
    "#     tokens = tokenizer(sent)\n",
    "#     return [token.text.lower() for token in tokens if (token.text not in punctuations)]\n",
    "#     #return [token.text.lower() for token in tokens]\n",
    "    \n",
    "# Modified for n-grams\n",
    "def tokenize(sent, n_gram = 0):\n",
    "    \n",
    "    tokens = tokenizer(sent)\n",
    "    \n",
    "    if n_gram >= 1:\n",
    "        unigrams = [token.text.lower() for token in tokens if (token.text not in punctuations)]\n",
    "        output = []\n",
    "        for k in range(n_gram):\n",
    "            for i in range(len(unigrams)-(k+1)+1):\n",
    "                output.append(unigrams[i:i+(k+1)])\n",
    "        return output\n",
    "    #return [token.text.lower() for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11800\n"
     ]
    }
   ],
   "source": [
    "random_text = np.random.randint(1, high=len(train_pos)-1)\n",
    "print(random_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Partially from the perceived need, one feels, to include a conventional love story in the plot to make the film more marketable to a 1950's movie-going public. The film starts with some wickedly funny characterizations of the upper-class bureaucrats running the Foreign Office --- the British are pilloried in the way that only the British can pillory themselves. But after that, the film loses its way in a conventional farcical plot. Terry-Thomas watchable as always, but the great talent in the cast (Peter Sellers, et al) is largely wasted.A diverting, but not great film.\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pos_clean[random_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['partially'], ['from'], ['the'], ['perceived'], ['need'], ['one'], ['feels'], ['to'], ['include'], ['a'], ['conventional'], ['love'], ['story'], ['in'], ['the'], ['plot'], ['to'], ['make'], ['the'], ['film'], ['more'], ['marketable'], ['to'], ['a'], ['1950'], [\"'s\"], ['movie'], ['going'], ['public'], ['the'], ['film'], ['starts'], ['with'], ['some'], ['wickedly'], ['funny'], ['characterizations'], ['of'], ['the'], ['upper'], ['class'], ['bureaucrats'], ['running'], ['the'], ['foreign'], ['office'], ['---'], ['the'], ['british'], ['are'], ['pilloried'], ['in'], ['the'], ['way'], ['that'], ['only'], ['the'], ['british'], ['can'], ['pillory'], ['themselves'], ['but'], ['after'], ['that'], ['the'], ['film'], ['loses'], ['its'], ['way'], ['in'], ['a'], ['conventional'], ['farcical'], ['plot'], ['terry'], ['thomas'], ['watchable'], ['as'], ['always'], ['but'], ['the'], ['great'], ['talent'], ['in'], ['the'], ['cast'], ['peter'], ['sellers'], ['et'], ['al'], ['is'], ['largely'], ['wasted'], ['a'], ['diverting'], ['but'], ['not'], ['great'], ['film'], ['partially', 'from'], ['from', 'the'], ['the', 'perceived'], ['perceived', 'need'], ['need', 'one'], ['one', 'feels'], ['feels', 'to'], ['to', 'include'], ['include', 'a'], ['a', 'conventional'], ['conventional', 'love'], ['love', 'story'], ['story', 'in'], ['in', 'the'], ['the', 'plot'], ['plot', 'to'], ['to', 'make'], ['make', 'the'], ['the', 'film'], ['film', 'more'], ['more', 'marketable'], ['marketable', 'to'], ['to', 'a'], ['a', '1950'], ['1950', \"'s\"], [\"'s\", 'movie'], ['movie', 'going'], ['going', 'public'], ['public', 'the'], ['the', 'film'], ['film', 'starts'], ['starts', 'with'], ['with', 'some'], ['some', 'wickedly'], ['wickedly', 'funny'], ['funny', 'characterizations'], ['characterizations', 'of'], ['of', 'the'], ['the', 'upper'], ['upper', 'class'], ['class', 'bureaucrats'], ['bureaucrats', 'running'], ['running', 'the'], ['the', 'foreign'], ['foreign', 'office'], ['office', '---'], ['---', 'the'], ['the', 'british'], ['british', 'are'], ['are', 'pilloried'], ['pilloried', 'in'], ['in', 'the'], ['the', 'way'], ['way', 'that'], ['that', 'only'], ['only', 'the'], ['the', 'british'], ['british', 'can'], ['can', 'pillory'], ['pillory', 'themselves'], ['themselves', 'but'], ['but', 'after'], ['after', 'that'], ['that', 'the'], ['the', 'film'], ['film', 'loses'], ['loses', 'its'], ['its', 'way'], ['way', 'in'], ['in', 'a'], ['a', 'conventional'], ['conventional', 'farcical'], ['farcical', 'plot'], ['plot', 'terry'], ['terry', 'thomas'], ['thomas', 'watchable'], ['watchable', 'as'], ['as', 'always'], ['always', 'but'], ['but', 'the'], ['the', 'great'], ['great', 'talent'], ['talent', 'in'], ['in', 'the'], ['the', 'cast'], ['cast', 'peter'], ['peter', 'sellers'], ['sellers', 'et'], ['et', 'al'], ['al', 'is'], ['is', 'largely'], ['largely', 'wasted'], ['wasted', 'a'], ['a', 'diverting'], ['diverting', 'but'], ['but', 'not'], ['not', 'great'], ['great', 'film'], ['partially', 'from', 'the'], ['from', 'the', 'perceived'], ['the', 'perceived', 'need'], ['perceived', 'need', 'one'], ['need', 'one', 'feels'], ['one', 'feels', 'to'], ['feels', 'to', 'include'], ['to', 'include', 'a'], ['include', 'a', 'conventional'], ['a', 'conventional', 'love'], ['conventional', 'love', 'story'], ['love', 'story', 'in'], ['story', 'in', 'the'], ['in', 'the', 'plot'], ['the', 'plot', 'to'], ['plot', 'to', 'make'], ['to', 'make', 'the'], ['make', 'the', 'film'], ['the', 'film', 'more'], ['film', 'more', 'marketable'], ['more', 'marketable', 'to'], ['marketable', 'to', 'a'], ['to', 'a', '1950'], ['a', '1950', \"'s\"], ['1950', \"'s\", 'movie'], [\"'s\", 'movie', 'going'], ['movie', 'going', 'public'], ['going', 'public', 'the'], ['public', 'the', 'film'], ['the', 'film', 'starts'], ['film', 'starts', 'with'], ['starts', 'with', 'some'], ['with', 'some', 'wickedly'], ['some', 'wickedly', 'funny'], ['wickedly', 'funny', 'characterizations'], ['funny', 'characterizations', 'of'], ['characterizations', 'of', 'the'], ['of', 'the', 'upper'], ['the', 'upper', 'class'], ['upper', 'class', 'bureaucrats'], ['class', 'bureaucrats', 'running'], ['bureaucrats', 'running', 'the'], ['running', 'the', 'foreign'], ['the', 'foreign', 'office'], ['foreign', 'office', '---'], ['office', '---', 'the'], ['---', 'the', 'british'], ['the', 'british', 'are'], ['british', 'are', 'pilloried'], ['are', 'pilloried', 'in'], ['pilloried', 'in', 'the'], ['in', 'the', 'way'], ['the', 'way', 'that'], ['way', 'that', 'only'], ['that', 'only', 'the'], ['only', 'the', 'british'], ['the', 'british', 'can'], ['british', 'can', 'pillory'], ['can', 'pillory', 'themselves'], ['pillory', 'themselves', 'but'], ['themselves', 'but', 'after'], ['but', 'after', 'that'], ['after', 'that', 'the'], ['that', 'the', 'film'], ['the', 'film', 'loses'], ['film', 'loses', 'its'], ['loses', 'its', 'way'], ['its', 'way', 'in'], ['way', 'in', 'a'], ['in', 'a', 'conventional'], ['a', 'conventional', 'farcical'], ['conventional', 'farcical', 'plot'], ['farcical', 'plot', 'terry'], ['plot', 'terry', 'thomas'], ['terry', 'thomas', 'watchable'], ['thomas', 'watchable', 'as'], ['watchable', 'as', 'always'], ['as', 'always', 'but'], ['always', 'but', 'the'], ['but', 'the', 'great'], ['the', 'great', 'talent'], ['great', 'talent', 'in'], ['talent', 'in', 'the'], ['in', 'the', 'cast'], ['the', 'cast', 'peter'], ['cast', 'peter', 'sellers'], ['peter', 'sellers', 'et'], ['sellers', 'et', 'al'], ['et', 'al', 'is'], ['al', 'is', 'largely'], ['is', 'largely', 'wasted'], ['largely', 'wasted', 'a'], ['wasted', 'a', 'diverting'], ['a', 'diverting', 'but'], ['diverting', 'but', 'not'], ['but', 'not', 'great'], ['not', 'great', 'film']]\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "tokens = tokenize(train_pos_clean[random_text], n_gram = 3)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging neg and pos examples - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check the order of concatenation\n",
    "train_data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_clean = train_pos_clean + train_neg_clean\n",
    "len(train_all_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging neg and pos examples - Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check the order of concatenation\n",
    "test_data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all_clean = test_pos_clean + test_neg_clean\n",
    "len(test_all_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training -> Training + Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# should be smaller than 25000\n",
    "training_size = 20000\n",
    "\n",
    "assert training_size < 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_index = np.random.permutation(len(train_all_clean))\n",
    "print(len(shuffled_index))\n",
    "print(shuffled_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_index[:training_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "training_all_clean = [train_all_clean[i] for i in shuffled_index[:training_size]]\n",
    "training_labels = [train_data_labels[i] for i in shuffled_index[:training_size]]\n",
    "print(len(training_all_clean))\n",
    "print(len(training_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_all_clean = [train_all_clean[i] for i in shuffled_index[training_size:]]\n",
    "validation_labels = [train_data_labels[i] for i in shuffled_index[training_size:]]\n",
    "print(len(validation_all_clean))\n",
    "print(len(validation_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lower_case_remove_punc(parsed):\n",
    "    return [token.text.lower() for token in parsed if (token.text not in punctuations)]\n",
    "\n",
    "def tokenize_dataset(dataset):\n",
    "    token_dataset = []\n",
    "    # we are keeping track of all tokens in dataset\n",
    "    # in order to create vocabulary later\n",
    "    all_tokens = []\n",
    "\n",
    "    for sample in tqdm_notebook(tokenizer.pipe(dataset, disable=['parser', 'tagger', 'ner'], batch_size=512, n_threads=1)):\n",
    "        tokens = lower_case_remove_punc(sample)\n",
    "        token_dataset.append(tokens)\n",
    "        all_tokens += tokens\n",
    "\n",
    "    return token_dataset, all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train set tokens\n",
    "print (\"Tokenizing train data\")\n",
    "train_data_tokens, all_train_tokens = tokenize_dataset(training_all_clean)\n",
    "pkl.dump(train_data_tokens, open(\"train_data_tokens.p\", \"wb\"))\n",
    "pkl.dump(all_train_tokens, open(\"all_train_tokens.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val set tokens\n",
    "print (\"Tokenizing val data\")\n",
    "val_data_tokens, _ = tokenize_dataset(validation_all_clean)\n",
    "pkl.dump(val_data_tokens, open(\"val_data_tokens.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set tokens\n",
    "print (\"Tokenizing test data\")\n",
    "test_data_tokens, _ = tokenize_dataset(test_all_clean)\n",
    "pkl.dump(test_data_tokens, open(\"test_data_tokens.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(train_data_tokens[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_train_tokens[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove blank space tokens\n",
    "\n",
    "In the above tokenization, some blankspace strings were observed, thus this section adresses that by deleting them from the token list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# blankspaces = [\" \",\"  \",\"   \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def remove_blankspaces(review):\n",
    "    \n",
    "#     review = [x for x in review if x not in blankspaces] \n",
    "    \n",
    "#     return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(remove_blankspaces(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_data_tokens_clean = [remove_blankspaces(token) for token in train_data_tokens]\n",
    "# len(train_data_tokens_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all_train_tokens_clean = remove_blankspaces(all_train_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(set(all_train_tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we are going to create the vocabulary of most common 10,000 tokens in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "max_vocab_size = 10000\n",
    "# save index 0 for unk and 1 for pad\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "\n",
    "def build_vocab(all_tokens):\n",
    "    # Returns:\n",
    "    # id2token: list of tokens, where id2token[i] returns token that corresponds to token i\n",
    "    # token2id: dictionary where keys represent tokens and corresponding values represent indices\n",
    "    token_counter = Counter(all_tokens)\n",
    "    vocab, count = zip(*token_counter.most_common(max_vocab_size))\n",
    "    id2token = list(vocab)\n",
    "    token2id = dict(zip(vocab, range(2,2+len(vocab)))) \n",
    "    id2token = ['<pad>', '<unk>'] + id2token\n",
    "    token2id['<pad>'] = PAD_IDX \n",
    "    token2id['<unk>'] = UNK_IDX\n",
    "    return token2id, id2token\n",
    "\n",
    "token2id, id2token = build_vocab(all_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check the dictionary by loading random token from it\n",
    "\n",
    "random_token_id = random.randint(0, len(id2token)-1)\n",
    "random_token = id2token[random_token_id]\n",
    "\n",
    "print (\"Token id {} ; token {}\".format(random_token_id, id2token[random_token_id]))\n",
    "print (\"Token {}; token id {}\".format(random_token, token2id[random_token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert token to id in the dataset\n",
    "def token2index_dataset(tokens_data):\n",
    "    indices_data = []\n",
    "    for tokens in tokens_data:\n",
    "        index_list = [token2id[token] if token in token2id else UNK_IDX for token in tokens]\n",
    "        indices_data.append(index_list)\n",
    "    return indices_data\n",
    "\n",
    "train_data_indices = token2index_dataset(train_data_tokens)\n",
    "val_data_indices = token2index_dataset(val_data_tokens)\n",
    "test_data_indices = token2index_dataset(test_data_tokens)\n",
    "\n",
    "# double checking\n",
    "print (\"Train dataset size is {}\".format(len(train_data_indices)))\n",
    "print (\"Val dataset size is {}\".format(len(val_data_indices)))\n",
    "print (\"Test dataset size is {}\".format(len(test_data_indices)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_SENTENCE_LENGTH = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class IMDBDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's \n",
    "    readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_list, target_list):\n",
    "        \"\"\"\n",
    "        @param data_list: list of newsgroup tokens \n",
    "        @param target_list: list of newsgroup targets \n",
    "\n",
    "        \"\"\"\n",
    "        self.data_list = data_list\n",
    "        self.target_list = target_list\n",
    "        assert (len(self.data_list) == len(self.target_list))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        \n",
    "        token_idx = self.data_list[key][:MAX_SENTENCE_LENGTH]\n",
    "        label = self.target_list[key]\n",
    "        return [token_idx, len(token_idx), label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imdb_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    length_list = []\n",
    "    #print(\"collate batch: \", batch[0][0])\n",
    "    #batch[0][0] = batch[0][0][:MAX_SENTENCE_LENGTH]\n",
    "    for datum in batch:\n",
    "        label_list.append(datum[2])\n",
    "        length_list.append(datum[1])\n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        padded_vec = np.pad(np.array(datum[0]), \n",
    "                                pad_width=((0,MAX_SENTENCE_LENGTH-datum[1])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list.append(padded_vec)\n",
    "    return [torch.from_numpy(np.array(data_list)), \n",
    "            torch.LongTensor(length_list), \n",
    "            torch.LongTensor(label_list)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_dataset = IMDBDataset(train_data_indices, training_labels)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=imdb_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset = IMDBDataset(val_data_indices, validation_labels)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=imdb_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_dataset = IMDBDataset(test_data_indices, test_data_labels)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=imdb_func,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of N-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BagOfWords(nn.Module):\n",
    "    \"\"\"\n",
    "    BagOfNgrams classification model\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, emb_dim):\n",
    "        \"\"\"\n",
    "        @param vocab_size: size of the vocabulary. \n",
    "        @param emb_dim: size of the word embedding\n",
    "        \"\"\"\n",
    "        super(BagOfNgrams, self).__init__()\n",
    "        # pay attention to padding_idx \n",
    "        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        self.linear = nn.Linear(emb_dim,20)\n",
    "    \n",
    "    def forward(self, data, length):\n",
    "        \"\"\"\n",
    "        \n",
    "        @param data: matrix of size (batch_size, max_sentence_length). Each row in data represents a \n",
    "            review that is represented using n-gram index. Note that they are padded to have same length.\n",
    "        @param length: an int tensor of size (batch_size), which represents the non-trivial (excludes padding)\n",
    "            length of each sentences in the data.\n",
    "        \"\"\"\n",
    "        out = self.embed(data)\n",
    "        out = torch.sum(out, dim=1)\n",
    "        out /= length.view(length.size()[0],1).expand_as(out).float()\n",
    "     \n",
    "        # return logits\n",
    "        out = self.linear(out.float())\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_dim = 100\n",
    "model = BagOfNgrams(len(id2token), emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "num_epochs = 10 # number epoch to train\n",
    "\n",
    "# Criterion and Optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()  \n",
    "## try both sgd and adam\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for testing the model\n",
    "def test_model(loader, model):\n",
    "    \"\"\"\n",
    "    Help function that tests the model's performance on a dataset\n",
    "    @param: loader - data loader for the dataset to test against\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    for data, lengths, labels in loader:\n",
    "        data_batch, length_batch, label_batch = data, lengths, labels\n",
    "        outputs = F.softmax(model(data_batch, length_batch), dim=1)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "    return (100 * correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (data, lengths, labels) in enumerate(train_loader):\n",
    "        model.train()\n",
    "        data_batch, length_batch, label_batch = data, lengths, labels\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data_batch, length_batch)\n",
    "        loss = criterion(outputs, label_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # check training score every 100 iterations\n",
    "        ## validate every 100 iterations\n",
    "        if i > 0 and i % 50 == 0:\n",
    "            # validate\n",
    "            val_acc = test_model(val_loader, model)\n",
    "            train_acc = test_model(train_loader, model)\n",
    "            print('Epoch: [{}/{}], Step: [{}/{}], Training Acc: {},Validation Acc: {}'.format( \n",
    "                       epoch+1, num_epochs, i+1, \n",
    "                len(train_loader), train_acc, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
