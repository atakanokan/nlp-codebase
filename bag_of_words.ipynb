{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atakanokan/anaconda/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import string\n",
    "import requests\n",
    "import io\n",
    "from zipfile import ZipFile\n",
    "from tensorflow.contrib import learn\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start a computation graph session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start a graph session\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if data was downloaded, otherwise download it and save for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_file_name = os.path.join('temp','temp_spam_data.csv')\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "if not os.path.exists('temp'):\n",
    "    os.makedirs('temp')\n",
    "\n",
    "if os.path.isfile(save_file_name):\n",
    "    text_data = []\n",
    "    with open(save_file_name, 'r') as temp_output_file:\n",
    "        reader = csv.reader(temp_output_file)\n",
    "        for row in reader:\n",
    "            text_data.append(row)\n",
    "else:\n",
    "    zip_url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip'\n",
    "    r = requests.get(zip_url)\n",
    "    z = ZipFile(io.BytesIO(r.content))\n",
    "    file = z.read('SMSSpamCollection')\n",
    "    # Format Data\n",
    "    text_data = file.decode()\n",
    "    text_data = text_data.encode('ascii',errors='ignore')\n",
    "    text_data = text_data.decode().split('\\n')\n",
    "    text_data = [x.split('\\t') for x in text_data if len(x)>=1]\n",
    "    \n",
    "    # And write to csv\n",
    "    with open(save_file_name, 'w') as temp_output_file:\n",
    "        writer = csv.writer(temp_output_file)\n",
    "        writer.writerows(text_data)\n",
    "\n",
    "texts = [x[1] for x in text_data]\n",
    "target = [x[0] for x in text_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce the potential vocabulary size, we normalize the text. To do this, we remove the influence of capitalization and numbers in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Relabel 'spam' as 1, 'ham' as 0\n",
    "target = [1 if x=='spam' else 0 for x in target]\n",
    "\n",
    "# Normalize text\n",
    "# Lower case\n",
    "texts = [x.lower() for x in texts]\n",
    "\n",
    "# Remove punctuation\n",
    "texts = [''.join(c for c in x if c not in string.punctuation) for x in texts]\n",
    "\n",
    "# Remove numbers\n",
    "texts = [''.join(c for c in x if c not in '0123456789') for x in texts]\n",
    "\n",
    "# Trim extra whitespace\n",
    "texts = [' '.join(x.split()) for x in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine a good sentence length to pad/crop at, we plot a histogram of text lengths (in words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nljkHvZlZ5v4/T4UmwEFrUagAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1204cef98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# Plot histogram of text lengths\n",
    "text_lengths = [len(x.split()) for x in texts]\n",
    "text_lengths = [x for x in text_lengths if x < 50]\n",
    "plt.hist(text_lengths, bins=25)\n",
    "plt.title('Histogram of # of Words in Texts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We crop/pad all texts to be 25 words long. We also will filter out any words that do not appear at least 3 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Choose max text word length at 25\n",
    "sentence_size = 25\n",
    "min_word_freq = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow has a built in text processing function called VocabularyProcessor(). We use this function to process the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-17f2a5f5ce7e>:2: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-17f2a5f5ce7e>:2: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/atakanokan/anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/atakanokan/anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/atakanokan/anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:203: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/atakanokan/anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:203: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n"
     ]
    }
   ],
   "source": [
    "# Setup vocabulary processor\n",
    "vocab_processor = learn.preprocessing.VocabularyProcessor(sentence_size, min_frequency=min_word_freq)\n",
    "\n",
    "# Have to fit transform to get length of unique words.\n",
    "vocab_processor.transform(texts)\n",
    "transformed_texts = np.array([x for x in vocab_processor.transform(texts)])\n",
    "embedding_size = len(np.unique(transformed_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test our logistic model (predicting spam/ham), we split the texts into a train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split up data set into train/test\n",
    "train_indices = np.random.choice(len(texts), round(len(texts)*0.8), replace=False)\n",
    "test_indices = np.array(list(set(range(len(texts))) - set(train_indices)))\n",
    "texts_train = [x for ix, x in enumerate(texts) if ix in train_indices]\n",
    "texts_test = [x for ix, x in enumerate(texts) if ix in test_indices]\n",
    "target_train = [x for ix, x in enumerate(target) if ix in train_indices]\n",
    "target_test = [x for ix, x in enumerate(target) if ix in test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For one-hot-encoding, we setup an identity matrix for the TensorFlow embedding lookup.\n",
    "\n",
    "We also create the variables and placeholders for the logistic regression we will perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup Index Matrix for one-hot-encoding\n",
    "identity_mat = tf.diag(tf.ones(shape=[embedding_size]))\n",
    "\n",
    "# Create variables for logistic regression\n",
    "A = tf.Variable(tf.random_normal(shape=[embedding_size,1]))\n",
    "b = tf.Variable(tf.random_normal(shape=[1,1]))\n",
    "\n",
    "# Initialize placeholders\n",
    "x_data = tf.placeholder(shape=[sentence_size], dtype=tf.int32)\n",
    "y_target = tf.placeholder(shape=[1, 1], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create the text-word embedding lookup with the prior identity matrix.\n",
    "\n",
    "Our logistic regression will use the counts of the words as the input. The counts are created by summing the embedding output across the rows.\n",
    "\n",
    "Then we declare the logistic regression operations. Note that we do not wrap the logistic operations in the sigmoid function because this will be done in the loss function later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Text-Vocab Embedding\n",
    "x_embed = tf.nn.embedding_lookup(identity_mat, x_data)\n",
    "x_col_sums = tf.reduce_sum(x_embed, 0)\n",
    "\n",
    "# Declare model operations\n",
    "x_col_sums_2D = tf.expand_dims(x_col_sums, 0)\n",
    "model_output = tf.add(tf.matmul(x_col_sums_2D, A), b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we declare our loss function (which has the sigmoid built in), prediction operations, optimizer, and initialize the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declare loss function (Cross Entropy loss)\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=model_output, labels=y_target))\n",
    "\n",
    "# Prediction operation\n",
    "prediction = tf.sigmoid(model_output)\n",
    "\n",
    "# Declare optimizer\n",
    "my_opt = tf.train.GradientDescentOptimizer(0.001)\n",
    "train_step = my_opt.minimize(loss)\n",
    "\n",
    "# Intitialize Variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we loop through the iterations and fit the logistic regression on wether or not the text is spam or ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Over 4459 Sentences.\n",
      "Training Observation #10: Loss = 2.2550027\n",
      "Training Observation #20: Loss = 0.01644477\n",
      "Training Observation #30: Loss = 0.46738636\n",
      "Training Observation #40: Loss = 0.2508839\n",
      "Training Observation #50: Loss = 0.039120324\n",
      "Training Observation #60: Loss = 0.25523725\n",
      "Training Observation #70: Loss = 0.42048928\n",
      "Training Observation #80: Loss = 0.00090670114\n",
      "Training Observation #90: Loss = 0.0029919338\n",
      "Training Observation #100: Loss = 0.021491338\n",
      "Training Observation #110: Loss = 0.011196385\n",
      "Training Observation #120: Loss = 0.008090788\n",
      "Training Observation #130: Loss = 0.043880336\n",
      "Training Observation #140: Loss = 0.007570286\n",
      "Training Observation #150: Loss = 0.0010308262\n",
      "Training Observation #160: Loss = 0.012622298\n",
      "Training Observation #170: Loss = 0.006370655\n",
      "Training Observation #180: Loss = 0.0037109894\n",
      "Training Observation #190: Loss = 0.025819646\n",
      "Training Observation #200: Loss = 0.2708278\n",
      "Training Observation #210: Loss = 0.0058802553\n",
      "Training Observation #220: Loss = 3.043666\n",
      "Training Observation #230: Loss = 0.06446792\n",
      "Training Observation #240: Loss = 0.00648922\n",
      "Training Observation #250: Loss = 0.021023376\n",
      "Training Observation #260: Loss = 0.03992156\n",
      "Training Observation #270: Loss = 0.0019437518\n",
      "Training Observation #280: Loss = 0.14398387\n",
      "Training Observation #290: Loss = 0.0005908365\n",
      "Training Observation #300: Loss = 0.57884973\n",
      "Training Observation #310: Loss = 3.1894727\n",
      "Training Observation #320: Loss = 0.00018135464\n",
      "Training Observation #330: Loss = 0.0006342096\n",
      "Training Observation #340: Loss = 0.06540169\n",
      "Training Observation #350: Loss = 0.00088193995\n",
      "Training Observation #360: Loss = 0.0013644779\n",
      "Training Observation #370: Loss = 0.0020510654\n",
      "Training Observation #380: Loss = 1.0024588e-05\n",
      "Training Observation #390: Loss = 0.027950555\n",
      "Training Observation #400: Loss = 0.003554744\n",
      "Training Observation #410: Loss = 0.26524892\n",
      "Training Observation #420: Loss = 0.0016344535\n",
      "Training Observation #430: Loss = 0.044534918\n",
      "Training Observation #440: Loss = 0.021654304\n",
      "Training Observation #450: Loss = 0.00046790592\n",
      "Training Observation #460: Loss = 0.008150137\n",
      "Training Observation #470: Loss = 0.6211891\n",
      "Training Observation #480: Loss = 1.1801418\n",
      "Training Observation #490: Loss = 3.6568046\n",
      "Training Observation #500: Loss = 0.020044416\n",
      "Training Observation #510: Loss = 3.109392e-06\n",
      "Training Observation #520: Loss = 0.021901384\n",
      "Training Observation #530: Loss = 3.450441\n",
      "Training Observation #540: Loss = 0.0022823147\n",
      "Training Observation #550: Loss = 0.045670398\n",
      "Training Observation #560: Loss = 1.504441\n",
      "Training Observation #570: Loss = 3.1721005\n",
      "Training Observation #580: Loss = 0.61650586\n",
      "Training Observation #590: Loss = 0.018497212\n",
      "Training Observation #600: Loss = 0.029260278\n",
      "Training Observation #610: Loss = 0.0024740845\n",
      "Training Observation #620: Loss = 1.1732424e-06\n",
      "Training Observation #630: Loss = 1.189227\n",
      "Training Observation #640: Loss = 0.41942105\n",
      "Training Observation #650: Loss = 0.28790915\n",
      "Training Observation #660: Loss = 2.9674308\n",
      "Training Observation #670: Loss = 0.0002646861\n",
      "Training Observation #680: Loss = 7.668337\n",
      "Training Observation #690: Loss = 1.8171021\n",
      "Training Observation #700: Loss = 0.39651155\n",
      "Training Observation #710: Loss = 5.70032\n",
      "Training Observation #720: Loss = 0.14709875\n",
      "Training Observation #730: Loss = 0.015579568\n",
      "Training Observation #740: Loss = 1.794082\n",
      "Training Observation #750: Loss = 5.223902\n",
      "Training Observation #760: Loss = 0.21813881\n",
      "Training Observation #770: Loss = 0.10725599\n",
      "Training Observation #780: Loss = 0.010711971\n",
      "Training Observation #790: Loss = 0.25144577\n",
      "Training Observation #800: Loss = 0.082592025\n",
      "Training Observation #810: Loss = 0.00073743943\n",
      "Training Observation #820: Loss = 0.08833034\n",
      "Training Observation #830: Loss = 0.00090504193\n",
      "Training Observation #840: Loss = 3.6580823e-05\n",
      "Training Observation #850: Loss = 0.16469085\n",
      "Training Observation #860: Loss = 5.5929877e-06\n",
      "Training Observation #870: Loss = 0.0006999097\n",
      "Training Observation #880: Loss = 0.007008484\n",
      "Training Observation #890: Loss = 4.862073\n",
      "Training Observation #900: Loss = 0.05905228\n",
      "Training Observation #910: Loss = 0.18300033\n",
      "Training Observation #920: Loss = 0.00034742453\n",
      "Training Observation #930: Loss = 1.3601677\n",
      "Training Observation #940: Loss = 0.0018543729\n",
      "Training Observation #950: Loss = 0.008830273\n",
      "Training Observation #960: Loss = 0.00019427222\n",
      "Training Observation #970: Loss = 0.059219025\n",
      "Training Observation #980: Loss = 0.00042373376\n",
      "Training Observation #990: Loss = 0.00035449443\n",
      "Training Observation #1000: Loss = 6.085893e-05\n",
      "Training Observation #1010: Loss = 0.0457512\n",
      "Training Observation #1020: Loss = 0.22764638\n",
      "Training Observation #1030: Loss = 0.7612619\n",
      "Training Observation #1040: Loss = 0.0008638467\n",
      "Training Observation #1050: Loss = 0.014474233\n",
      "Training Observation #1060: Loss = 6.9867754\n",
      "Training Observation #1070: Loss = 0.013606739\n",
      "Training Observation #1080: Loss = 0.0013704819\n",
      "Training Observation #1090: Loss = 0.003764704\n",
      "Training Observation #1100: Loss = 0.50747186\n",
      "Training Observation #1110: Loss = 0.001894372\n",
      "Training Observation #1120: Loss = 0.07457151\n",
      "Training Observation #1130: Loss = 0.005225635\n",
      "Training Observation #1140: Loss = 0.00045429007\n",
      "Training Observation #1150: Loss = 0.0046032825\n",
      "Training Observation #1160: Loss = 0.47321716\n",
      "Training Observation #1170: Loss = 0.44457227\n",
      "Training Observation #1180: Loss = 0.16525766\n",
      "Training Observation #1190: Loss = 0.0008593151\n",
      "Training Observation #1200: Loss = 0.032495152\n",
      "Training Observation #1210: Loss = 0.0033289576\n",
      "Training Observation #1220: Loss = 0.041585676\n",
      "Training Observation #1230: Loss = 1.13426895e-05\n",
      "Training Observation #1240: Loss = 0.0047526397\n",
      "Training Observation #1250: Loss = 0.00038825895\n",
      "Training Observation #1260: Loss = 0.02333822\n",
      "Training Observation #1270: Loss = 0.00060136116\n",
      "Training Observation #1280: Loss = 0.002544292\n",
      "Training Observation #1290: Loss = 0.056323834\n",
      "Training Observation #1300: Loss = 9.435957e-05\n",
      "Training Observation #1310: Loss = 7.950966e-05\n",
      "Training Observation #1320: Loss = 0.0047670566\n",
      "Training Observation #1330: Loss = 0.33667314\n",
      "Training Observation #1340: Loss = 0.09785217\n",
      "Training Observation #1350: Loss = 1.1604866\n",
      "Training Observation #1360: Loss = 1.7133335\n",
      "Training Observation #1370: Loss = 0.016768886\n",
      "Training Observation #1380: Loss = 9.0857935\n",
      "Training Observation #1390: Loss = 0.009449083\n",
      "Training Observation #1400: Loss = 5.3715947e-05\n",
      "Training Observation #1410: Loss = 0.0026814505\n",
      "Training Observation #1420: Loss = 0.56361246\n",
      "Training Observation #1430: Loss = 0.026036575\n",
      "Training Observation #1440: Loss = 0.011289358\n",
      "Training Observation #1450: Loss = 0.015354564\n",
      "Training Observation #1460: Loss = 0.0003624427\n",
      "Training Observation #1470: Loss = 2.9322\n",
      "Training Observation #1480: Loss = 0.024331484\n",
      "Training Observation #1490: Loss = 0.0007673616\n",
      "Training Observation #1500: Loss = 0.0042818757\n",
      "Training Observation #1510: Loss = 0.00069174875\n",
      "Training Observation #1520: Loss = 0.008249558\n",
      "Training Observation #1530: Loss = 0.03718541\n",
      "Training Observation #1540: Loss = 6.9906804e-05\n",
      "Training Observation #1550: Loss = 0.039632417\n",
      "Training Observation #1560: Loss = 1.4094813\n",
      "Training Observation #1570: Loss = 0.11745268\n",
      "Training Observation #1580: Loss = 3.7281814\n",
      "Training Observation #1590: Loss = 0.0003208359\n",
      "Training Observation #1600: Loss = 0.014707789\n",
      "Training Observation #1610: Loss = 0.06549091\n",
      "Training Observation #1620: Loss = 0.0721562\n",
      "Training Observation #1630: Loss = 0.049929902\n",
      "Training Observation #1640: Loss = 0.011695125\n",
      "Training Observation #1650: Loss = 0.012766014\n",
      "Training Observation #1660: Loss = 0.00013034644\n",
      "Training Observation #1670: Loss = 0.0010177513\n",
      "Training Observation #1680: Loss = 0.0002659313\n",
      "Training Observation #1690: Loss = 0.0027868617\n",
      "Training Observation #1700: Loss = 0.0005134922\n",
      "Training Observation #1710: Loss = 0.0003061618\n",
      "Training Observation #1720: Loss = 0.012968763\n",
      "Training Observation #1730: Loss = 0.0010124943\n",
      "Training Observation #1740: Loss = 0.04116913\n",
      "Training Observation #1750: Loss = 0.009616741\n",
      "Training Observation #1760: Loss = 0.0019057989\n",
      "Training Observation #1770: Loss = 0.0029415744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Observation #1780: Loss = 4.321352e-05\n",
      "Training Observation #1790: Loss = 0.00055492064\n",
      "Training Observation #1800: Loss = 0.004362749\n",
      "Training Observation #1810: Loss = 0.0038150784\n",
      "Training Observation #1820: Loss = 0.00044936757\n",
      "Training Observation #1830: Loss = 6.3979125\n",
      "Training Observation #1840: Loss = 2.3190687e-05\n",
      "Training Observation #1850: Loss = 0.00048226624\n",
      "Training Observation #1860: Loss = 0.00063637365\n",
      "Training Observation #1870: Loss = 0.00063321966\n",
      "Training Observation #1880: Loss = 0.00042678288\n",
      "Training Observation #1890: Loss = 0.0068358677\n",
      "Training Observation #1900: Loss = 0.003993897\n",
      "Training Observation #1910: Loss = 0.0014085833\n",
      "Training Observation #1920: Loss = 0.06156337\n",
      "Training Observation #1930: Loss = 0.016269425\n",
      "Training Observation #1940: Loss = 0.00035674885\n",
      "Training Observation #1950: Loss = 0.727706\n",
      "Training Observation #1960: Loss = 0.0070212903\n",
      "Training Observation #1970: Loss = 0.00013279752\n",
      "Training Observation #1980: Loss = 0.011412739\n",
      "Training Observation #1990: Loss = 0.00018753819\n",
      "Training Observation #2000: Loss = 0.04583712\n",
      "Training Observation #2010: Loss = 0.00036724284\n",
      "Training Observation #2020: Loss = 0.025995841\n",
      "Training Observation #2030: Loss = 0.00065038045\n",
      "Training Observation #2040: Loss = 0.0027188046\n",
      "Training Observation #2050: Loss = 0.0002252881\n",
      "Training Observation #2060: Loss = 0.00013488336\n",
      "Training Observation #2070: Loss = 5.286032\n",
      "Training Observation #2080: Loss = 0.0003554674\n",
      "Training Observation #2090: Loss = 0.0013072231\n",
      "Training Observation #2100: Loss = 0.00024044703\n",
      "Training Observation #2110: Loss = 0.0044769337\n",
      "Training Observation #2120: Loss = 0.0015388033\n",
      "Training Observation #2130: Loss = 3.9898863e-05\n",
      "Training Observation #2140: Loss = 0.00029355747\n",
      "Training Observation #2150: Loss = 0.009253593\n",
      "Training Observation #2160: Loss = 0.00075522944\n",
      "Training Observation #2170: Loss = 0.009510386\n",
      "Training Observation #2180: Loss = 0.00029439564\n",
      "Training Observation #2190: Loss = 3.0618453e-06\n",
      "Training Observation #2200: Loss = 0.001744866\n",
      "Training Observation #2210: Loss = 0.004742346\n",
      "Training Observation #2220: Loss = 0.00016027172\n",
      "Training Observation #2230: Loss = 0.13646884\n",
      "Training Observation #2240: Loss = 0.000115410614\n",
      "Training Observation #2250: Loss = 2.4037516\n",
      "Training Observation #2260: Loss = 0.00010579499\n",
      "Training Observation #2270: Loss = 0.00081694644\n",
      "Training Observation #2280: Loss = 3.142562e-05\n",
      "Training Observation #2290: Loss = 4.9809093\n",
      "Training Observation #2300: Loss = 0.1778813\n",
      "Training Observation #2310: Loss = 0.0025197172\n",
      "Training Observation #2320: Loss = 0.00091660797\n",
      "Training Observation #2330: Loss = 0.00012121568\n",
      "Training Observation #2340: Loss = 0.000952117\n",
      "Training Observation #2350: Loss = 0.18170156\n",
      "Training Observation #2360: Loss = 0.0011625951\n",
      "Training Observation #2370: Loss = 4.5282345\n",
      "Training Observation #2380: Loss = 1.3199012\n",
      "Training Observation #2390: Loss = 0.008424351\n",
      "Training Observation #2400: Loss = 0.030188067\n",
      "Training Observation #2410: Loss = 2.21305\n",
      "Training Observation #2420: Loss = 0.0005192447\n",
      "Training Observation #2430: Loss = 0.0020463136\n",
      "Training Observation #2440: Loss = 0.0010157998\n",
      "Training Observation #2450: Loss = 2.272443e-05\n",
      "Training Observation #2460: Loss = 0.00028755856\n",
      "Training Observation #2470: Loss = 0.0006226684\n",
      "Training Observation #2480: Loss = 0.005482708\n",
      "Training Observation #2490: Loss = 0.025166688\n",
      "Training Observation #2500: Loss = 0.12579569\n",
      "Training Observation #2510: Loss = 0.00037853306\n",
      "Training Observation #2520: Loss = 0.0070860093\n",
      "Training Observation #2530: Loss = 2.3744385\n",
      "Training Observation #2540: Loss = 8.288746\n",
      "Training Observation #2550: Loss = 0.57615346\n",
      "Training Observation #2560: Loss = 0.02998224\n",
      "Training Observation #2570: Loss = 0.0011782588\n",
      "Training Observation #2580: Loss = 1.2526145\n",
      "Training Observation #2590: Loss = 0.00024071062\n",
      "Training Observation #2600: Loss = 0.8439134\n",
      "Training Observation #2610: Loss = 0.001333394\n",
      "Training Observation #2620: Loss = 0.00013328929\n",
      "Training Observation #2630: Loss = 0.00021484258\n",
      "Training Observation #2640: Loss = 5.9475856e-06\n",
      "Training Observation #2650: Loss = 2.5528612e-05\n",
      "Training Observation #2660: Loss = 0.0075912913\n",
      "Training Observation #2670: Loss = 0.004022673\n",
      "Training Observation #2680: Loss = 0.00058003626\n",
      "Training Observation #2690: Loss = 0.064476036\n",
      "Training Observation #2700: Loss = 0.0008055317\n",
      "Training Observation #2710: Loss = 0.00014366455\n",
      "Training Observation #2720: Loss = 0.012513696\n",
      "Training Observation #2730: Loss = 7.9933014\n",
      "Training Observation #2740: Loss = 5.112023\n",
      "Training Observation #2750: Loss = 0.0054409904\n",
      "Training Observation #2760: Loss = 0.014566541\n",
      "Training Observation #2770: Loss = 0.000110858906\n",
      "Training Observation #2780: Loss = 4.9830833e-05\n",
      "Training Observation #2790: Loss = 0.26244608\n",
      "Training Observation #2800: Loss = 0.0014093386\n",
      "Training Observation #2810: Loss = 0.7115556\n",
      "Training Observation #2820: Loss = 1.4040936\n",
      "Training Observation #2830: Loss = 0.08524789\n",
      "Training Observation #2840: Loss = 0.0013402535\n",
      "Training Observation #2850: Loss = 1.3157578\n",
      "Training Observation #2860: Loss = 0.002552079\n",
      "Training Observation #2870: Loss = 1.7728933\n",
      "Training Observation #2880: Loss = 0.0003369818\n",
      "Training Observation #2890: Loss = 0.0011660302\n",
      "Training Observation #2900: Loss = 0.00031672337\n",
      "Training Observation #2910: Loss = 4.096488\n",
      "Training Observation #2920: Loss = 0.0077604507\n",
      "Training Observation #2930: Loss = 0.00032566919\n",
      "Training Observation #2940: Loss = 0.002502791\n",
      "Training Observation #2950: Loss = 0.0006912174\n",
      "Training Observation #2960: Loss = 0.0013207226\n",
      "Training Observation #2970: Loss = 0.0007429008\n",
      "Training Observation #2980: Loss = 0.052184306\n",
      "Training Observation #2990: Loss = 0.00016064095\n",
      "Training Observation #3000: Loss = 0.008464198\n",
      "Training Observation #3010: Loss = 0.024747344\n",
      "Training Observation #3020: Loss = 0.0014582223\n",
      "Training Observation #3030: Loss = 2.2811577\n",
      "Training Observation #3040: Loss = 0.01583407\n",
      "Training Observation #3050: Loss = 5.768092e-05\n",
      "Training Observation #3060: Loss = 4.335865\n",
      "Training Observation #3070: Loss = 0.0016052234\n",
      "Training Observation #3080: Loss = 0.0012689009\n",
      "Training Observation #3090: Loss = 0.0019320066\n",
      "Training Observation #3100: Loss = 0.00024094302\n",
      "Training Observation #3110: Loss = 0.00034973\n",
      "Training Observation #3120: Loss = 2.7950788e-05\n",
      "Training Observation #3130: Loss = 0.13403092\n",
      "Training Observation #3140: Loss = 0.00073127344\n",
      "Training Observation #3150: Loss = 0.004999486\n",
      "Training Observation #3160: Loss = 0.0014101386\n",
      "Training Observation #3170: Loss = 4.2211697e-05\n",
      "Training Observation #3180: Loss = 0.24421407\n",
      "Training Observation #3190: Loss = 4.408072\n",
      "Training Observation #3200: Loss = 0.50652397\n",
      "Training Observation #3210: Loss = 5.4664946\n",
      "Training Observation #3220: Loss = 0.019743009\n",
      "Training Observation #3230: Loss = 0.000522414\n",
      "Training Observation #3240: Loss = 0.0041167606\n",
      "Training Observation #3250: Loss = 6.146956\n",
      "Training Observation #3260: Loss = 0.0150373\n",
      "Training Observation #3270: Loss = 1.4563444\n",
      "Training Observation #3280: Loss = 0.005311557\n",
      "Training Observation #3290: Loss = 0.0057795737\n",
      "Training Observation #3300: Loss = 0.00078941055\n",
      "Training Observation #3310: Loss = 6.977451\n",
      "Training Observation #3320: Loss = 0.15848847\n",
      "Training Observation #3330: Loss = 0.03601969\n",
      "Training Observation #3340: Loss = 0.00050076994\n",
      "Training Observation #3350: Loss = 1.5521102e-05\n",
      "Training Observation #3360: Loss = 4.290744\n",
      "Training Observation #3370: Loss = 0.26578102\n",
      "Training Observation #3380: Loss = 0.0037532882\n",
      "Training Observation #3390: Loss = 0.0039260215\n",
      "Training Observation #3400: Loss = 3.7390773e-06\n",
      "Training Observation #3410: Loss = 0.60307115\n",
      "Training Observation #3420: Loss = 6.445477\n",
      "Training Observation #3430: Loss = 3.0028827\n",
      "Training Observation #3440: Loss = 0.44768372\n",
      "Training Observation #3450: Loss = 0.03322803\n",
      "Training Observation #3460: Loss = 0.0076772477\n",
      "Training Observation #3470: Loss = 0.06542162\n",
      "Training Observation #3480: Loss = 0.00079392316\n",
      "Training Observation #3490: Loss = 0.40547302\n",
      "Training Observation #3500: Loss = 0.014830328\n",
      "Training Observation #3510: Loss = 0.00872494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Observation #3520: Loss = 4.3877444\n",
      "Training Observation #3530: Loss = 0.036769085\n",
      "Training Observation #3540: Loss = 0.00031273538\n",
      "Training Observation #3550: Loss = 0.0012476476\n",
      "Training Observation #3560: Loss = 0.0010183917\n",
      "Training Observation #3570: Loss = 0.00039315043\n",
      "Training Observation #3580: Loss = 0.004066246\n",
      "Training Observation #3590: Loss = 0.0022042633\n",
      "Training Observation #3600: Loss = 0.0071450872\n",
      "Training Observation #3610: Loss = 2.2977521\n",
      "Training Observation #3620: Loss = 0.0021307634\n",
      "Training Observation #3630: Loss = 0.42222467\n",
      "Training Observation #3640: Loss = 0.00086315646\n",
      "Training Observation #3650: Loss = 3.557452e-05\n",
      "Training Observation #3660: Loss = 12.681997\n",
      "Training Observation #3670: Loss = 4.7520534e-06\n",
      "Training Observation #3680: Loss = 7.9151134e-05\n",
      "Training Observation #3690: Loss = 0.00069629453\n",
      "Training Observation #3700: Loss = 0.0074146455\n",
      "Training Observation #3710: Loss = 0.0042483537\n",
      "Training Observation #3720: Loss = 0.0064478223\n",
      "Training Observation #3730: Loss = 0.018440325\n",
      "Training Observation #3740: Loss = 0.002107324\n",
      "Training Observation #3750: Loss = 0.0006162471\n",
      "Training Observation #3760: Loss = 0.00015640995\n",
      "Training Observation #3770: Loss = 0.00735783\n",
      "Training Observation #3780: Loss = 0.0017742515\n",
      "Training Observation #3790: Loss = 0.051762268\n",
      "Training Observation #3800: Loss = 0.13470912\n",
      "Training Observation #3810: Loss = 0.0005226195\n",
      "Training Observation #3820: Loss = 0.10986787\n",
      "Training Observation #3830: Loss = 0.0009008618\n",
      "Training Observation #3840: Loss = 8.86331\n",
      "Training Observation #3850: Loss = 0.037397582\n",
      "Training Observation #3860: Loss = 0.1022968\n",
      "Training Observation #3870: Loss = 0.0011869667\n",
      "Training Observation #3880: Loss = 0.007572761\n",
      "Training Observation #3890: Loss = 0.33900735\n",
      "Training Observation #3900: Loss = 0.004904015\n",
      "Training Observation #3910: Loss = 0.00042013195\n",
      "Training Observation #3920: Loss = 4.1415725\n",
      "Training Observation #3930: Loss = 0.0023960536\n",
      "Training Observation #3940: Loss = 0.004118681\n",
      "Training Observation #3950: Loss = 0.018340098\n",
      "Training Observation #3960: Loss = 0.0038478754\n",
      "Training Observation #3970: Loss = 0.006975264\n",
      "Training Observation #3980: Loss = 0.00015809017\n",
      "Training Observation #3990: Loss = 0.043114174\n",
      "Training Observation #4000: Loss = 0.00032019595\n",
      "Training Observation #4010: Loss = 0.102882706\n",
      "Training Observation #4020: Loss = 0.008761152\n",
      "Training Observation #4030: Loss = 0.6546615\n",
      "Training Observation #4040: Loss = 0.023078732\n",
      "Training Observation #4050: Loss = 0.015020606\n",
      "Training Observation #4060: Loss = 0.031387024\n",
      "Training Observation #4070: Loss = 0.014693093\n",
      "Training Observation #4080: Loss = 0.00016493871\n",
      "Training Observation #4090: Loss = 0.005930531\n",
      "Training Observation #4100: Loss = 8.413005e-07\n",
      "Training Observation #4110: Loss = 0.0032360917\n",
      "Training Observation #4120: Loss = 0.0011927038\n",
      "Training Observation #4130: Loss = 0.009812631\n",
      "Training Observation #4140: Loss = 4.843583\n",
      "Training Observation #4150: Loss = 0.00035096705\n",
      "Training Observation #4160: Loss = 0.0029064321\n",
      "Training Observation #4170: Loss = 0.0027321477\n",
      "Training Observation #4180: Loss = 6.6885433\n",
      "Training Observation #4190: Loss = 0.02465345\n",
      "Training Observation #4200: Loss = 0.0022523066\n",
      "Training Observation #4210: Loss = 0.2845863\n",
      "Training Observation #4220: Loss = 2.7464268\n",
      "Training Observation #4230: Loss = 0.009193332\n",
      "Training Observation #4240: Loss = 1.04951\n",
      "Training Observation #4250: Loss = 0.0012920639\n",
      "Training Observation #4260: Loss = 0.14071903\n",
      "Training Observation #4270: Loss = 4.737028e-05\n",
      "Training Observation #4280: Loss = 1.0029825\n",
      "Training Observation #4290: Loss = 0.0005813182\n",
      "Training Observation #4300: Loss = 0.0018461709\n",
      "Training Observation #4310: Loss = 0.002532392\n",
      "Training Observation #4320: Loss = 0.24856848\n",
      "Training Observation #4330: Loss = 0.003275357\n",
      "Training Observation #4340: Loss = 2.3038075\n",
      "Training Observation #4350: Loss = 0.03152847\n",
      "Training Observation #4360: Loss = 0.007853916\n",
      "Training Observation #4370: Loss = 0.06624662\n",
      "Training Observation #4380: Loss = 0.001975053\n",
      "Training Observation #4390: Loss = 0.002547808\n",
      "Training Observation #4400: Loss = 7.627039\n",
      "Training Observation #4410: Loss = 0.0027337966\n",
      "Training Observation #4420: Loss = 0.8560108\n",
      "Training Observation #4430: Loss = 4.1910753\n",
      "Training Observation #4440: Loss = 0.24332859\n",
      "Training Observation #4450: Loss = 0.00096901815\n"
     ]
    }
   ],
   "source": [
    "# Start Logistic Regression\n",
    "print('Starting Training Over {} Sentences.'.format(len(texts_train)))\n",
    "loss_vec = []\n",
    "train_acc_all = []\n",
    "train_acc_avg = []\n",
    "for ix, t in enumerate(vocab_processor.fit_transform(texts_train)):\n",
    "    y_data = [[target_train[ix]]]\n",
    "    \n",
    "    \n",
    "    sess.run(train_step, feed_dict={x_data: t, y_target: y_data})\n",
    "    temp_loss = sess.run(loss, feed_dict={x_data: t, y_target: y_data})\n",
    "    loss_vec.append(temp_loss)\n",
    "    \n",
    "    if (ix+1)%10==0:\n",
    "        print('Training Observation #' + str(ix+1) + ': Loss = ' + str(temp_loss))\n",
    "        \n",
    "    # Keep trailing average of past 50 observations accuracy\n",
    "    # Get prediction of single observation\n",
    "    [[temp_pred]] = sess.run(prediction, feed_dict={x_data:t, y_target:y_data})\n",
    "    # Get True/False if prediction is accurate\n",
    "    train_acc_temp = target_train[ix]==np.round(temp_pred)\n",
    "    train_acc_all.append(train_acc_temp)\n",
    "    if len(train_acc_all) >= 50:\n",
    "        train_acc_avg.append(np.mean(train_acc_all[-50:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a logistic model, we can evaluate the accuracy on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Test Set Accuracy For 1115 Sentences.\n",
      "Test Observation #50\n",
      "Test Observation #100\n",
      "Test Observation #150\n",
      "Test Observation #200\n",
      "Test Observation #250\n",
      "Test Observation #300\n",
      "Test Observation #350\n",
      "Test Observation #400\n",
      "Test Observation #450\n",
      "Test Observation #500\n",
      "Test Observation #550\n",
      "Test Observation #600\n",
      "Test Observation #650\n",
      "Test Observation #700\n",
      "Test Observation #750\n",
      "Test Observation #800\n",
      "Test Observation #850\n",
      "Test Observation #900\n",
      "Test Observation #950\n",
      "Test Observation #1000\n",
      "Test Observation #1050\n",
      "Test Observation #1100\n",
      "\n",
      "Overall Test Accuracy: 0.8385650224215246\n"
     ]
    }
   ],
   "source": [
    "# Get test set accuracy\n",
    "print('Getting Test Set Accuracy For {} Sentences.'.format(len(texts_test)))\n",
    "test_acc_all = []\n",
    "for ix, t in enumerate(vocab_processor.fit_transform(texts_test)):\n",
    "    y_data = [[target_test[ix]]]\n",
    "    \n",
    "    if (ix+1)%50==0:\n",
    "        print('Test Observation #' + str(ix+1))    \n",
    "    \n",
    "    # Keep trailing average of past 50 observations accuracy\n",
    "    # Get prediction of single observation\n",
    "    [[temp_pred]] = sess.run(prediction, feed_dict={x_data:t, y_target:y_data})\n",
    "    # Get True/False if prediction is accurate\n",
    "    test_acc_temp = target_test[ix]==np.round(temp_pred)\n",
    "    test_acc_all.append(test_acc_temp)\n",
    "\n",
    "print('\\nOverall Test Accuracy: {}'.format(np.mean(test_acc_all)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the training accuracy over all the iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12a627a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# Plot training accuracy over time\n",
    "plt.plot(range(len(train_acc_avg)), train_acc_avg, 'k-', label='Train Accuracy')\n",
    "plt.title('Avg Training Acc Over Past 50 Iterations')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worthwhile to mention the motivation of limiting the sentence (or text) size. In this example we limited the text size to 25 words. This is a common practice with bag of words because it limits the effect of text length on the prediction. You can imagine that if we find a word, meeting for example, that is predictive of a text being ham (not spam), then a spam message might get through by putting in many occurrences of that word at the end. In fact, this is a common problem with imbalanced target data. Imbalanced data might occur in this situation, since spam may be hard to find and ham may be easy to find. Because of this fact, our vocabulary that we create might be heavily skewed toward words represented in the ham part of our data (more ham means more words are represented in ham than spam). If we allow unlimited length of texts, then spammers might take advantage of this and create very long texts, which have a higher probability of triggering non-spam word factors in our logistic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
